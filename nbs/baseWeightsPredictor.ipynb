{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "# from nbdev.qmd import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from fastcore.docments import *\n",
    "from fastcore.test import *\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Class Weights-Based Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseWeightsBasedPredictor(ABC):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        \"\"\"Define weights-based predictor\"\"\"\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    @abstractmethod\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"Fit weights-based predictor on given training data\"\"\"\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    @abstractmethod\n",
    "    def getWeightsData(self, X, scalingList = None):\n",
    "        \"\"\"Compute weights of feature array X\"\"\"\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    def predict(self, \n",
    "                X: np.ndarray, # Feature matrix of samples for which an estimation of conditional quantiles is computed.\n",
    "                probs: list | np.ndarray = [0.1, 0.5, 0.9], # Probabilities for which the estimated conditional p-quantiles are computed.\n",
    "                outputAsDf: bool = False, # Output is either a dataframe with 'probs' as cols or a dict with 'probs' as keys.\n",
    "                scalingList: list | np.ndarray | None = None, # List or array with same size as self.Y containing floats being multiplied with self.Y.\n",
    "               ):\n",
    "        \n",
    "        distributionDataList = self.getWeightsData(X = X,\n",
    "                                                   outputType = 'cumulativeDistribution',\n",
    "                                                   scalingList = scalingList)\n",
    "        \n",
    "        quantilesDict = {prob: [] for prob in probs}\n",
    "        \n",
    "        for probsDistributionFunction, YDistributionFunction in distributionDataList:\n",
    "        \n",
    "            for prob in probs:\n",
    "                quantileIndex = np.where(probsDistributionFunction >= prob)[0][0]\n",
    "                quantile = YDistributionFunction[quantileIndex]\n",
    "                quantilesDict[prob].append(quantile)\n",
    "        \n",
    "        quantilesDf = pd.DataFrame(quantilesDict)\n",
    "        \n",
    "        # Just done to make the dictionary contain arrays rather than lists of the quantiles.\n",
    "        quantilesDict = {prob: np.array(quantiles) for prob, quantiles in quantilesDict.items()}\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        if outputAsDf:\n",
    "            return quantilesDf\n",
    "        \n",
    "        else:\n",
    "            return quantilesDict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructure Weights Data List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def restructureWeightsDataList(weightsDataList, outputType = 'onlyPositiveWeights', Y = None, scalingList = None, equalWeights = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Helper function. Creates weights-output by specifying considered\n",
    "    neighbors of training observations for every test observation of interest.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    neighborsList : {list}\n",
    "        The i-th list-entry is supposed to correspond to the i-th test observation. \n",
    "        Every list-entry should be a array containing the indices of training observations\n",
    "        which were selected as the neighbors of the considered test observation based on\n",
    "        the selected Level-Set-Forecaster algorithm.     \n",
    "    outputType : {\"summarized\", \"onlyPositiveWeights\", \"all\"}, default=\"onlyPositiveWeights\"\n",
    "        Specifies the structure of the output. \n",
    "        - If \"all\", then the weights are outputted as an array that is exactly as long as \n",
    "          the number of training observations. Consequently, also weights equal to zero are\n",
    "          being computed. \n",
    "          NOTE: This can be take up lots of RAM for large datasets with\n",
    "          > 10^6 observations.\n",
    "        - If \"onlyPositiveWeights\", then weights equal to zero are truncated. In order to be \n",
    "          able to identify to which training observation each weight belongs, a tuple is\n",
    "          outputted whose first entry are the weights and the second one are the corresponding\n",
    "          training indices. \n",
    "        - If \"summarized\", then additionally to \"onlyPositiveWeights\", weights referencing to the\n",
    "          same y-value are condensed to one single weight. In this case, the second entry of the\n",
    "          outputted tuple contains the y-values to which each weight corresponds. \n",
    "          NOTE: Summarizing the weights can be very computationally burdensome if roughly the considered\n",
    "          dataset has more than 10^6 observations and if ``binSize`` > 10^4.\n",
    "        - If \"cumulativeDistributionSummarized\", then additionally to \"summarized\", the cumulative sum of the\n",
    "          weights is computed, which can be interpreted as the empirical cumulative distribution\n",
    "          function given the feature vector at hand.\n",
    "          NOTE: This output type requires summarizing the weights, which can be very computationally \n",
    "          burdensome if roughly the considered dataset has more than 10^6 observations and if \n",
    "          ``binSize`` > 10^4.\n",
    "    Y: array, default=None\n",
    "        The target values of the training observations. Only needed when ``outputType`` is given as \n",
    "        \"all\" or \"summarized\".\"\"\"\n",
    "    \n",
    "    if outputType == 'all':\n",
    "        \n",
    "        weightsDataListAll = list()\n",
    "        \n",
    "        for weights, indicesPosWeight in weightsDataList:\n",
    "            weightsAll = np.zeros(len(Y))\n",
    "            weightsAll[indicesPosWeight] = weights\n",
    "            weightsDataListAll.append(weightsAll)\n",
    "        \n",
    "        return weightsDataListAll\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    elif outputType == 'onlyPositiveWeights':\n",
    "        \n",
    "        return weightsDataList\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    elif outputType == 'summarized':\n",
    "        \n",
    "        weightsDataListSummarized = list()\n",
    "\n",
    "        for i in range(len(weightsDataList)):\n",
    "            weightsPos, YWeightPos = weightsDataList[i][0], Y[weightsDataList[i][1]]\n",
    "            \n",
    "            weightsSummarized, YUnique = summarizeWeightsData(weightsPos = weightsPos, \n",
    "                                                              YWeightPos = YWeightPos,\n",
    "                                                              equalWeights = equalWeights)\n",
    "            \n",
    "            if not scalingList is None:\n",
    "                YUnique = YUnique * scalingList[i]\n",
    "                \n",
    "            weightsDataListSummarized.append((weightsSummarized, YUnique))\n",
    "            \n",
    "        return weightsDataListSummarized\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    elif outputType == 'cumulativeDistribution':\n",
    "        \n",
    "        distributionDataList = list()\n",
    "        \n",
    "        for i in range(len(weightsDataList)):\n",
    "            weightsPos, YWeightPos = weightsDataList[i][0], Y[weightsDataList[i][1]]\n",
    "            \n",
    "            indicesSort = np.argsort(YWeightPos)\n",
    "            \n",
    "            weightsPosSorted = weightsPos[indicesSort]\n",
    "            YWeightPosSorted = YWeightPos[indicesSort]\n",
    "            \n",
    "            cumulativeProbs = np.cumsum(weightsPosSorted)\n",
    "            \n",
    "            if not scalingList is None:\n",
    "                YWeightPosSorted = YWeightPosSorted * scalingList[i]\n",
    "                \n",
    "            distributionDataList.append((cumulativeProbs, YWeightPosSorted))\n",
    "            \n",
    "        return distributionDataList\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    elif outputType == 'cumulativeDistributionSummarized':\n",
    "        \n",
    "        distributionDataList = list()\n",
    "        \n",
    "        for i in range(len(weightsDataList)):\n",
    "            weightsPos, YWeightPos = weightsDataList[i][0], Y[weightsDataList[i][1]]\n",
    "            \n",
    "            weightsSummarizedSorted, YPosWeightUniqueSorted = summarizeWeightsData(weightsPos = weightsPos, \n",
    "                                                                                   YWeightPos = YWeightPos,\n",
    "                                                                                   equalWeights = equalWeights)\n",
    "            \n",
    "            cumulativeProbs = np.cumsum(weightsSummarizedSorted)\n",
    "            \n",
    "            if not scalingList is None:\n",
    "                YPosWeightUniqueSorted = YPosWeightUniqueSorted * scalingList[i]\n",
    "                \n",
    "            distributionDataList.append((cumulativeProbs, YPosWeightUniqueSorted))\n",
    "            \n",
    "        return distributionDataList\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize Weights Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def summarizeWeightsData(weightsPos, YWeightPos, equalWeights = False):\n",
    "    \n",
    "    if equalWeights:\n",
    "        counterDict = Counter(YWeightPos)\n",
    "        YUniqueSorted = np.sort(list(counterDict.keys()))\n",
    "\n",
    "        weightsSummarizedSorted = np.array([counterDict[value] / len(YWeightPos) for value in YUniqueSorted])\n",
    "    \n",
    "    else:\n",
    "        duplicationDict = defaultdict(list)\n",
    "\n",
    "        for i, item in enumerate(YWeightPos):\n",
    "            duplicationDict[item].append(i)\n",
    "\n",
    "        #---\n",
    "\n",
    "        weightsSummarized = list()\n",
    "        YUnique = list()\n",
    "\n",
    "        for value, indices in duplicationDict.items():        \n",
    "\n",
    "            weightsSummarized.append(weightsPos[indices].sum())\n",
    "            YUnique.append(value)\n",
    "\n",
    "        weightsSummarized, YUnique = np.array(weightsSummarized), np.array(YUnique)\n",
    "\n",
    "        #---\n",
    "\n",
    "        indicesSort = np.argsort(YUnique)\n",
    "        weightsSummarizedSorted, YUniqueSorted = weightsSummarized[indicesSort], YUnique[indicesSort]\n",
    "    \n",
    "    return weightsSummarizedSorted, YUniqueSorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
