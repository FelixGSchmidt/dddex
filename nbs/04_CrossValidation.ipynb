{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a800fac0-995f-41b1-b679-bf1eb76d7253",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b1a36-300d-4661-a2b2-52f48f9647d7",
   "metadata": {},
   "source": [
    "# Cross Validation Functions\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddba5e3-2640-4630-a836-663301c6c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp crossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fea4d3-5da2-412e-9bd6-292e4a0cf1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "# from nbdev.qmd import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af4132-d4b9-40bd-b05a-0cc1d4ec3fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from fastcore.docments import *\n",
    "from fastcore.test import *\n",
    "from fastcore.utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "from sklearn.base import clone\n",
    "\n",
    "from dddex.wSAA import SampleAverageApproximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7e1c90-40c0-41b4-8ba5-04a5003b3332",
   "metadata": {},
   "source": [
    "## Cross Validation - General Quantile Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad25f5-6f41-4cc9-b71d-1a0d59bb4ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class QuantileCrossValidation:\n",
    "    \"\"\"\n",
    "    Class to efficiently tune the `binSize` parameter of all Level-Set based models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 # An object with a `predict` method that must (!) have an argument called `probs`\n",
    "                 # that specifies which quantiles to predict. Further, `quantileEstimator` needs\n",
    "                 # a `set_params` and `fit` method.\n",
    "                 quantileEstimator, \n",
    "                 cvFolds, # An iterable yielding (train, test) splits as arrays of indices.\n",
    "                 parameterGrid: dict,\n",
    "                 probs: list=[i / 100 for i in range(1, 100, 1)], # list or array of floats between 0 and 1. p-quantiles being predicted to evaluate performance of LSF.\n",
    "                 # If True, for each p-quantile a fitted LSF with best binSize to predict it is returned. \n",
    "                 # Otherwise only one LSF is returned that is best over all probs.\n",
    "                 refitPerProb: bool=False, \n",
    "                 n_jobs: int=None, # number of folds being computed in parallel.\n",
    "                 ):\n",
    "        \n",
    "        # CHECKS  \n",
    "        # if not isinstance(estimatorLSx, (BaseLSx)):\n",
    "        #     raise ValueError(\"'estimatorLSx' has to be a 'LevelSetKDEx', 'LevelSetKDEx_NN_new' or a 'LevelSetKDEx_kNN' object!\")               \n",
    "            \n",
    "        if np.any(np.array(probs) > 1) or np.any(np.array(probs) < 0): \n",
    "            raise ValueError(\"probs must only contain numbers between 0 and 1!\") \n",
    "        \n",
    "        #---\n",
    "        \n",
    "        self.quantileEstimator = copy.deepcopy(quantileEstimator)\n",
    "        self.parameterGrid = ParameterGrid(parameterGrid)\n",
    "        self.cvFolds = cvFolds\n",
    "        self.probs = probs\n",
    "        self.refitPerProb = refitPerProb\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "        self.bestParams = None\n",
    "        self.bestParams_perProb = None\n",
    "        self.bestEstimator = None\n",
    "        self.bestEstimator_perProb = None\n",
    "        self.cvResults = None\n",
    "        self.cvResults_raw = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e9083c-e9db-43a3-b27e-9563bb966d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def fit(self: QuantileCrossValidation, \n",
    "        X: np.ndarray, # Feature matrix (has to work with the folds specified via `cvFolds`)\n",
    "        y: np.ndarray, # Target values (has to work with the folds specified via `cvFolds`)\n",
    "        ): \n",
    "    \n",
    "    # Making sure that X and y are arrays to ensure correct subsetting via implicit indices.\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # scoresPerFold = Parallel(n_jobs = self.n_jobs)(delayed(getFoldScore)(estimatorLSx = copy.deepcopy(self.quantileEstimator),\n",
    "    #                                                                      parameterGrid = self.parameterGrid,\n",
    "    #                                                                      cvFold = cvFold,\n",
    "    #                                                                      probs = self.probs,\n",
    "    #                                                                      X = X,\n",
    "    #                                                                      y = y) for cvFold in self.cvFolds)\n",
    "    \n",
    "    scoresPerFold = [getFoldScore(quantileEstimator = copy.deepcopy(self.quantileEstimator),\n",
    "                                  parameterGrid = self.parameterGrid,\n",
    "                                  cvFold = cvFold,\n",
    "                                  probs = self.probs,\n",
    "                                  y = y,\n",
    "                                  X = X) for cvFold in self.cvFolds]\n",
    "\n",
    "    self.cvResults_raw = scoresPerFold\n",
    "    meanCostsDf = sum(scoresPerFold) / len(scoresPerFold)\n",
    "    self.cvResults = meanCostsDf\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    # BEST PARAMETER SETTINGS OVER ALL PROBS\n",
    "    meanCostsPerParam = meanCostsDf.mean(axis = 1)\n",
    "    paramsBest = meanCostsPerParam.index[np.argmin(meanCostsPerParam)]\n",
    "    paramsBest = dict(zip(meanCostsPerParam.index.names, paramsBest))\n",
    "    self.bestParams = paramsBest\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    # BEST PARAMETER SETTINGS PER PROB\n",
    "    paramsBestPerProbSeries = meanCostsDf.idxmin(axis = 0)\n",
    "    paramsBestPerProb = {prob: dict(zip(meanCostsDf.index.names, paramsBestPerProbSeries.loc[prob])) for prob in self.probs}\n",
    "    self.bestParams_perProb = paramsBestPerProb\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    # REFITTING ESTIMATORS\n",
    "    if self.refitPerProb:      \n",
    "        \n",
    "        # GET UNIQUE PARAMETER COMBS OF LSx THAT ARE BEST FOR ANY PROB\n",
    "        paramsUnique = pd.DataFrame(paramsBestPerProb.values()).drop_duplicates().to_dict(orient = 'records')\n",
    "        estimatorDict = dict()\n",
    "        \n",
    "        for params in paramsUnique:\n",
    "            quantileEstimator = copy.deepcopy(self.quantileEstimator)\n",
    "            quantileEstimator.set_params(**params)\n",
    "            \n",
    "            quantileEstimator.fit(X = X, y = y)\n",
    "            estimatorDict[tuple(params.values())] = quantileEstimator\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        # DICTIONARY OF THE BEST LSx-ESTIMATORS PER PROB\n",
    "        bestEstimatorPerProb = {prob: estimatorDict[tuple(paramsBestPerProb[prob].values())] for prob in self.probs}\n",
    "        self.bestEstimator_perProb = bestEstimatorPerProb\n",
    "        \n",
    "    #---\n",
    "    \n",
    "    quantileEstimator = copy.deepcopy(self.quantileEstimator)\n",
    "    quantileEstimator.set_params(**paramsBest)\n",
    "    quantileEstimator.fit(X = X, y = y)\n",
    "\n",
    "    self.bestEstimator = quantileEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488035d2-75cc-4a97-997c-1e3f040d2f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(CrossValidationLSx.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d51812a-41e2-45c7-a653-ea662a3bff33",
   "metadata": {},
   "source": [
    "#### Scores for Single Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4188bccf-91fa-43b7-ac4c-1959437d6aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# This function evaluates the newsvendor performance for different bin sizes for one specific fold.\n",
    "# The considered bin sizes\n",
    "\n",
    "def getFoldScore(quantileEstimator, parameterGrid, cvFold, probs, X, y):\n",
    "    \n",
    "    indicesTrain = cvFold[0]\n",
    "    indicesTest = cvFold[1]\n",
    "    \n",
    "    yTrainFold = y[indicesTrain]\n",
    "    XTrainFold = X[indicesTrain]\n",
    "    \n",
    "    yTestFold = y[indicesTest]\n",
    "    XTestFold = X[indicesTest]\n",
    "    \n",
    "    #---\n",
    "\n",
    "    SAA_fold = SampleAverageApproximation()\n",
    "    SAA_fold.fit(y = yTrainFold)\n",
    "\n",
    "    # By setting 'X = None', the SAA results are only computed for a single observation (they are independent of X anyway).\n",
    "    # In order to receive the final dataframe of SAA results, we simply duplicate this single row as many times as needed.\n",
    "    quantilesDictSAAOneOb = SAA_fold.predict(X = None, probs = probs, outputAsDf = False)\n",
    "    quantilesDictSAA = {prob: np.repeat(quantile, len(XTestFold)) for prob, quantile in quantilesDictSAAOneOb.items()}\n",
    "\n",
    "    #---\n",
    "    \n",
    "    # Necessary to ensure compatability with wSAA-models etc.\n",
    "    try:\n",
    "        quantileEstimator.refitPointEstimator(X = XTrainFold, \n",
    "                                              y = yTrainFold)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    costsPerParam = defaultdict(dict)\n",
    "\n",
    "    for params in parameterGrid:\n",
    "\n",
    "        quantileEstimator.set_params(**params)\n",
    "\n",
    "        quantileEstimator.fit(X = XTrainFold,\n",
    "                              y = yTrainFold)\n",
    "\n",
    "        quantilesDict = quantileEstimator.predict(X = XTestFold,\n",
    "                                                  probs = probs,\n",
    "                                                  outputAsDf = False)\n",
    "\n",
    "        costsDict = dict()\n",
    "        for prob in probs:            \n",
    "            costsDict[prob] = getCostRatio(decisions = quantilesDict[prob], \n",
    "                                           decisionsSAA = quantilesDictSAA[prob], \n",
    "                                           yTest = yTestFold, \n",
    "                                           prob = prob)\n",
    "\n",
    "        costsPerParam[tuple(params.values())] = costsDict\n",
    "\n",
    "    #---\n",
    "\n",
    "    costsDf = pd.DataFrame.from_dict(costsPerParam, orient = 'index')\n",
    "    costsDf.index.names = list(params.keys())\n",
    "    \n",
    "    return costsDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99911626-0352-4829-9ab6-412f104ec00b",
   "metadata": {},
   "source": [
    "## Cross Validation - LSx + Point Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c3049c-6dd2-489b-bc2a-cd34ef5acfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class CrossValidationLSx_combined:\n",
    "    \"\"\"\n",
    "    Class to efficiently tune the `binSize` parameter of all Level-Set based models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 estimatorLSx, # A Level-Set based model.\n",
    "                 cvFolds, # An iterable yielding (train, test) splits as arrays of indices.\n",
    "                 parameterGridLSx: dict,\n",
    "                 parameterGridEstimator: dict,\n",
    "                 probs: list=[i / 100 for i in range(1, 100, 1)], # list or array of floats between 0 and 1. p-quantiles being predicted to evaluate performance of LSF.\n",
    "                 # If True, for each p-quantile a fitted LSF with best binSize to predict it is returned. \n",
    "                 # Otherwise only one LSF is returned that is best over all probs.\n",
    "                 refitPerProb: bool=False, \n",
    "                 n_jobs: int=None, # number of folds being computed in parallel.\n",
    "                 ):\n",
    "        \n",
    "        # CHECKS  \n",
    "        if not isinstance(estimatorLSx, (BaseLSx)):\n",
    "            raise ValueError(\"'estimatorLSx' has to be a 'LevelSetKDEx', 'LevelSetKDEx_NN_new' or a 'LevelSetKDEx_kNN' object!\")               \n",
    "            \n",
    "        if np.any(np.array(probs) > 1) or np.any(np.array(probs) < 0): \n",
    "            raise ValueError(\"probs must only contain numbers between 0 and 1!\") \n",
    "        \n",
    "        #---\n",
    "        \n",
    "        self.estimatorLSx = copy.deepcopy(estimatorLSx)\n",
    "        self.parameterGridLSx = ParameterGrid(parameterGridLSx)\n",
    "        self.parameterGridEstimator = ParameterGrid(parameterGridEstimator)\n",
    "        self.cvFolds = cvFolds\n",
    "        self.probs = probs\n",
    "        self.refitPerProb = refitPerProb\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "        self.bestParams = None\n",
    "        self.bestParams_perProb = None\n",
    "        self.bestEstimatorLSx = None\n",
    "        self.bestEstimatorLSx_perProb = None\n",
    "        self.cvResults = None\n",
    "        self.cvResults_raw = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a5c540-8e30-4399-941f-743a9e37fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def fit(self: CrossValidationLSx_combined, \n",
    "        X: np.ndarray, # Feature matrix (has to work with the folds specified via `cvFolds`)\n",
    "        y: np.ndarray, # Target values (has to work with the folds specified via `cvFolds`)\n",
    "        ): \n",
    "    \n",
    "    # Making sure that X and y are arrays to ensure correct subsetting via implicit indices.\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # scoresPerFold = Parallel(n_jobs = self.n_jobs)(delayed(getFoldScore_combined)(cvFold = cvFold,\n",
    "    #                                                                               binSizeGrid = self.binSizeGrid,\n",
    "    #                                                                               probs = self.probs,\n",
    "    #                                                                               estimatorLSx = copy.deepcopy(self.estimatorLSx),\n",
    "    #                                                                               y = y,\n",
    "    #                                                                               X = X) for cvFold in self.cvFolds)\n",
    "    \n",
    "    scoresPerFold = [getFoldScore_combined(estimatorLSx = copy.deepcopy(self.estimatorLSx),\n",
    "                                           parameterGridLSx = self.parameterGridLSx,\n",
    "                                           parameterGridEstimator = self.parameterGridEstimator,\n",
    "                                           cvFold = cvFold,\n",
    "                                           probs = self.probs,\n",
    "                                           y = y,\n",
    "                                           X = X) for cvFold in self.cvFolds]\n",
    "\n",
    "    self.cvResults_raw = scoresPerFold\n",
    "    meanCostsDf = sum(scoresPerFold) / len(scoresPerFold)\n",
    "    self.cvResults = meanCostsDf\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    # BEST PARAMETER SETTINGS OVER ALL PROBS\n",
    "    meanCostsPerParam = meanCostsDf.mean(axis = 1)\n",
    "    paramsBest = meanCostsPerParam.index[np.argmin(meanCostsPerParam)]\n",
    "    paramsBest = dict(zip(meanCostsPerParam.index.names, paramsBest))\n",
    "    \n",
    "    paramsLSxNames = self.estimatorLSx._get_param_names()\n",
    "    paramsLSxBest = {paramName: value for paramName, value in paramsBest.items() if paramName in paramsLSxNames}\n",
    "    paramsEstimatorBest = {paramName: value for paramName, value in paramsBest.items() if not paramName in paramsLSxNames}\n",
    "    \n",
    "    self.bestParams = paramsBest\n",
    "    self.bestParamsLSx = paramsLSxBest\n",
    "    self.bestParamsEstimator = paramsEstimatorBest\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    # BEST PARAMETER SETTINGS PER PROB\n",
    "    paramsBestPerProbSeries = meanCostsDf.idxmin(axis = 0)\n",
    "    paramsBestPerProb = {prob: dict(zip(meanCostsDf.index.names, paramsBestPerProbSeries.loc[prob])) for prob in self.probs}\n",
    "    \n",
    "    paramsLSxBestPerProb = {prob: {paramName: value for paramName, value in paramsBestPerProb[prob].items() \n",
    "                                   if paramName in paramsLSxNames} for prob in self.probs}\n",
    "    paramsEstimatorBestPerProb = {prob: {paramName: value for paramName, value in paramsBestPerProb[prob].items() \n",
    "                                   if not paramName in paramsLSxNames} for prob in self.probs}\n",
    "    \n",
    "    self.bestParams_perProb = paramsBestPerProb\n",
    "    self.bestParamsLSx_perProb = paramsBestPerProb\n",
    "    self.bestParamsEstimator_perProb = paramsBestPerProb\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    # REFITTING ESTIMATORS\n",
    "    if self.refitPerProb:\n",
    "        \n",
    "        # GET UNIQUE PARAMETER COMBS OF ESTIMATOR THAT ARE BEST FOR ANY PROB\n",
    "        paramsEstimatorUnique = pd.DataFrame(paramsEstimatorBestPerProb.values()).drop_duplicates().to_dict(orient = 'records')\n",
    "        estimatorDict = dict()\n",
    "        \n",
    "        for params in paramsEstimatorUnique:\n",
    "            estimator = clone(self.estimatorLSx.estimator)\n",
    "            estimator.set_params(**params)\n",
    "            estimator.fit(X = X, y = y)\n",
    "            estimatorDict[tuple(params.values())] = estimator\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        # GET UNIQUE PARAMETER COMBS OF LSx THAT ARE BEST FOR ANY PROB\n",
    "        paramsUnique = pd.DataFrame(paramsBestPerProb.values()).drop_duplicates().to_dict(orient = 'records')\n",
    "        \n",
    "        estimatorLSxDict = dict()\n",
    "        for params in paramsUnique:\n",
    "            paramsLSx = {paramName: value for paramName, value in params.items() if paramName in paramsLSxNames}\n",
    "            paramsEstimatorTuple = tuple(value for paramName, value in params.items() if not paramName in paramsLSxNames)\n",
    "            \n",
    "            estimator = estimatorDict[paramsEstimatorTuple]\n",
    "            estimatorLSx = copy.deepcopy(self.estimatorLSx)\n",
    "            \n",
    "            estimatorLSx.set_params(**paramsLSx, \n",
    "                                    estimator = estimator)\n",
    "            \n",
    "            estimatorLSx.fit(X = X, y = y)\n",
    "            estimatorLSxDict[tuple(params.values())] = estimatorLSx\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        # DICTIONARY OF THE BEST LSx-ESTIMATORS PER PROB\n",
    "        bestEstimatorPerProb = {prob: estimatorLSxDict[tuple(paramsBestPerProb[prob].values())] for prob in self.probs}\n",
    "        self.bestEstimatorLSx_perProb = bestEstimatorPerProb\n",
    "        \n",
    "    #---\n",
    "    \n",
    "    estimatorLSx = copy.deepcopy(self.estimatorLSx)\n",
    "    \n",
    "    estimator = clone(estimatorLSx.estimator)\n",
    "    estimator.set_params(**paramsEstimatorBest)\n",
    "    estimator.fit(X = X, y = y)\n",
    "    \n",
    "    estimatorLSx.set_params(**paramsLSxBest,\n",
    "                            estimator = estimator)\n",
    "    estimatorLSx.fit(X = X, y = y)\n",
    "\n",
    "    self.bestEstimatorLSx = estimatorLSx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e4c000-976e-40dc-9c4c-e4e3da959668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(CrossValidationLSx_combined.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e48150-d0f2-4699-a6c0-1d6f17918ad7",
   "metadata": {},
   "source": [
    "#### Scores for Single Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976ee9c5-39e1-44b2-94ab-2cc361862373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# This function evaluates the newsvendor performance for different bin sizes for one specific fold.\n",
    "# The considered bin sizes\n",
    "\n",
    "def getFoldScore_combined(estimatorLSx, parameterGridLSx, parameterGridEstimator, cvFold, probs, X, y):\n",
    "    \n",
    "    indicesTrain = cvFold[0]\n",
    "    indicesTest = cvFold[1]\n",
    "    \n",
    "    yTrainFold = y[indicesTrain]\n",
    "    XTrainFold = X[indicesTrain]\n",
    "    \n",
    "    yTestFold = y[indicesTest]\n",
    "    XTestFold = X[indicesTest]\n",
    "    \n",
    "    costsDfList = list()\n",
    "    \n",
    "    for paramsEstimator in parameterGridEstimator:\n",
    "        \n",
    "        estimatorLSx.refitPointEstimator(X = XTrainFold, \n",
    "                                         y = yTrainFold,\n",
    "                                         **paramsEstimator)\n",
    "\n",
    "        #---\n",
    "\n",
    "        SAA_fold = SampleAverageApproximation()\n",
    "        SAA_fold.fit(y = yTrainFold)\n",
    "\n",
    "        # By setting 'X = None', the SAA results are only computed for a single observation (they are independent of X anyway).\n",
    "        # In order to receive the final dataframe of SAA results, we simply duplicate this single row as many times as needed.\n",
    "        quantilesDictSAAOneOb = SAA_fold.predict(X = None, probs = probs, outputAsDf = False)\n",
    "        quantilesDictSAA = {prob: np.repeat(quantile, len(XTestFold)) for prob, quantile in quantilesDictSAAOneOb.items()}\n",
    "\n",
    "        #---\n",
    "\n",
    "        costsPerParamLSx = defaultdict(dict)\n",
    "\n",
    "        for paramsLSx in parameterGridLSx:\n",
    "\n",
    "            estimatorLSx.set_params(**paramsLSx)\n",
    "\n",
    "            estimatorLSx.fit(X = XTrainFold,\n",
    "                             y = yTrainFold)\n",
    "\n",
    "            quantilesDict = estimatorLSx.predict(X = XTestFold,\n",
    "                                                 probs = probs,\n",
    "                                                 outputAsDf = False)\n",
    "\n",
    "            #---\n",
    "\n",
    "            costsDict = dict()\n",
    "\n",
    "            for prob in probs:            \n",
    "                costsDict[prob] = getCostRatio(decisions = quantilesDict[prob], \n",
    "                                               decisionsSAA = quantilesDictSAA[prob], \n",
    "                                               yTest = yTestFold, \n",
    "                                               prob = prob)\n",
    "            \n",
    "           \n",
    "            costsPerParamLSx[tuple(paramsLSx.values())] = costsDict\n",
    "\n",
    "        #---\n",
    "        \n",
    "        costsDf = pd.DataFrame.from_dict(costsPerParamLSx, orient = 'index')\n",
    "        \n",
    "        paramsLSxNames = list(paramsLSx.keys())\n",
    "        costsDf.index.names = paramsLSxNames\n",
    "\n",
    "        costsDf = costsDf.reset_index(drop = False)\n",
    "        for paramName, value in paramsEstimator.items():\n",
    "            costsDf[paramName] = value\n",
    "\n",
    "        paramNames = paramsLSxNames + list(paramsEstimator.keys())\n",
    "        costsDf = costsDf.set_index(paramNames)\n",
    "        \n",
    "        costsDfList.append(costsDf)\n",
    "        \n",
    "    #---\n",
    "    \n",
    "    costsDf = pd.concat(costsDfList, axis = 0)\n",
    "    \n",
    "    return costsDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fada52-3351-4323-b0f0-d529a995de89",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1cabde-9765-4adc-8e8c-381ab50a9ce2",
   "metadata": {},
   "source": [
    "### Get Cost Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f437f33b-361e-4c50-b03d-e7b36fcd9ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def getCostRatio(decisions, decisionsSAA, yTest, prob):\n",
    "\n",
    "    # Newsvendor Costs of our model\n",
    "    cost = np.array([prob * (yTest[i] - decisions[i]) if yTest[i] > decisions[i] \n",
    "                     else (1 - prob) * (decisions[i] - yTest[i]) \n",
    "                     for i in range(len(yTest))]).sum()\n",
    "    \n",
    "    # Newsvendor Costs of SAA\n",
    "    costSAA = np.array([prob * (yTest[i] - decisionsSAA[i]) if yTest[i] > decisionsSAA[i] \n",
    "                        else (1 - prob) * (decisionsSAA[i] - yTest[i]) \n",
    "                        for i in range(len(yTest))]).sum()\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    # We have to capture the special case of costSAA == 0, because then we can't compute the \n",
    "    # Cost-Ratio using the actual definition.\n",
    "    if costSAA > 0:\n",
    "        costRatio = cost / costSAA\n",
    "    else:\n",
    "        if cost == 0:\n",
    "            costRatio = 0\n",
    "        else:\n",
    "            costRatio = 1\n",
    "    \n",
    "    return costRatio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a628cfb-028a-4d7e-ae23-5e459995d6e3",
   "metadata": {},
   "source": [
    "### Grouped Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e558baa5-750c-4809-9c73-81d22ff3603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# This function creates the cross-validation folds for every time series. Usually you'd want all test-observations \n",
    "# of each fold to refer to the same time period, but this is impossible to ensure in the case of the two-step models,\n",
    "# because the regression of the non-zero observations will always contain data of different time points. For that\n",
    "# reason, we refrain from trying to ensure this consistency.\n",
    "# Instead we organize our splits such that we always move a fixed amount of observations into the future from split\n",
    "# to split for every time series. This fixed amount of observations is currently set to the test length of the\n",
    "# corresponding time series.\n",
    "\n",
    "# In case this function is supposed to be used in the two-step case, data simply has to be filtered before hand\n",
    "# to only contain positive demand observations.\n",
    "\n",
    "def groupedTimeSeriesSplit(data, kFolds, testLength, groupFeature, timeFeature):\n",
    "    \n",
    "    # We reset the index because we have to access 'group.index' later on and\n",
    "    # want to make sure that we return the implicit numerical indices for our splits.\n",
    "    data = data.reset_index(drop = True)\n",
    "\n",
    "    dataGrouped = data.groupby(groupFeature)\n",
    "    splitNumbers = np.flip(np.array(range(kFolds)))\n",
    "    \n",
    "    foldsList = list()\n",
    "\n",
    "    for i in splitNumbers:\n",
    "\n",
    "        trainIndicesList = list()\n",
    "        valIndicesList = list()\n",
    "\n",
    "        valIndicesDict = dict()\n",
    "\n",
    "        for name, group in dataGrouped:\n",
    "\n",
    "            timeMin = int(group[timeFeature].min())\n",
    "            timeMax = int(group[timeFeature].max())\n",
    "\n",
    "            validationTimeMax = timeMax - i * testLength\n",
    "            trainTimeMax = validationTimeMax - testLength\n",
    "\n",
    "            trainTimesGroup = np.array(range(timeMin, trainTimeMax + 1))\n",
    "            valTimesGroup = np.array(range(trainTimeMax + 1, validationTimeMax + 1))\n",
    "\n",
    "            trainIndicesCheck = [timePoint in trainTimesGroup for timePoint in group[timeFeature]]\n",
    "            valIndicesCheck = [timePoint in valTimesGroup for timePoint in group[timeFeature]]\n",
    "\n",
    "            trainIndicesGroup = group.index[trainIndicesCheck]\n",
    "            valIndicesGroup = group.index[valIndicesCheck]\n",
    "\n",
    "            trainIndicesList.append(trainIndicesGroup)\n",
    "            valIndicesList.append(valIndicesGroup)\n",
    "\n",
    "        trainIndices = np.concatenate(trainIndicesList)\n",
    "        valIndices = np.concatenate(valIndicesList)\n",
    "        fold = (trainIndices, valIndices)\n",
    "\n",
    "        foldsList.append(fold)\n",
    "\n",
    "    return foldsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79762a-1427-49d7-b8b2-42ecde48e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f92782a-5fef-40fa-a501-01b0f5e99186",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f8d681-5c45-414e-b162-c84a42f65569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# import ipdb\n",
    "# from lightgbm import LGBMRegressor\n",
    "\n",
    "# from dddex.loadData import *\n",
    "# from dddex.wSAA import RandomForestWSAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c31d24d-457b-4473-9574-f5db4124cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# data, XTrain, yTrain, XTest, yTest = loadDataYaz(testDays = 14, \n",
    "#                                                  returnXY = True,\n",
    "#                                                  daysToCut = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0126734-feeb-4e91-9ac3-31b269f591a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# LGBM = LGBMRegressor(boosting_type = 'gbdt',\n",
    "#                      n_jobs = 1)\n",
    "\n",
    "# LGBM.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef94795-2496-4528-9776-abe1833df5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# LSKDEx = LevelSetKDEx(estimator = LGBM, binSize = 100, weightsByDistance = False)\n",
    "# LSKDEx.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab47f8-d170-4278-82c4-6805dcc3b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# dataTrain = data[data.label == 'train']\n",
    "\n",
    "# cvFolds = groupedTimeSeriesSplit(data = dataTrain, \n",
    "#                                  kFolds = 3, \n",
    "#                                  testLength = 28, \n",
    "#                                  groupFeature = 'id', \n",
    "#                                  timeFeature = 'dayIndex')\n",
    "\n",
    "# CV = CrossValidationLSx_combined(estimatorLSx = LSKDEx,\n",
    "#                                  cvFolds = cvFolds,\n",
    "#                                  parameterGridLSx = {'binSize': [10, 100, 400],\n",
    "#                                                     'weightsByDistance': [True, False]},\n",
    "#                                  parameterGridEstimator = {'max_depth': [3, 4],\n",
    "#                                                            'n_estimators': [150, 210]},\n",
    "#                                  probs = [0.01, 0.49, 0.5, 0.999],\n",
    "#                                  refitPerProb = True)\n",
    "\n",
    "# CV.fit(X = XTrain, y = yTrain)\n",
    "\n",
    "# CV2 = QuantileCrossValidation(quantileEstimator = LSKDEx,\n",
    "#                               cvFolds = cvFolds,\n",
    "#                               parameterGrid = {'binSize': [10, 100, 400],\n",
    "#                                                'weightsByDistance': [True, False]},\n",
    "#                               probs = [0.01, 0.49, 0.5, 0.999],\n",
    "#                               refitPerProb = True)\n",
    "\n",
    "# CV2.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0bd343-a8e5-4ee5-975d-c12eccf61be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF = RandomForestWSAA()\n",
    "\n",
    "# CV = QuantileCrossValidation(quantileEstimator = RF,\n",
    "#                              cvFolds = cvFolds,\n",
    "#                              parameterGrid = {'max_depth': [3, 4],\n",
    "#                                               'n_estimators': [150, 210]},\n",
    "#                              probs = [0.01, 0.49, 0.5, 0.999],\n",
    "#                              refitPerProb = True)\n",
    "\n",
    "# CV.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e77c34-ca94-4dd9-9d81-b276a0b64617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dddex",
   "language": "python",
   "name": "dddex"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
