{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Fill in a module description here\n",
    "output-file: crossvalidation.html\n",
    "title: Cross Validation Functions\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a800fac0-995f-41b1-b679-bf1eb76d7253",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6d5baf3-bf86-48cb-a771-3e6102407c0c",
   "metadata": {},
   "source": [
    "## Cross Validation - General Quantile Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L27){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QuantileCrossValidation\n",
       "\n",
       ">      QuantileCrossValidation (quantileEstimator, cvFolds, parameterGrid:dict,\n",
       ">                               randomSearch:bool=False, nIter:int=None,\n",
       ">                               probs:list=[0.01, 0.02, 0.03, 0.04, 0.05, 0.06,\n",
       ">                               0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14,\n",
       ">                               0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22,\n",
       ">                               0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3,\n",
       ">                               0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38,\n",
       ">                               0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46,\n",
       ">                               0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54,\n",
       ">                               0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62,\n",
       ">                               0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7,\n",
       ">                               0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78,\n",
       ">                               0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86,\n",
       ">                               0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94,\n",
       ">                               0.95, 0.96, 0.97, 0.98, 0.99],\n",
       ">                               refitPerProb:bool=False, n_jobs:int=None,\n",
       ">                               random_state:int=None)\n",
       "\n",
       "Class to efficiently tune the `binSize` parameter of all Level-Set based models.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| quantileEstimator |  |  | An object with a `predict` method that must (!) have an argument called `probs`<br>that specifies which quantiles to predict. Further, `quantileEstimator` needs<br>a `set_params` and `fit` method. |\n",
       "| cvFolds |  |  | An iterable yielding (train, test) splits as arrays of indices. |\n",
       "| parameterGrid | dict |  | dict or list of dicts with parameters names (`str`) as keys and distributions<br>or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| randomSearch | bool | False | Whether to use randomized search or grid search |\n",
       "| nIter | int | None | Number of parameter settings that are sampled if `randomSearch == True`. <br>n_iter trades off runtime vs quality of the solution. |\n",
       "| probs | list | [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99] | iterable of floats between 0 and 1. These determine the p-quantiles being predicted <br>to evaluate performance of each parameter setting. |\n",
       "| refitPerProb | bool | False | If True, for each p-quantile a fitted LSF with best binSize to predict it is returned. <br>Otherwise only one LSF is returned that is best over all probs. |\n",
       "| n_jobs | int | None | Number of jobs to run in parallel. |\n",
       "| random_state | int | None | Pseudo random number generator state used for random uniform sampling of parameter candidate values.<br>Pass an int for reproducible output across multiple function calls. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L27){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QuantileCrossValidation\n",
       "\n",
       ">      QuantileCrossValidation (quantileEstimator, cvFolds, parameterGrid:dict,\n",
       ">                               randomSearch:bool=False, nIter:int=None,\n",
       ">                               probs:list=[0.01, 0.02, 0.03, 0.04, 0.05, 0.06,\n",
       ">                               0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14,\n",
       ">                               0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22,\n",
       ">                               0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3,\n",
       ">                               0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38,\n",
       ">                               0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46,\n",
       ">                               0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54,\n",
       ">                               0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62,\n",
       ">                               0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7,\n",
       ">                               0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78,\n",
       ">                               0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86,\n",
       ">                               0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94,\n",
       ">                               0.95, 0.96, 0.97, 0.98, 0.99],\n",
       ">                               refitPerProb:bool=False, n_jobs:int=None,\n",
       ">                               random_state:int=None)\n",
       "\n",
       "Class to efficiently tune the `binSize` parameter of all Level-Set based models.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| quantileEstimator |  |  | An object with a `predict` method that must (!) have an argument called `probs`<br>that specifies which quantiles to predict. Further, `quantileEstimator` needs<br>a `set_params` and `fit` method. |\n",
       "| cvFolds |  |  | An iterable yielding (train, test) splits as arrays of indices. |\n",
       "| parameterGrid | dict |  | dict or list of dicts with parameters names (`str`) as keys and distributions<br>or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| randomSearch | bool | False | Whether to use randomized search or grid search |\n",
       "| nIter | int | None | Number of parameter settings that are sampled if `randomSearch == True`. <br>n_iter trades off runtime vs quality of the solution. |\n",
       "| probs | list | [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99] | iterable of floats between 0 and 1. These determine the p-quantiles being predicted <br>to evaluate performance of each parameter setting. |\n",
       "| refitPerProb | bool | False | If True, for each p-quantile a fitted LSF with best binSize to predict it is returned. <br>Otherwise only one LSF is returned that is best over all probs. |\n",
       "| n_jobs | int | None | Number of jobs to run in parallel. |\n",
       "| random_state | int | None | Pseudo random number generator state used for random uniform sampling of parameter candidate values.<br>Pass an int for reproducible output across multiple function calls. |"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(QuantileCrossValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L98){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QuantileCrossValidation.fit\n",
       "\n",
       ">      QuantileCrossValidation.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | np.ndarray | Feature matrix (has to work with the folds specified via `cvFolds`) |\n",
       "| y | np.ndarray | Target values (has to work with the folds specified via `cvFolds`) |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L98){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QuantileCrossValidation.fit\n",
       "\n",
       ">      QuantileCrossValidation.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | np.ndarray | Feature matrix (has to work with the folds specified via `cvFolds`) |\n",
       "| y | np.ndarray | Target values (has to work with the folds specified via `cvFolds`) |"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(QuantileCrossValidation.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d51812a-41e2-45c7-a653-ea662a3bff33",
   "metadata": {},
   "source": [
    "#### Scores for Single Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L174){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getFoldScore\n",
       "\n",
       ">      getFoldScore (quantileEstimator, parameterGrid, cvFold, probs, X, y)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L174){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getFoldScore\n",
       "\n",
       ">      getFoldScore (quantileEstimator, parameterGrid, cvFold, probs, X, y)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(getFoldScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99911626-0352-4829-9ab6-412f104ec00b",
   "metadata": {},
   "source": [
    "## Cross Validation - LSx + Point Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L232){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CrossValidationLSx_combined\n",
       "\n",
       ">      CrossValidationLSx_combined (estimatorLSx, cvFolds,\n",
       ">                                   parameterGridLSx:dict,\n",
       ">                                   parameterGridEstimator:dict,\n",
       ">                                   randomSearchLSx:bool=False,\n",
       ">                                   randomSearchEstimator:bool=False,\n",
       ">                                   nIterLSx:int=None, nIterEstimator:int=None,\n",
       ">                                   probs:list=[0.01, 0.02, 0.03, 0.04, 0.05,\n",
       ">                                   0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12,\n",
       ">                                   0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19,\n",
       ">                                   0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26,\n",
       ">                                   0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33,\n",
       ">                                   0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4,\n",
       ">                                   0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47,\n",
       ">                                   0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54,\n",
       ">                                   0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61,\n",
       ">                                   0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68,\n",
       ">                                   0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75,\n",
       ">                                   0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82,\n",
       ">                                   0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89,\n",
       ">                                   0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96,\n",
       ">                                   0.97, 0.98, 0.99], refitPerProb:bool=False,\n",
       ">                                   n_jobs:int=None, random_state:int=None)\n",
       "\n",
       "Class to efficiently tune the `binSize` parameter of all Level-Set based models.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimatorLSx |  |  | A Level-Set based model. |\n",
       "| cvFolds |  |  | An iterable yielding (train, test) splits as arrays of indices. |\n",
       "| parameterGridLSx | dict |  | dict or list of dicts with LSx parameters names (`str`) as keys and distributions<br>or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| parameterGridEstimator | dict |  | dict or list of dicts with parameters names (`str`) of the point predictor as keys<br>and distributions or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| randomSearchLSx | bool | False | Whether to use randomized search or grid search for the LSx parameters. |\n",
       "| randomSearchEstimator | bool | False | Whether to use randomized search or grid search for the point predictor parameters. |\n",
       "| nIterLSx | int | None | Number of parameter settings of the LSx model that are sampled if `randomSearchLSx == True`. <br>LSx parameter settings are usually relatively cheap to evaluate, so all sampled LSx paramater settings<br>are evaluated for each point predictor parameter setting. |\n",
       "| nIterEstimator | int | None | Number of parameter settings of the underlying point predictor that are sampled if <br>`randomSearchEstimator == True`. nIterEstimator trades off runtime vs quality of the solution. |\n",
       "| probs | list | [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99] | iterable of floats between 0 and 1. These determine the p-quantiles being predicted <br>to evaluate performance of each parameter setting. |\n",
       "| refitPerProb | bool | False | If True, for each p-quantile a fitted LSF with best binSize to predict it is returned. <br>Otherwise only one LSF is returned that is best over all probs. |\n",
       "| n_jobs | int | None | number of folds being computed in parallel. |\n",
       "| random_state | int | None | Pseudo random number generator state used for random uniform sampling of parameter candidate values.<br>Pass an int for reproducible output across multiple function calls. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L232){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CrossValidationLSx_combined\n",
       "\n",
       ">      CrossValidationLSx_combined (estimatorLSx, cvFolds,\n",
       ">                                   parameterGridLSx:dict,\n",
       ">                                   parameterGridEstimator:dict,\n",
       ">                                   randomSearchLSx:bool=False,\n",
       ">                                   randomSearchEstimator:bool=False,\n",
       ">                                   nIterLSx:int=None, nIterEstimator:int=None,\n",
       ">                                   probs:list=[0.01, 0.02, 0.03, 0.04, 0.05,\n",
       ">                                   0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12,\n",
       ">                                   0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19,\n",
       ">                                   0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26,\n",
       ">                                   0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33,\n",
       ">                                   0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4,\n",
       ">                                   0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47,\n",
       ">                                   0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54,\n",
       ">                                   0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61,\n",
       ">                                   0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68,\n",
       ">                                   0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75,\n",
       ">                                   0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82,\n",
       ">                                   0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89,\n",
       ">                                   0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96,\n",
       ">                                   0.97, 0.98, 0.99], refitPerProb:bool=False,\n",
       ">                                   n_jobs:int=None, random_state:int=None)\n",
       "\n",
       "Class to efficiently tune the `binSize` parameter of all Level-Set based models.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimatorLSx |  |  | A Level-Set based model. |\n",
       "| cvFolds |  |  | An iterable yielding (train, test) splits as arrays of indices. |\n",
       "| parameterGridLSx | dict |  | dict or list of dicts with LSx parameters names (`str`) as keys and distributions<br>or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| parameterGridEstimator | dict |  | dict or list of dicts with parameters names (`str`) of the point predictor as keys<br>and distributions or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| randomSearchLSx | bool | False | Whether to use randomized search or grid search for the LSx parameters. |\n",
       "| randomSearchEstimator | bool | False | Whether to use randomized search or grid search for the point predictor parameters. |\n",
       "| nIterLSx | int | None | Number of parameter settings of the LSx model that are sampled if `randomSearchLSx == True`. <br>LSx parameter settings are usually relatively cheap to evaluate, so all sampled LSx paramater settings<br>are evaluated for each point predictor parameter setting. |\n",
       "| nIterEstimator | int | None | Number of parameter settings of the underlying point predictor that are sampled if <br>`randomSearchEstimator == True`. nIterEstimator trades off runtime vs quality of the solution. |\n",
       "| probs | list | [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99] | iterable of floats between 0 and 1. These determine the p-quantiles being predicted <br>to evaluate performance of each parameter setting. |\n",
       "| refitPerProb | bool | False | If True, for each p-quantile a fitted LSF with best binSize to predict it is returned. <br>Otherwise only one LSF is returned that is best over all probs. |\n",
       "| n_jobs | int | None | number of folds being computed in parallel. |\n",
       "| random_state | int | None | Pseudo random number generator state used for random uniform sampling of parameter candidate values.<br>Pass an int for reproducible output across multiple function calls. |"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(CrossValidationLSx_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L337){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CrossValidationLSx_combined.fit\n",
       "\n",
       ">      CrossValidationLSx_combined.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | np.ndarray | Feature matrix (has to work with the folds specified via `cvFolds`) |\n",
       "| y | np.ndarray | Target values (has to work with the folds specified via `cvFolds`) |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L337){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CrossValidationLSx_combined.fit\n",
       "\n",
       ">      CrossValidationLSx_combined.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | np.ndarray | Feature matrix (has to work with the folds specified via `cvFolds`) |\n",
       "| y | np.ndarray | Target values (has to work with the folds specified via `cvFolds`) |"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(CrossValidationLSx_combined.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e4c000-976e-40dc-9c4c-e4e3da959668",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# show_doc(CrossValidationLSx_combined.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e48150-d0f2-4699-a6c0-1d6f17918ad7",
   "metadata": {},
   "source": [
    "#### Scores for Single Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L454){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getFoldScore_combined\n",
       "\n",
       ">      getFoldScore_combined (estimatorLSx, parameterGridLSx,\n",
       ">                             parameterGridEstimator, cvFold, probs, X, y)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L454){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getFoldScore_combined\n",
       "\n",
       ">      getFoldScore_combined (estimatorLSx, parameterGridLSx,\n",
       ">                             parameterGridEstimator, cvFold, probs, X, y)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(getFoldScore_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fada52-3351-4323-b0f0-d529a995de89",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1cabde-9765-4adc-8e8c-381ab50a9ce2",
   "metadata": {},
   "source": [
    "### Get Cost Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L532){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getCostRatio\n",
       "\n",
       ">      getCostRatio (decisions, decisionsSAA, yTest, prob)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L532){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getCostRatio\n",
       "\n",
       ">      getCostRatio (decisions, decisionsSAA, yTest, prob)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(getCostRatio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a628cfb-028a-4d7e-ae23-5e459995d6e3",
   "metadata": {},
   "source": [
    "### Grouped Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L570){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### groupedTimeSeriesSplit\n",
       "\n",
       ">      groupedTimeSeriesSplit (data, kFolds, testLength, groupFeature,\n",
       ">                              timeFeature)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L570){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### groupedTimeSeriesSplit\n",
       "\n",
       ">      groupedTimeSeriesSplit (data, kFolds, testLength, groupFeature,\n",
       ">                              timeFeature)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(groupedTimeSeriesSplit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f92782a-5fef-40fa-a501-01b0f5e99186",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e77c34-ca94-4dd9-9d81-b276a0b64617",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dddex",
   "language": "python",
   "name": "dddex"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
