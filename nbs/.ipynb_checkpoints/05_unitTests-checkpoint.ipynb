{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d423b3f1-62e8-40b8-83e9-c4efbc9a57ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import isclose\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from dddex.levelSetKDEx import *\n",
    "from dddex.wSAA import *\n",
    "from dddex.loadData import *\n",
    "from dddex.utils import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec54c1d-b98d-4ed5-8aa0-8ca47d772340",
   "metadata": {},
   "source": [
    "## SAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc638613-f25d-44d6-8047-edbbb8a7ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAA = SampleAverageApproximation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57c64817-18ae-4361-ad93-f33858f6417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAA.fit(y = np.arange(100))\n",
    "weightsData = SAA.getWeights(outputType = 'onlyPositiveWeights')\n",
    "\n",
    "test_eq(len(weightsData), 1)\n",
    "test_eq(weightsData[0][0], np.repeat(0.01, 100))\n",
    "test_eq(weightsData[0][1], np.arange(100))\n",
    "\n",
    "weightsData = SAA.getWeights(X = np.identity(10))\n",
    "test_eq(len(weightsData), 10)\n",
    "\n",
    "for i in range(10):\n",
    "    assert np.array_equal(weightsData[i][0], weightsData[0][0])\n",
    "    assert np.array_equal(weightsData[i][1], weightsData[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8552d1d-1e4d-49ca-9d51-b4aa1653ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAA.fit(y = np.repeat(np.arange(10), 2))\n",
    "weightsData = SAA.getWeights(outputType = 'onlyPositiveWeights')\n",
    "\n",
    "test_eq(len(weightsData), 1)\n",
    "test_eq(weightsData[0][0], np.repeat(0.05, 20))\n",
    "test_eq(weightsData[0][1], np.arange(20))\n",
    "\n",
    "weightsData = SAA.getWeights(X = np.identity(10))\n",
    "test_eq(len(weightsData), 10)\n",
    "\n",
    "for i in range(10):\n",
    "    assert np.array_equal(weightsData[i][0], weightsData[0][0])\n",
    "    assert np.array_equal(weightsData[i][1], weightsData[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114de996-a4fe-43f9-998e-38796e1a4412",
   "metadata": {},
   "source": [
    "## Loading Yaz Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d56af3-c742-433f-97c1-9d19e716a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "testDays = 182\n",
    "daysToCut = 300\n",
    "\n",
    "data, XTrain, yTrain, XTest, yTest = loadDataYaz(testDays = testDays,\n",
    "                                                 daysToCut = 0,\n",
    "                                                 returnXY = True)\n",
    "scalingList = data.loc[data['label'] == 'test', 'scalingValue'].tolist()\n",
    "\n",
    "# data2, XTrain2, yTrain2, XTest2, yTest2 = loadDataYaz(testDays = testDays,\n",
    "#                                                       daysToCut = daysToCut,\n",
    "#                                                       returnXY = True)\n",
    "\n",
    "# data3 = loadDataYaz(testDays = testDays,\n",
    "#                     daysToCut = 300,\n",
    "#                     returnXY = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25690c93-8807-4743-b308-fefc811e6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "assert XTest.shape[0] == len(data['id'].unique()) * testDays \n",
    "assert yTest.shape[0] == len(data['id'].unique()) * testDays\n",
    "\n",
    "assert XTrain.shape[0] == data.shape[0] - len(data['id'].unique()) * testDays\n",
    "assert yTrain.shape[0] == data.shape[0] - len(data['id'].unique()) * testDays\n",
    "\n",
    "#---\n",
    "\n",
    "# assert XTest2.shape[0] == len(data2['id'].unique()) * testDays\n",
    "# assert yTest2.shape[0] == len(data2['id'].unique()) * testDays\n",
    "\n",
    "# assert data2.shape[0] == data.shape[0] - len(data['id'].unique()) * daysToCut\n",
    "# assert XTrain2.shape[0] == data.shape[0] - len(data['id'].unique()) * (daysToCut + testDays)\n",
    "# assert yTrain2.shape[0] == data.shape[0] - len(data['id'].unique()) * (daysToCut + testDays)\n",
    "\n",
    "# #---\n",
    "\n",
    "# test_eq(data2, data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac897f-05f7-4086-9694-4d18265d7e63",
   "metadata": {},
   "source": [
    "## Grouped Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800eb785-5e3b-4af7-8a45-363d7618eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "\n",
    "nIDs = len(data['id'].unique())\n",
    "kFolds = 4\n",
    "testLength = 7\n",
    "timeFeature = 'dayIndex'\n",
    "groupFeature = 'id'\n",
    "\n",
    "cvFolds = groupedTimeSeriesSplit(data = data, \n",
    "                                 kFolds = kFolds, \n",
    "                                 testLength = testLength, \n",
    "                                 groupFeature = groupFeature, \n",
    "                                 timeFeature = timeFeature)\n",
    "\n",
    "test_eq(len(cvFolds), 4)\n",
    "\n",
    "for i in range(len(cvFolds)):\n",
    "    fold = cvFolds[i]\n",
    "    \n",
    "    test_eq(len(fold[1]), testLength * nIDs)\n",
    "    test_eq(len(fold[0]), (data.shape[0] - nIDs * testLength * (kFolds - i - 1)) - len(fold[1]))\n",
    "    test_eq(len(set(fold[0]) & set(fold[1])), 0)\n",
    "    \n",
    "    dataTrainToCheck = data.iloc[fold[0]]\n",
    "    dataTestToCheck = data.iloc[fold[1]]\n",
    "    \n",
    "    timeMaxGroupTrain = dataTrainToCheck.groupby(groupFeature)[timeFeature].max()\n",
    "    timeMinGroupTest = dataTestToCheck.groupby(groupFeature)[timeFeature].min()\n",
    "    \n",
    "    assert (timeMaxGroupTrain < timeMinGroupTest).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c77a0f-a44a-4e74-b061-7a015aa4f240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(max_depth=4, n_jobs=1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "LGBM = LGBMRegressor(max_depth = 4, n_jobs = 1)\n",
    "LGBM.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8f9421-8c1d-4ce4-91f7-233efc5a4c4b",
   "metadata": {},
   "source": [
    "## Bin Size Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a821af90-5aa5-41d1-8903-73f145e84ffb",
   "metadata": {},
   "source": [
    "### LSx Bin-Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9bd45b-5812-470e-9843-2681a9a32061",
   "metadata": {},
   "source": [
    "#### Normal Weights, no refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a8f4a6-e341-4826-895a-8a6c40dc179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrainPred = LGBM.predict(XTrain)\n",
    "yTestPred = LGBM.predict(XTest)\n",
    "\n",
    "LSKDEx = LevelSetKDEx(estimator = LGBM,\n",
    "                      weightsByDistance = False)\n",
    "\n",
    "kFolds = 2\n",
    "probs = [0.001, 0.01, 0.1, 0.5, 0.9, 0.99, 0.999]\n",
    "binSizeGrid = [1, 100, 1000, 10000]\n",
    "\n",
    "dataTrain = data[data['label'] == 'train']\n",
    "\n",
    "cvFolds = groupedTimeSeriesSplit(data = dataTrain, \n",
    "                                 kFolds = kFolds, \n",
    "                                 testLength = 28, \n",
    "                                 groupFeature = 'id', \n",
    "                                 timeFeature = 'dayIndex')\n",
    "\n",
    "CV = binSizeCV(estimatorLSx = LSKDEx, \n",
    "               cvFolds = cvFolds, \n",
    "               binSizeGrid = binSizeGrid,\n",
    "               probs = probs,\n",
    "               refitPerProb = False,\n",
    "               n_jobs = None)\n",
    "\n",
    "CV.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a361aa6-7603-444b-b796-84fb939db348",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(CV.cvFolds, cvFolds)\n",
    "test_eq(CV.probs, probs)\n",
    "assert not CV.refitPerProb\n",
    "\n",
    "#---\n",
    "\n",
    "# Stored binSize-Grid\n",
    "binSizesFiltered = [binSize for binSize in CV.binSizeGrid if binSize <= len(cvFolds[0][0])]\n",
    "test_eq(CV.binSizeGrid, binSizesFiltered)\n",
    "\n",
    "#---\n",
    "\n",
    "# Estimator the same? Note: No __eq__ method is implemented for LGBMRegressor. \n",
    "# LGBM == LGBM2 consequently only returns true when both names are refering to \n",
    "# the exact same object in memory, which shouldn't be the case here because we \n",
    "# create a deepcopy of LGBM when initiating LS_KDEx. The point estimators\n",
    "# should be copies of each other though.\n",
    "assert CV.estimatorLSx.estimator is not LGBM\n",
    "test_eq(CV.estimatorLSx.estimator.predict(XTrain), LGBM.predict(XTrain))\n",
    "test_eq(CV.estimatorLSx.estimator.predict(XTest), LGBM.predict(XTest))\n",
    "\n",
    "#---\n",
    "\n",
    "# CV results raw\n",
    "assert isinstance(CV.cv_results_raw, list)\n",
    "test_eq(len(CV.cv_results_raw), kFolds)\n",
    "\n",
    "for resDf in CV.cv_results_raw:\n",
    "    test_eq(resDf.shape, (len(binSizesFiltered), len(probs)))\n",
    "    test_eq(resDf.index, binSizesFiltered)\n",
    "    test_eq(resDf.columns, probs)\n",
    "    assert np.all(resDf >= 0)\n",
    "    \n",
    "#---\n",
    "\n",
    "# CV results aggregated\n",
    "meanCostMatrix = 0\n",
    "for i in range(0, kFolds, 1):\n",
    "    meanCostMatrix += CV.cv_results_raw[i]\n",
    "    \n",
    "meanCostMatrix = meanCostMatrix / kFolds\n",
    "\n",
    "assert np.allclose(CV.cv_results, meanCostMatrix)\n",
    "\n",
    "test_eq(CV.cv_results.shape, (len(binSizesFiltered), len(probs)))\n",
    "test_eq(CV.cv_results.index, binSizesFiltered)\n",
    "test_eq(CV.cv_results.columns, probs)\n",
    "assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# best bin size\n",
    "averageCostsPerBin = CV.cv_results.mean(axis = 1)\n",
    "bestBinSizeTest = CV.cv_results.index[np.argmin(averageCostsPerBin)]\n",
    "test_eq(CV.bestBinSize, bestBinSizeTest)\n",
    "assert CV.bestBinSize in binSizeGrid\n",
    "\n",
    "#---\n",
    "\n",
    "# best bin size per prob\n",
    "test_eq(len(CV.bestBinSize_perProb), len(probs))\n",
    "assert [binSize in binSizeGrid for binSize in CV.bestBinSize_perProb]\n",
    "\n",
    "bestBinSizePerProbTest = CV.cv_results.idxmin(axis = 0)\n",
    "test_eq(CV.bestBinSize_perProb, bestBinSizePerProbTest)\n",
    "\n",
    "#---\n",
    "\n",
    "# refitted LSx object\n",
    "assert isinstance(CV.bestEstimatorLSx, LevelSetKDEx)\n",
    "test_eq(CV.bestEstimatorLSx.binSize, bestBinSizeTest)\n",
    "\n",
    "# Estimator the same? (Note: No __eq__ method is implemented for LGBMRegressor. \n",
    "# LGBM == LGBM2 consequently only returns true when both names are refering to \n",
    "# the exact same object in memory, which is not (!!) the case here)\n",
    "assert CV.bestEstimatorLSx.estimator is not LGBM\n",
    "test_eq(CV.bestEstimatorLSx.estimator.predict(XTrain), LGBM.predict(XTrain))\n",
    "test_eq(CV.bestEstimatorLSx.estimator.predict(XTest), LGBM.predict(XTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65d4d8e-9632-49d8-9d16-e5d5d03eb1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = LevelSetKDEx(estimator = LGBM)\n",
    "testCV = binSizeCV(estimatorLSx = test,\n",
    "                   cvFolds = cvFolds,\n",
    "                   binSizeGrid = [10, 100])\n",
    "\n",
    "testCV.fit(XTrain, yTrain)\n",
    "\n",
    "testCV.estimatorLSx.estimator == LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad267426-a8ab-4c1a-813f-73506ec71ff0",
   "metadata": {},
   "source": [
    "#### Normal Weights, refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c804f50-c5b5-4c65-b765-3d5a4c7bdf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSKDEx = LevelSetKDEx(estimator = LGBM,\n",
    "                weightsByDistance = False)\n",
    "\n",
    "kFolds = 2\n",
    "probs = [0.001, 0.01, 0.1, 0.5, 0.9, 0.99, 0.999]\n",
    "binSizeGrid = [1, 100, 1000, 10000]\n",
    "\n",
    "dataTrain = data[data['label'] == 'train']\n",
    "\n",
    "cvFolds = groupedTimeSeriesSplit(data = dataTrain, \n",
    "                                 kFolds = kFolds, \n",
    "                                 testLength = 28, \n",
    "                                 groupFeature = 'id', \n",
    "                                 timeFeature = 'dayIndex')\n",
    "\n",
    "CV = binSizeCV(estimatorLSx = LSKDEx, \n",
    "               cvFolds = cvFolds, \n",
    "               binSizeGrid = binSizeGrid,\n",
    "               probs = probs,\n",
    "               refitPerProb = True,\n",
    "               n_jobs = None)\n",
    "\n",
    "CV.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3134136-bccc-44ff-9581-af0463f9b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(CV.cvFolds, cvFolds)\n",
    "test_eq(CV.probs, probs)\n",
    "assert CV.refitPerProb\n",
    "\n",
    "#---\n",
    "\n",
    "# Stored binSize-Grid\n",
    "binSizesFiltered = [binSize for binSize in CV.binSizeGrid if binSize <= len(cvFolds[0][0])]\n",
    "test_eq(CV.binSizeGrid, binSizesFiltered)\n",
    "\n",
    "#---\n",
    "\n",
    "# Estimator the same? Note: No __eq__ method is implemented for LGBMRegressor. \n",
    "# LGBM == LGBM2 consequently only returns true when both names are refering to \n",
    "# the exact same object in memory, which shouldn't be the case here because we \n",
    "# create a deepcopy of LGBM when initiating LS_KDEx. The point estimators\n",
    "# should be copies of each other though.\n",
    "assert CV.estimatorLSx.estimator is not LGBM\n",
    "test_eq(CV.estimatorLSx.estimator.predict(XTrain), LGBM.predict(XTrain))\n",
    "test_eq(CV.estimatorLSx.estimator.predict(XTest), LGBM.predict(XTest))\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Raw\n",
    "assert isinstance(CV.cv_results_raw, list)\n",
    "test_eq(len(CV.cv_results_raw), kFolds)\n",
    "\n",
    "for resDf in CV.cv_results_raw:\n",
    "    test_eq(resDf.shape, (len(binSizesFiltered), len(probs)))\n",
    "    test_eq(resDf.index, binSizesFiltered)\n",
    "    test_eq(resDf.columns, probs)\n",
    "    assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Aggregated\n",
    "meanCostMatrix = 0\n",
    "for i in range(0, kFolds, 1):\n",
    "    meanCostMatrix += CV.cv_results_raw[i]\n",
    "    \n",
    "meanCostMatrix = meanCostMatrix / kFolds\n",
    "\n",
    "assert np.allclose(CV.cv_results, meanCostMatrix)\n",
    "\n",
    "test_eq(CV.cv_results.shape, (len(binSizesFiltered), len(probs)))\n",
    "test_eq(CV.cv_results.index, binSizesFiltered)\n",
    "test_eq(CV.cv_results.columns, probs)\n",
    "assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size\n",
    "averageCostsPerBin = CV.cv_results.mean(axis = 1)\n",
    "bestBinSizeTest = CV.cv_results.index[np.argmin(averageCostsPerBin)]\n",
    "test_eq(CV.bestBinSize, bestBinSizeTest)\n",
    "assert CV.bestBinSize in binSizeGrid\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size per prob\n",
    "test_eq(len(CV.bestBinSize_perProb), len(probs))\n",
    "assert [binSize in binSizeGrid for binSize in CV.bestBinSize_perProb]\n",
    "\n",
    "bestBinSizePerProbTest = CV.cv_results.idxmin(axis = 0)\n",
    "test_eq(CV.bestBinSize_perProb, bestBinSizePerProbTest)\n",
    "\n",
    "#---\n",
    "\n",
    "# refitted LSx objects\n",
    "assert isinstance(CV.bestEstimatorLSx, dict)\n",
    "test_eq(list(CV.bestEstimatorLSx.keys()), probs)\n",
    "\n",
    "for prob, LSx in CV.bestEstimatorLSx.items():\n",
    "    assert isinstance(LSx, LevelSetKDEx)\n",
    "    test_eq(LSx.binSize, bestBinSizePerProbTest.loc[prob])\n",
    "    \n",
    "    # Estimator the same? (Note: No __eq__ method is implemented for LGBMRegressor. \n",
    "    # LGBM == LGBM2 consequently only returns true when both names are refering to \n",
    "    # the exact same object in memory, which is not (!!) the case here)\n",
    "    assert LSx.estimator is not LGBM\n",
    "    test_eq(LSx.estimator.predict(XTrain), LGBM.predict(XTrain))\n",
    "    test_eq(LSx.estimator.predict(XTest), LGBM.predict(XTest))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1af564-fa1b-46bf-9f3b-0094f8df9df2",
   "metadata": {},
   "source": [
    "#### Distance Weights, no refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1634a77-cb75-4456-bdb7-5b9326e9e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSKDEx = LevelSetKDEx(estimator = LGBM,\n",
    "                weightsByDistance = True)\n",
    "\n",
    "kFolds = 2\n",
    "probs = [0.001, 0.01, 0.1, 0.5, 0.9, 0.99, 0.999]\n",
    "binSizeGrid = [1, 100, 1000, 10000]\n",
    "LSF_type = 'LSF'\n",
    "\n",
    "dataTrain = data[data['label'] == 'train']\n",
    "\n",
    "cvFolds = groupedTimeSeriesSplit(data = dataTrain, \n",
    "                                 kFolds = kFolds, \n",
    "                                 testLength = 28, \n",
    "                                 groupFeature = 'id', \n",
    "                                 timeFeature = 'dayIndex')\n",
    "\n",
    "CVDistance = binSizeCV(estimatorLSx = LSKDEx, \n",
    "                       cvFolds = cvFolds, \n",
    "                       binSizeGrid = binSizeGrid,\n",
    "                       probs = probs,\n",
    "                       refitPerProb = False,\n",
    "                       n_jobs = None)\n",
    "\n",
    "CVDistance.fit(X = XTrain, y = yTrain)\n",
    "\n",
    "#---\n",
    "\n",
    "LSKDEx.set_params(weightsByDistance = False)\n",
    "\n",
    "CVStandard = binSizeCV(estimatorLSx = LSKDEx, \n",
    "                       cvFolds = cvFolds, \n",
    "                       binSizeGrid = binSizeGrid,\n",
    "                       probs = probs,\n",
    "                       refitPerProb = False,\n",
    "                       n_jobs = None)\n",
    "\n",
    "CVStandard.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fe4ad1-9315-4e2a-96cf-1b448c1e2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(CVDistance.cvFolds, cvFolds)\n",
    "test_eq(CVDistance.probs, probs)\n",
    "assert not CVDistance.refitPerProb\n",
    "\n",
    "#---\n",
    "\n",
    "# Check if CV Results are different compared to the standard case of generating weights\n",
    "# This is supposed to check whether we really used the attribute 'weightsByDistance'\n",
    "# in the predict function inside scorePerFold\n",
    "assert not np.allclose(CVDistance.cv_results, CVStandard.cv_results)\n",
    "\n",
    "#---\n",
    "\n",
    "# Stored binSize-Grid\n",
    "binSizesFiltered = [binSize for binSize in CVDistance.binSizeGrid if binSize <= len(cvFolds[0][0])]\n",
    "test_eq(CVDistance.binSizeGrid, binSizesFiltered)\n",
    "\n",
    "#---\n",
    "\n",
    "# Estimator the same? Note: No __eq__ method is implemented for LGBMRegressor. \n",
    "# LGBM == LGBM2 consequently only returns true when both names are refering to \n",
    "# the exact same object in memory, which shouldn't be the case here because we \n",
    "# create a deepcopy of LGBM when initiating LS_KDEx. The point estimators\n",
    "# should be copies of each other though.\n",
    "assert CV.estimatorLSx.estimator is not LGBM\n",
    "test_eq(CV.estimatorLSx.estimator.predict(XTrain), LGBM.predict(XTrain))\n",
    "test_eq(CV.estimatorLSx.estimator.predict(XTest), LGBM.predict(XTest))\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Raw\n",
    "assert isinstance(CVDistance.cv_results_raw, list)\n",
    "test_eq(len(CVDistance.cv_results_raw), kFolds)\n",
    "\n",
    "for resDf in CVDistance.cv_results_raw:\n",
    "    test_eq(resDf.shape, (len(binSizesFiltered), len(probs)))\n",
    "    test_eq(resDf.index, binSizesFiltered)\n",
    "    test_eq(resDf.columns, probs)\n",
    "    assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Aggregated\n",
    "meanCostMatrix = 0\n",
    "for i in range(0, kFolds, 1):\n",
    "    meanCostMatrix += CVDistance.cv_results_raw[i]\n",
    "    \n",
    "meanCostMatrix = meanCostMatrix / kFolds\n",
    "\n",
    "assert np.allclose(CVDistance.cv_results, meanCostMatrix)\n",
    "\n",
    "test_eq(CVDistance.cv_results.shape, (len(binSizesFiltered), len(probs)))\n",
    "test_eq(CVDistance.cv_results.index, binSizesFiltered)\n",
    "test_eq(CVDistance.cv_results.columns, probs)\n",
    "assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size\n",
    "averageCostsPerBin = CVDistance.cv_results.mean(axis = 1)\n",
    "bestBinSizeTest = CVDistance.cv_results.index[np.argmin(averageCostsPerBin)]\n",
    "test_eq(CVDistance.bestBinSize, bestBinSizeTest)\n",
    "assert CVDistance.bestBinSize in binSizeGrid\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size per prob\n",
    "test_eq(len(CVDistance.bestBinSize_perProb), len(probs))\n",
    "assert [binSize in binSizeGrid for binSize in CVDistance.bestBinSize_perProb]\n",
    "\n",
    "bestBinSizePerProbTest = CVDistance.cv_results.idxmin(axis = 0)\n",
    "test_eq(CVDistance.bestBinSize_perProb, bestBinSizePerProbTest)\n",
    "\n",
    "#---\n",
    "\n",
    "# refitted LSx object\n",
    "assert isinstance(CVDistance.bestEstimatorLSx, LevelSetKDEx)\n",
    "test_eq(CVDistance.bestEstimatorLSx.binSize, bestBinSizeTest)\n",
    "\n",
    "# Estimator the same? (Note: No __eq__ method is implemented for LGBMRegressor. \n",
    "# LGBM == LGBM2 consequently only returns true when both names are refering to \n",
    "# the exact same object in memory, which is not (!!) the case here)\n",
    "assert CVDistance.bestEstimatorLSx.estimator is not LGBM\n",
    "test_eq(CVDistance.bestEstimatorLSx.estimator.predict(XTrain), LGBM.predict(XTrain))\n",
    "test_eq(CVDistance.bestEstimatorLSx.estimator.predict(XTest), LGBM.predict(XTest))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c16c86a-519c-49ad-8fe8-f44cc2c056cd",
   "metadata": {},
   "source": [
    "#### Distance Weights, refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92048279-9c4f-4c67-8a9f-3adda2e494ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSKDEx = LevelSetKDEx(estimator = LGBM,\n",
    "                      weightsByDistance = True)\n",
    "\n",
    "kFolds = 2\n",
    "probs = [0.001, 0.01, 0.1, 0.5, 0.9, 0.99, 0.999]\n",
    "binSizeGrid = [1, 100, 1000, 10000]\n",
    "LSF_type = 'LSF'\n",
    "\n",
    "dataTrain = data[data['label'] == 'train']\n",
    "\n",
    "cvFolds = groupedTimeSeriesSplit(data = dataTrain, \n",
    "                                 kFolds = kFolds, \n",
    "                                 testLength = 28, \n",
    "                                 groupFeature = 'id', \n",
    "                                 timeFeature = 'dayIndex')\n",
    "\n",
    "CVDistance = binSizeCV(estimatorLSx = LSKDEx, \n",
    "                       cvFolds = cvFolds, \n",
    "                       binSizeGrid = binSizeGrid,\n",
    "                       probs = probs,\n",
    "                       refitPerProb = True,\n",
    "                       n_jobs = None)\n",
    "\n",
    "CVDistance.fit(X = XTrain, y = yTrain)\n",
    "\n",
    "#---\n",
    "\n",
    "LSKDEx.set_params(weightsByDistance = False)\n",
    "\n",
    "CVStandard = binSizeCV(estimatorLSx = LSKDEx, \n",
    "                       cvFolds = cvFolds, \n",
    "                       binSizeGrid = binSizeGrid,\n",
    "                       probs = probs,\n",
    "                       refitPerProb = True,\n",
    "                       n_jobs = None)\n",
    "\n",
    "CVStandard.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e97938-9c42-4fdc-a5c5-21cd07bd90ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(CVDistance.cvFolds, cvFolds)\n",
    "test_eq(CVDistance.probs, probs)\n",
    "assert CVDistance.refitPerProb\n",
    "\n",
    "#---\n",
    "\n",
    "# Check if CV Results are different compared to the standard case of generating weights\n",
    "# This is supposed to check whether we really used the attribute 'weightsByDistance'\n",
    "# in the predict function inside scorePerFold\n",
    "assert not np.allclose(CVDistance.cv_results, CVStandard.cv_results)\n",
    "\n",
    "#---\n",
    "\n",
    "# Stored binSize-Grid\n",
    "binSizesFiltered = [binSize for binSize in CVDistance.binSizeGrid if binSize <= len(cvFolds[0][0])]\n",
    "test_eq(CVDistance.binSizeGrid, binSizesFiltered)\n",
    "\n",
    "#---\n",
    "\n",
    "# Estimator the same? Note: No __eq__ method is implemented for LGBMRegressor. \n",
    "# LGBM == LGBM2 consequently only returns true when both names are refering to \n",
    "# the exact same object in memory, which shouldn't be the case here because we \n",
    "# create a deepcopy of LGBM when initiating LS_KDEx. The point estimators\n",
    "# should be copies of each other though.\n",
    "assert CV.estimatorLSx.estimator is not LGBM\n",
    "test_eq(CV.estimatorLSx.estimator.predict(XTrain), LGBM.predict(XTrain))\n",
    "test_eq(CV.estimatorLSx.estimator.predict(XTest), LGBM.predict(XTest))\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Raw\n",
    "assert isinstance(CVDistance.cv_results_raw, list)\n",
    "test_eq(len(CVDistance.cv_results_raw), kFolds)\n",
    "\n",
    "for resDf in CVDistance.cv_results_raw:\n",
    "    test_eq(resDf.shape, (len(binSizesFiltered), len(probs)))\n",
    "    test_eq(resDf.index, binSizesFiltered)\n",
    "    test_eq(resDf.columns, probs)\n",
    "    assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Aggregated\n",
    "meanCostMatrix = 0\n",
    "for i in range(0, kFolds, 1):\n",
    "    meanCostMatrix += CVDistance.cv_results_raw[i]\n",
    "    \n",
    "meanCostMatrix = meanCostMatrix / kFolds\n",
    "\n",
    "assert np.allclose(CVDistance.cv_results, meanCostMatrix)\n",
    "\n",
    "test_eq(CVDistance.cv_results.shape, (len(binSizesFiltered), len(probs)))\n",
    "test_eq(CVDistance.cv_results.index, binSizesFiltered)\n",
    "test_eq(CVDistance.cv_results.columns, probs)\n",
    "assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size\n",
    "averageCostsPerBin = CVDistance.cv_results.mean(axis = 1)\n",
    "bestBinSizeTest = CVDistance.cv_results.index[np.argmin(averageCostsPerBin)]\n",
    "test_eq(CVDistance.bestBinSize, bestBinSizeTest)\n",
    "assert CVDistance.bestBinSize in binSizeGrid\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size per prob\n",
    "test_eq(len(CVDistance.bestBinSize_perProb), len(probs))\n",
    "assert [binSize in binSizeGrid for binSize in CVDistance.bestBinSize_perProb]\n",
    "\n",
    "bestBinSizePerProbTest = CVDistance.cv_results.idxmin(axis = 0)\n",
    "test_eq(CVDistance.bestBinSize_perProb, bestBinSizePerProbTest)\n",
    "\n",
    "#---\n",
    "\n",
    "# refitted LSx objects\n",
    "assert isinstance(CVDistance.bestEstimatorLSx, dict)\n",
    "test_eq(list(CVDistance.bestEstimatorLSx.keys()), probs)\n",
    "\n",
    "for prob, LSx in CVDistance.bestEstimatorLSx.items():\n",
    "    assert isinstance(LSx, LevelSetKDEx)\n",
    "    test_eq(LSx.binSize, bestBinSizePerProbTest.loc[prob])\n",
    "    \n",
    "    # Estimator the same? (Note: No __eq__ method is implemented for LGBMRegressor. \n",
    "    # LGBM == LGBM2 consequently only returns true when both names are refering to \n",
    "    # the exact same object in memory, which is not (!!) the case here)\n",
    "    assert LSx.estimator is not LGBM\n",
    "    test_eq(LSx.estimator.predict(XTrain), LGBM.predict(XTrain))\n",
    "    test_eq(LSx.estimator.predict(XTest), LGBM.predict(XTest))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecac0f2b-6327-4462-b634-24aa2a62f8ca",
   "metadata": {},
   "source": [
    "### LSx kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea77988-a469-4c24-90dc-2221b75b056b",
   "metadata": {},
   "source": [
    "#### Normal Weights, refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f748d9e-3417-4f0d-8bf8-92657210acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSKDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM,\n",
    "                              weightsByDistance = False)\n",
    "\n",
    "kFolds = 3\n",
    "probs = [0.005, 0.2, 0.4, 0.6, 0.78,0.99999]\n",
    "binSizeGrid = [1, 100, 1000, 10000, 2000000]\n",
    "\n",
    "dataTrain = data[data['label'] == 'train']\n",
    "\n",
    "cvFolds = groupedTimeSeriesSplit(data = dataTrain, \n",
    "                                 kFolds = kFolds, \n",
    "                                 testLength = 7, \n",
    "                                 groupFeature = 'id', \n",
    "                                 timeFeature = 'dayIndex')\n",
    "\n",
    "CV = binSizeCV(estimatorLSx = LSKDEx_kNN, \n",
    "               cvFolds = cvFolds, \n",
    "               binSizeGrid = binSizeGrid, \n",
    "               probs = probs,\n",
    "               refitPerProb = True,\n",
    "               n_jobs = 2)\n",
    "\n",
    "CV.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a382e-462e-4627-ab69-157cea29ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(CV.cvFolds, cvFolds)\n",
    "test_eq(CV.probs, probs)\n",
    "assert CV.refitPerProb\n",
    "\n",
    "#---\n",
    "\n",
    "# Stored binSize-Grid\n",
    "binSizesFiltered = [binSize for binSize in CV.binSizeGrid if binSize <= len(cvFolds[0][0])]\n",
    "test_eq(CV.binSizeGrid, binSizesFiltered)\n",
    "\n",
    "#---\n",
    "\n",
    "# Estimator the same? Note: No __eq__ method is implemented for LGBMRegressor. \n",
    "# LGBM == LGBM2 consequently only returns true when both names are refering to \n",
    "# the exact same object in memory, which shouldn't be the case here because we \n",
    "# create a deepcopy of LGBM when initiating LS_KDEx. The point estimators\n",
    "# should be copies of each other though.\n",
    "assert CV.estimatorLSx.estimator is not LGBM\n",
    "test_eq(CV.estimatorLSx.estimator.predict(XTrain), LGBM.predict(XTrain))\n",
    "test_eq(CV.estimatorLSx.estimator.predict(XTest), LGBM.predict(XTest))\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Raw\n",
    "assert isinstance(CV.cv_results_raw, list)\n",
    "test_eq(len(CV.cv_results_raw), kFolds)\n",
    "\n",
    "for resDf in CV.cv_results_raw:\n",
    "    test_eq(resDf.shape, (len(binSizesFiltered), len(probs)))\n",
    "    test_eq(resDf.index, binSizesFiltered)\n",
    "    test_eq(resDf.columns, probs)\n",
    "    assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Aggregated\n",
    "meanCostMatrix = 0\n",
    "for i in range(0, kFolds, 1):\n",
    "    meanCostMatrix += CV.cv_results_raw[i]\n",
    "    \n",
    "meanCostMatrix = meanCostMatrix / kFolds\n",
    "\n",
    "assert np.allclose(CV.cv_results, meanCostMatrix)\n",
    "\n",
    "test_eq(CV.cv_results.shape, (len(binSizesFiltered), len(probs)))\n",
    "test_eq(CV.cv_results.index, binSizesFiltered)\n",
    "test_eq(CV.cv_results.columns, probs)\n",
    "assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size\n",
    "averageCostsPerBin = CV.cv_results.mean(axis = 1)\n",
    "bestBinSizeTest = CV.cv_results.index[np.argmin(averageCostsPerBin)]\n",
    "test_eq(CV.bestBinSize, bestBinSizeTest)\n",
    "assert CV.bestBinSize in binSizeGrid\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size per prob\n",
    "test_eq(len(CV.bestBinSize_perProb), len(probs))\n",
    "assert [binSize in binSizeGrid for binSize in CV.bestBinSize_perProb]\n",
    "\n",
    "bestBinSizePerProbTest = CV.cv_results.idxmin(axis = 0)\n",
    "test_eq(CV.bestBinSize_perProb, bestBinSizePerProbTest)\n",
    "\n",
    "#---\n",
    "\n",
    "# refitted LSx objects\n",
    "assert isinstance(CV.bestEstimatorLSx, dict)\n",
    "test_eq(list(CV.bestEstimatorLSx.keys()), probs)\n",
    "\n",
    "for prob, LSx in CV.bestEstimatorLSx.items():\n",
    "    assert isinstance(LSx, LevelSetKDEx_kNN)\n",
    "    test_eq(LSx.binSize, bestBinSizePerProbTest.loc[prob])\n",
    "    \n",
    "    # Estimator the same? (Note: No __eq__ method is implemented for LGBMRegressor. \n",
    "    # LGBM == LGBM2 consequently only returns true when both names are refering to \n",
    "    # the exact same object in memory, which is not (!!) the case here)\n",
    "    assert LSx.estimator is not LGBM\n",
    "    test_eq(LSx.estimator.predict(XTrain), LGBM.predict(XTrain))\n",
    "    test_eq(LSx.estimator.predict(XTest), LGBM.predict(XTest))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524f0da-d4da-49da-8466-d4bd78ebfa9d",
   "metadata": {},
   "source": [
    "#### Distance Weights, refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3fe671-5c09-44ac-9e0c-6e85b791182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSKDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM,\n",
    "                              weightsByDistance = True)\n",
    "\n",
    "kFolds = 3\n",
    "probs = [0.005, 0.2, 0.4, 0.6, 0.78,0.99999]\n",
    "binSizeGrid = [1, 100, 1000, 10000, 2000000]\n",
    "\n",
    "dataTrain = data[data['label'] == 'train']\n",
    "\n",
    "cvFolds = groupedTimeSeriesSplit(data = dataTrain, \n",
    "                                 kFolds = kFolds, \n",
    "                                 testLength = 7, \n",
    "                                 groupFeature = 'id', \n",
    "                                 timeFeature = 'dayIndex')\n",
    "\n",
    "CVDistance = binSizeCV(estimatorLSx = LSKDEx_kNN, \n",
    "                       cvFolds = cvFolds, \n",
    "                       binSizeGrid = binSizeGrid, \n",
    "                       probs = probs,\n",
    "                       refitPerProb = True,\n",
    "                       n_jobs = 2)\n",
    "\n",
    "CVDistance.fit(X = XTrain, y = yTrain)\n",
    "\n",
    "#---\n",
    "\n",
    "LSKDEx_kNN.set_params(weightsByDistance = False)\n",
    "\n",
    "CVStandard = binSizeCV(estimatorLSx = LSKDEx_kNN, \n",
    "                       cvFolds = cvFolds, \n",
    "                       binSizeGrid = binSizeGrid,\n",
    "                       probs = probs,\n",
    "                       refitPerProb = True,\n",
    "                       n_jobs = None)\n",
    "\n",
    "CVStandard.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817c2d2-6945-459c-891e-01e1c1fa28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(CVDistance.cvFolds, cvFolds)\n",
    "test_eq(CVDistance.probs, probs)\n",
    "assert CVDistance.refitPerProb\n",
    "\n",
    "#---\n",
    "\n",
    "# Check if CV Results are different compared to the standard case of generating weights\n",
    "# This is supposed to check whether we really used the attribute 'weightsByDistance'\n",
    "# in the predict function inside scorePerFold\n",
    "assert not np.allclose(CVDistance.cv_results, CVStandard.cv_results)\n",
    "\n",
    "#---\n",
    "\n",
    "# Stored binSize-Grid\n",
    "binSizesFiltered = [binSize for binSize in CVDistance.binSizeGrid if binSize <= len(cvFolds[0][0])]\n",
    "test_eq(CVDistance.binSizeGrid, binSizesFiltered)\n",
    "\n",
    "#---\n",
    "\n",
    "# Estimator the same? Note: No __eq__ method is implemented for LGBMRegressor. \n",
    "# LGBM == LGBM2 consequently only returns true when both names are refering to \n",
    "# the exact same object in memory, which shouldn't be the case here because we \n",
    "# create a deepcopy of LGBM when initiating LS_KDEx. The point estimators\n",
    "# should be copies of each other though.\n",
    "assert CV.estimatorLSx.estimator is not LGBM\n",
    "test_eq(CV.estimatorLSx.estimator.predict(XTrain), LGBM.predict(XTrain))\n",
    "test_eq(CV.estimatorLSx.estimator.predict(XTest), LGBM.predict(XTest))\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Raw\n",
    "assert isinstance(CVDistance.cv_results_raw, list)\n",
    "test_eq(len(CVDistance.cv_results_raw), kFolds)\n",
    "\n",
    "for resDf in CVDistance.cv_results_raw:\n",
    "    test_eq(resDf.shape, (len(binSizesFiltered), len(probs)))\n",
    "    test_eq(resDf.index, binSizesFiltered)\n",
    "    test_eq(resDf.columns, probs)\n",
    "    assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Aggregated\n",
    "meanCostMatrix = 0\n",
    "for i in range(0, kFolds, 1):\n",
    "    meanCostMatrix += CVDistance.cv_results_raw[i]\n",
    "    \n",
    "meanCostMatrix = meanCostMatrix / kFolds\n",
    "\n",
    "assert np.allclose(CVDistance.cv_results, meanCostMatrix)\n",
    "\n",
    "test_eq(CVDistance.cv_results.shape, (len(binSizesFiltered), len(probs)))\n",
    "test_eq(CVDistance.cv_results.index, binSizesFiltered)\n",
    "test_eq(CVDistance.cv_results.columns, probs)\n",
    "assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size\n",
    "averageCostsPerBin = CVDistance.cv_results.mean(axis = 1)\n",
    "bestBinSizeTest = CVDistance.cv_results.index[np.argmin(averageCostsPerBin)]\n",
    "test_eq(CVDistance.bestBinSize, bestBinSizeTest)\n",
    "assert CVDistance.bestBinSize in binSizeGrid\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size per prob\n",
    "test_eq(len(CVDistance.bestBinSize_perProb), len(probs))\n",
    "assert [binSize in binSizeGrid for binSize in CVDistance.bestBinSize_perProb]\n",
    "\n",
    "bestBinSizePerProbTest = CVDistance.cv_results.idxmin(axis = 0)\n",
    "test_eq(CVDistance.bestBinSize_perProb, bestBinSizePerProbTest)\n",
    "\n",
    "#---\n",
    "\n",
    "# refitted LSx objects\n",
    "assert isinstance(CVDistance.bestEstimatorLSx, dict)\n",
    "test_eq(list(CVDistance.bestEstimatorLSx.keys()), probs)\n",
    "\n",
    "for prob, LSx in CVDistance.bestEstimatorLSx.items():\n",
    "    assert isinstance(LSx, LevelSetKDEx_kNN)\n",
    "    test_eq(LSx.binSize, bestBinSizePerProbTest.loc[prob])\n",
    "    \n",
    "    # Estimator the same? (Note: No __eq__ method is implemented for LGBMRegressor. \n",
    "    # LGBM == LGBM2 consequently only returns true when both names are refering to \n",
    "    # the exact same object in memory, which is not (!!) the case here)\n",
    "    assert LSx.estimator is not LGBM\n",
    "    test_eq(LSx.estimator.predict(XTrain), LGBM.predict(XTrain))\n",
    "    test_eq(LSx.estimator.predict(XTest), LGBM.predict(XTest))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4112db-d50d-46aa-9e66-b09c7cceb90b",
   "metadata": {},
   "source": [
    "## LS_KDEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f87150-6d6a-4759-aa45-3eb2d8e1528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "LS_KDEx = LevelSetKDEx(estimator = LGBM, binSize = 100)\n",
    "LS_KDEx.fit(XTrain, yTrain)\n",
    "\n",
    "# Check if nothing weird happened to y and yPred\n",
    "test_eq(LS_KDEx.yTrain, yTrain)\n",
    "test_eq(LS_KDEx.yTrainPred, LGBM.predict(XTrain))\n",
    "\n",
    "# Check if fitted has been set correctly\n",
    "assert LS_KDEx.fitted "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e63dd3f-e332-4a5f-857f-9c031edab2b0",
   "metadata": {},
   "source": [
    "### Standard Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b972c2d6-2f1e-4cd9-9ed8-6e6cd39029ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All train-indices must be part of indicesPerBin\n",
    "# and duplicates mustn't exist\n",
    "indicesList = list()\n",
    "\n",
    "for values in LS_KDEx.indicesPerBin.values():\n",
    "    indicesList.extend(values)\n",
    "    \n",
    "test_eq(set(indicesList), set(np.arange(XTrain.shape[0])))\n",
    "test_eq(len(indicesList), XTrain.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c3c72b-4409-4ad8-a5d4-f66eddee2e8f",
   "metadata": {},
   "source": [
    "### Lower Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1746eb43-e46a-4695-98bf-e0bada400385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower-bound structure has to be correct\n",
    "yPred = LS_KDEx.yTrainPred\n",
    "indicesPerBin = LS_KDEx.indicesPerBin\n",
    "lowerBoundPerBin = LS_KDEx.lowerBoundPerBin\n",
    "\n",
    "for i in range(len(indicesPerBin)):\n",
    "    binIndex = list(indicesPerBin.keys())[i]\n",
    "    indices = indicesPerBin[binIndex]\n",
    "    \n",
    "    minValue = yPred[indices].min()\n",
    "    maxValue = yPred[indices].max()\n",
    "    \n",
    "    assert minValue >= lowerBoundPerBin.loc[binIndex]\n",
    "    \n",
    "    if binIndex < max(list(indicesPerBin.keys())):\n",
    "        assert maxValue < lowerBoundPerBin.loc[binIndex + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb508cd-dde2-49eb-a95e-61597497632a",
   "metadata": {},
   "source": [
    "### getWeights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532ef110-b8d2-443b-b98a-fef857a09820",
   "metadata": {},
   "source": [
    "#### Standard Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8193d3-ffdf-4fb3-b18e-9c6028ea8852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights-Output Test\n",
    "\n",
    "LS_KDEx = LevelSetKDEx(estimator = LGBM, binSize = 100)\n",
    "LS_KDEx.fit(XTrain, yTrain)\n",
    "\n",
    "#---\n",
    "\n",
    "indicesPerBin = LS_KDEx.indicesPerBin\n",
    "lowerBoundPerBin = LS_KDEx.lowerBoundPerBin\n",
    "yPredTrain = LGBM.predict(XTrain)\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "binPerPred = np.searchsorted(a = lowerBoundPerBin, v = yPredTest, side = 'right') - 1\n",
    "indicesPerPred = [indicesPerBin[binIndex] for binIndex in binPerPred]\n",
    "\n",
    "#---\n",
    "\n",
    "weightsAll = LS_KDEx.getWeights(X = XTest, outputType = 'all')\n",
    "\n",
    "# Check if every bin contains at least 100 observations\n",
    "binSizesReal = [sum(weightsAll[i] > 0) for i in range(XTest.shape[0])]\n",
    "assert (np.array(binSizesReal) >= 100).all()\n",
    "\n",
    "test_eq(len(weightsAll), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsAll)):\n",
    "    weights = weightsAll[i]\n",
    "    \n",
    "    assert all(weights >= 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    test_eq(np.where(weights > 0)[0], np.sort(indicesPerPred[i]))\n",
    "\n",
    "#---\n",
    "\n",
    "weightsOnlyPos = LS_KDEx.getWeights(X = XTest, outputType = 'onlyPositiveWeights')\n",
    "\n",
    "# Check if every bin contains at least 100 observations\n",
    "binSizesReal = [len(weightsOnlyPos[i][1]) for i in range(XTest.shape[0])]\n",
    "assert (np.array(binSizesReal) >= 100).all()\n",
    "\n",
    "test_eq(len(weightsOnlyPos), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsOnlyPos)):\n",
    "    weights = weightsOnlyPos[i][0]\n",
    "    indices = weightsOnlyPos[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    test_eq(indices, indicesPerPred[i])\n",
    "    \n",
    "    if len(indices) > 100:\n",
    "        checkLastBin = yPredTrain.max() == yPredTrain[indices].max()\n",
    "        checkBinExtension = yPredTrain[indices[99]] == yPredTrain[indices[100]]\n",
    "        assert checkLastBin or checkBinExtension\n",
    "        \n",
    "#---\n",
    "\n",
    "weightsSummarized = LS_KDEx.getWeights(X = XTest, outputType = 'summarized')\n",
    "\n",
    "test_eq(len(weightsSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsSummarized)):\n",
    "    weights = weightsSummarized[i][0]\n",
    "    values = weightsSummarized[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(set(yTrain[indicesPerPred[i]]), set(values))\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsCumDistr = LS_KDEx.getWeights(X = XTest, outputType = 'cumulativeDistribution')\n",
    "\n",
    "# Check if every bin contains at least 100 observations\n",
    "binSizesReal = [len(weightsCumDistr[i][1]) for i in range(XTest.shape[0])]\n",
    "assert (np.array(binSizesReal) >= 100).all()\n",
    "\n",
    "test_eq(len(weightsCumDistr), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsCumDistr)):\n",
    "    cumProb = weightsCumDistr[i][0]\n",
    "    values = weightsCumDistr[i][1]\n",
    "    \n",
    "    assert all(cumProb > 0)\n",
    "    assert isclose(cumProb.max(), 1)\n",
    "    test_eq(cumProb, np.sort(cumProb))\n",
    "    assert np.allclose(np.diff(cumProb), np.diff(cumProb)[0])\n",
    "    \n",
    "    test_eq(values, np.sort(yTrain[indicesPerPred[i]]))\n",
    "\n",
    "#---\n",
    "\n",
    "weightsDistrSummarized = LS_KDEx.getWeights(X = XTest, outputType = 'cumulativeDistributionSummarized')\n",
    "\n",
    "test_eq(len(weightsDistrSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsDistrSummarized)):\n",
    "    cumProb = weightsDistrSummarized[i][0]\n",
    "    values = weightsDistrSummarized[i][1]\n",
    "    \n",
    "    assert all(cumProb > 0)\n",
    "    assert isclose(cumProb.max(), 1)\n",
    "    test_eq(cumProb, np.sort(cumProb))\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(set(values), set(np.sort(yTrain[indicesPerPred[i]])))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e29b66c-f331-4150-b997-d71410f51cd6",
   "metadata": {},
   "source": [
    "#### Distance Based Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8df32ba-07c7-4d4d-9eac-1c0b0a3599cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights-Output Test\n",
    "\n",
    "# Modifying XTrain to enforce test-predictions being identical to train predictions\n",
    "XTrainMod = np.concatenate([XTest[0:2, :], XTrain], axis = 0)\n",
    "yTrainMod = np.concatenate([yTest[0:2], yTrain], axis = 0)\n",
    "\n",
    "LS_KDEx = LevelSetKDEx(estimator = LGBM, binSize = 100, weightsByDistance = True)\n",
    "LS_KDEx.fit(XTrainMod, yTrainMod)\n",
    "\n",
    "#---\n",
    "\n",
    "indicesPerBin = LS_KDEx.indicesPerBin\n",
    "lowerBoundPerBin = LS_KDEx.lowerBoundPerBin\n",
    "yPredTrain = LGBM.predict(XTrainMod)\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "binPerPred = np.searchsorted(a = lowerBoundPerBin, v = yPredTest, side = 'right') - 1\n",
    "indicesPerPred = [indicesPerBin[binIndex] for binIndex in binPerPred]\n",
    "\n",
    "predDistances = [np.abs(yPredTrain[indicesPerPred[i]] - yPredTest[i]) for i in range(XTest.shape[0])]\n",
    "\n",
    "#---\n",
    "\n",
    "weightsList = LS_KDEx.getWeights(X = XTest, outputType = 'onlyPositiveWeights')\n",
    "\n",
    "# Check if all bins either contain at least 100 observations or if not all weights have to equal\n",
    "binSizesReal = [len(weightsList[i][1]) for i in range(XTest.shape[0])]\n",
    "\n",
    "for i in range(len(binSizesReal)):\n",
    "    if binSizesReal[i] < 100:\n",
    "        assert np.allclose(weightsList[i][0], 1 / len(weightsList[i][0]))\n",
    "        \n",
    "# Because of our above modification of XTrain and yTrain, for the first and second test observation \n",
    "# the special case applies where the test prediction is identical to at least 1 train prediction.\n",
    "assert np.allclose(weightsList[0][0], 1 / len(weightsList[0][0]))\n",
    "assert np.allclose(weightsList[1][0], 1 / len(weightsList[0][0]))\n",
    "\n",
    "assert 0 in weightsList[0][1]\n",
    "assert 1 in weightsList[1][1]\n",
    "\n",
    "#---\n",
    "\n",
    "weightsAll = LS_KDEx.getWeights(X = XTest, outputType = 'all')\n",
    "\n",
    "test_eq(len(weightsAll), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsAll)):\n",
    "    neighbors = indicesPerPred[i]\n",
    "    distances = predDistances[i]\n",
    "    weights = weightsAll[i]\n",
    "    \n",
    "    assert all(weights >= 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        assert np.allclose(weights[neighborsPredDistanceZero], 1 / sum(predDistanceCloseZero))\n",
    "        test_eq(np.sort(neighborsPredDistanceZero), np.sort(np.where(weights > 0)[0]))\n",
    "        \n",
    "    else:\n",
    "        inverseDistances = 1 / distances\n",
    "        np.allclose(np.sort(weights[neighbors]), np.sort(inverseDistances / sum(inverseDistances)))\n",
    "        test_eq(np.sort(neighbors), np.sort(np.where(weights > 0)[0]))\n",
    "\n",
    "#---\n",
    "\n",
    "weightsOnlyPos = LS_KDEx.getWeights(X = XTest, outputType = 'onlyPositiveWeights')\n",
    "\n",
    "test_eq(len(weightsOnlyPos), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsOnlyPos)):\n",
    "    neighbors = indicesPerPred[i]\n",
    "    distances = predDistances[i]\n",
    "    weights = weightsOnlyPos[i][0]\n",
    "    indices = weightsOnlyPos[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        assert np.allclose(weights, 1 / sum(predDistanceCloseZero))\n",
    "        test_eq(np.sort(neighborsPredDistanceZero), np.sort(indices))\n",
    "            \n",
    "    else:\n",
    "        inverseDistances = 1 / distances\n",
    "        assert np.allclose(weights, inverseDistances / sum(inverseDistances))\n",
    "        test_eq(np.sort(neighbors), np.sort(indices))\n",
    "    \n",
    "    if len(indices) > 100:\n",
    "        checkLastBin = yPredTrain.max() == yPredTrain[indices].max()\n",
    "        checkBinExtension = yPredTrain[indices[99]] == yPredTrain[indices[100]]\n",
    "        assert checkLastBin or checkBinExtension\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsSummarized = LS_KDEx.getWeights(X = XTest, outputType = 'summarized')\n",
    "\n",
    "test_eq(len(weightsSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsSummarized)):\n",
    "    neighbors = indicesPerPred[i]\n",
    "    distances = predDistances[i]\n",
    "    weights = weightsSummarized[i][0]\n",
    "    values = weightsSummarized[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n",
    "            \n",
    "    else:\n",
    "        valuesByHand = yTrainMod[neighbors]\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(set(valuesByHand), set(values))\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsCumDistr = LS_KDEx.getWeights(X = XTest, outputType = 'cumulativeDistribution')\n",
    "\n",
    "test_eq(len(weightsCumDistr), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsCumDistr)):\n",
    "    neighbors = indicesPerPred[i]\n",
    "    distances = predDistances[i]\n",
    "    cumProb = weightsCumDistr[i][0]\n",
    "    values = weightsCumDistr[i][1]\n",
    "    \n",
    "    assert all(cumProb > 0)\n",
    "    assert isclose(cumProb.max(), 1)\n",
    "    test_eq(cumProb, np.sort(cumProb))\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n",
    "        nCloseZero = sum(predDistanceCloseZero)\n",
    "        assert np.allclose(cumProb, np.cumsum(np.repeat(1 / nCloseZero, nCloseZero)))\n",
    "        \n",
    "    else:\n",
    "        # The following test works if we use 'valuesByHand = yTrainMod[weightsOnlyPos[i][1]' to grab the yTrain values\n",
    "        # because the getWeights-function does nothing else. If we grab them differently here (e.g. via neighborsMatrix),\n",
    "        # the sorting can become different for identical yTrain values which will change the cumulated probabilities\n",
    "        # for exactly those indices (and only these). This has no practical implications for the usage of the computed\n",
    "        # cumulated distribution function, but it has for the exact value testing we are doing here.\n",
    "        inverseDistances = 1 / distances\n",
    "        valuesByHand = yTrainMod[weightsOnlyPos[i][1]]\n",
    "        valuesByHandIndicesSort = np.argsort(valuesByHand)\n",
    "        assert np.allclose(cumProb, np.cumsum((inverseDistances / sum(inverseDistances))[valuesByHandIndicesSort]))\n",
    "    \n",
    "    test_eq(values, np.sort(values))\n",
    "    test_eq(np.sort(valuesByHand), values)\n",
    "\n",
    "#---\n",
    "\n",
    "weightsDistrSummarized = LS_KDEx.getWeights(X = XTest, outputType = 'cumulativeDistributionSummarized')\n",
    "\n",
    "test_eq(len(weightsDistrSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsDistrSummarized)):\n",
    "    neighbors = indicesPerPred[i]\n",
    "    distances = predDistances[i]\n",
    "    cumProb = weightsDistrSummarized[i][0]\n",
    "    values = weightsDistrSummarized[i][1]\n",
    "    \n",
    "    assert all(cumProb > 0)\n",
    "    assert isclose(cumProb.max(), 1)\n",
    "    test_eq(cumProb, np.sort(cumProb))\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n",
    "    \n",
    "    else:\n",
    "        inverseDistances = 1 / distances\n",
    "        valuesByHand = yTrainMod[neighbors]\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(values, np.sort(values))\n",
    "    test_eq(set(valuesByHand), set(values))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94fcf0a-e903-4d0a-a0e5-b733869df259",
   "metadata": {},
   "source": [
    "#### ScalingList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8058fc83-14d3-4967-8aa5-9d42b2a5058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing scalingList \n",
    "\n",
    "LS_KDEx = LevelSetKDEx(estimator = LGBM, binSize = 100)\n",
    "LS_KDEx.fit(XTrain, yTrain)\n",
    "\n",
    "#---\n",
    "\n",
    "indicesPerBin = LS_KDEx.indicesPerBin\n",
    "lowerBoundPerBin = LS_KDEx.lowerBoundPerBin\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "binPerPred = np.searchsorted(a = lowerBoundPerBin, v = yPredTest, side = 'right') - 1\n",
    "indicesPerPred = [indicesPerBin[binIndex] for binIndex in binPerPred]\n",
    "\n",
    "#---\n",
    "\n",
    "weightsSummarized = LS_KDEx.getWeights(X = XTest, outputType = 'summarized', scalingList = scalingList)\n",
    "\n",
    "test_eq(len(weightsSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsSummarized)):\n",
    "    weights = weightsSummarized[i][0]\n",
    "    values = weightsSummarized[i][1]\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(set(yTrain[indicesPerPred[i]] * scalingList[i]), set(values))\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsCumDistr = LS_KDEx.getWeights(X = XTest, outputType = 'cumulativeDistribution', scalingList = scalingList)\n",
    "\n",
    "test_eq(len(weightsCumDistr), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsCumDistr)):\n",
    "    cumProb = weightsCumDistr[i][0]\n",
    "    values = weightsCumDistr[i][1]\n",
    "    \n",
    "    test_eq(values, np.sort(yTrain[indicesPerPred[i]]) * scalingList[i])\n",
    "\n",
    "#---\n",
    "\n",
    "weightsDistrSummarized = LS_KDEx.getWeights(X = XTest, outputType = 'cumulativeDistributionSummarized', scalingList = scalingList)\n",
    "\n",
    "test_eq(len(weightsDistrSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsDistrSummarized)):\n",
    "    cumProb = weightsDistrSummarized[i][0]\n",
    "    values = weightsDistrSummarized[i][1]\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(set(values), set(np.sort(yTrain[indicesPerPred[i]]) * scalingList[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf08ad9-5bce-4fe7-af0f-586a7bb849e9",
   "metadata": {},
   "source": [
    "#### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d086697-3a40-4127-83a4-3e360f4c311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing predict-method\n",
    "LS_KDEx = LevelSetKDEx(estimator = LGBM, binSize = 100)\n",
    "LS_KDEx.fit(XTrain, yTrain)\n",
    "\n",
    "#---\n",
    "\n",
    "indicesPerBin = LS_KDEx.indicesPerBin\n",
    "lowerBoundPerBin = LS_KDEx.lowerBoundPerBin\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "binPerPred = np.searchsorted(a = lowerBoundPerBin, v = yPredTest, side = 'right') - 1\n",
    "indicesPerPred = [indicesPerBin[binIndex] for binIndex in binPerPred]\n",
    "yTrainPerPred = [yTrain[indices] for indices in indicesPerPred]\n",
    "\n",
    "#---\n",
    "\n",
    "probs = [0.001, 0.5, 0.999]\n",
    "quantileDict = LS_KDEx.predict(X = XTest, probs = probs, outputAsDf = False, scalingList = None)\n",
    "quantileDf = LS_KDEx.predict(X = XTest, probs = probs, outputAsDf = True, scalingList = None)\n",
    "\n",
    "test_eq(pd.DataFrame(quantileDict), quantileDf)\n",
    "test_eq(list(quantileDict.keys()), probs)\n",
    "\n",
    "for i in range(quantileDf.shape[0]):\n",
    "    assert((np.diff(quantileDf.iloc[i,:]) >= 0).all())\n",
    "    test_eq(yTrainPerPred[i].min(), quantileDf.loc[i, 0.001])\n",
    "    test_eq(yTrainPerPred[i].max(), quantileDf.loc[i, 0.999])\n",
    "    test_eq(np.quantile(a = yTrainPerPred[i], q = 0.5, method = 'inverted_cdf'), quantileDf.loc[i, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e92a75-f000-4ae8-b5b6-5a2438068d4e",
   "metadata": {},
   "source": [
    "### Set and Get Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bf9019-51e6-4e2f-9af3-337753070bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "LS_KDEx = LevelSetKDEx(estimator = LGBM, binSize = 100, weightsByDistance = False)\n",
    "LS_KDEx.fit(XTrain, yTrain)\n",
    "\n",
    "#---\n",
    "\n",
    "assert all([param in LS_KDEx.get_params() for param in ['binSize', 'estimator', 'weightsByDistance']])\n",
    "\n",
    "#---\n",
    "\n",
    "LS_KDEx.set_params(estimator = LGBMRegressor(min_child_samples = 10000))\n",
    "LS_KDEx.fit(X = XTrain, y = yTrain)\n",
    "test_eq(len(np.unique(LS_KDEx.estimator.predict(XTest))), 1)\n",
    "\n",
    "LS_KDEx.set_params(estimator = LGBM, binSize = 3000)\n",
    "LS_KDEx.fit(X = XTrain, y = yTrain)\n",
    "test_eq(len(np.unique(LS_KDEx.predict(XTest, probs = [0.5]).values.flatten())), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2ea37-8dee-4435-b644-42bea6bfc12b",
   "metadata": {},
   "source": [
    "### Point Estimator Fit and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99d473a-5bb8-43b9-898e-7a9df9f357d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM2 = LGBMRegressor(n_jobs = 1, max_depth = 2)\n",
    "\n",
    "LS_KDEx = LevelSetKDEx(estimator = LGBM2, binSize = 100, weightsByDistance = False)\n",
    "assert 'fitted_' not in dir(LS_KDEx.estimator)\n",
    "LS_KDEx.fit(XTrain, yTrain)\n",
    "assert LS_KDEx.estimator.fitted_\n",
    "\n",
    "# Check whether original estimator has been unintentionally modified\n",
    "assert 'fitted_' not in dir(LGBM2)\n",
    "\n",
    "#---\n",
    "\n",
    "LGBM2 = LGBMRegressor(n_jobs = 1, max_depth = 2)\n",
    "\n",
    "LS_KDEx = LevelSetKDEx(estimator = LGBM2, binSize = 100, weightsByDistance = False)\n",
    "assert 'fitted_' not in dir(LS_KDEx.estimator)\n",
    "LS_KDEx.refitPointEstimator(XTrain, yTrain)\n",
    "assert LS_KDEx.estimator.fitted_\n",
    "\n",
    "# Check whether original estimator has been unintentionally modified\n",
    "assert 'fitted_' not in dir(LGBM2)\n",
    "\n",
    "#---\n",
    "\n",
    "LGBM2 = LGBMRegressor(n_jobs = 1, max_depth = 2)\n",
    "\n",
    "LS_KDEx = LevelSetKDEx(estimator = LGBM2, binSize = 100, weightsByDistance = False)\n",
    "LS_KDEx.set_params(estimator = LGBMRegressor(min_child_samples = 10000))\n",
    "\n",
    "assert 'fitted_' not in dir(LS_KDEx.estimator)\n",
    "LS_KDEx.refitPointEstimator(XTrain, yTrain)\n",
    "assert LS_KDEx.estimator.fitted_\n",
    "test_eq(len(np.unique(LS_KDEx.estimator.predict(XTest))), 1)\n",
    "test_eq(len(np.unique(LS_KDEx.pointPredict(XTest))), 1)\n",
    "\n",
    "# Check whether original estimator has been unintentionally modified\n",
    "assert 'fitted_' not in dir(LGBM2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1d7eb3-95c6-42aa-9be7-8857c7cd55b2",
   "metadata": {},
   "source": [
    "## LS_KDEx_kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ef55b2-00e4-45ff-b772-e1e05ad38db3",
   "metadata": {},
   "source": [
    "### Standard Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ef3022-b673-49bc-a3b5-522a6ccaf850",
   "metadata": {},
   "outputs": [],
   "source": [
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 100)\n",
    "LS_KDEx_kNN.fit(XTrain, yTrain)\n",
    "\n",
    "# Check if nothing weird happened to y and yPred\n",
    "test_eq(LS_KDEx_kNN.yTrain, yTrain)\n",
    "test_eq(LS_KDEx_kNN.yTrainPred, LGBM.predict(XTrain))\n",
    "\n",
    "# Check if fitted has been set correctly\n",
    "assert LS_KDEx_kNN.fitted "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9de8b1-8199-49f5-81e2-1f682b10bd77",
   "metadata": {},
   "source": [
    "### getWeights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a0317-8042-4bb0-8386-2654806f053f",
   "metadata": {},
   "source": [
    "#### Standard Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a599bb7-377e-41b7-80cb-c0331ee6a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights-Output Test\n",
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 100, weightsByDistance = False)\n",
    "LS_KDEx_kNN.fit(XTrain, yTrain)\n",
    "\n",
    "nn = LS_KDEx_kNN.nearestNeighborsOnPreds\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "yPredTest_reshaped = np.reshape(yPredTest, newshape = (len(yPredTest), 1))\n",
    "\n",
    "weightsList = LS_KDEx_kNN.getWeights(X = XTest, \n",
    "                                     outputType = 'onlyPositiveWeights')\n",
    "\n",
    "binSizesReal = [len(weightsList[i][1]) for i in range(XTest.shape[0])]\n",
    "distancesMatrix, neighborsMatrix = nn.kneighbors(X = yPredTest_reshaped, n_neighbors = max(binSizesReal))\n",
    "\n",
    "# Check if all bins contain at least 100 observations\n",
    "assert np.all((np.array(binSizesReal) >= 100))\n",
    "\n",
    "#---\n",
    "\n",
    "weightsAll = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'all')\n",
    "\n",
    "test_eq(len(weightsAll), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsAll)):\n",
    "    weights = weightsAll[i]\n",
    "    \n",
    "    assert all(weights >= 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    assert np.allclose(weights[weights > 0], 1 / binSizesReal[i])\n",
    "    \n",
    "    test_eq(set(neighborsMatrix[i, 0:binSizesReal[i]]), set(np.where(weights > 0)[0]))\n",
    "\n",
    "#---\n",
    "\n",
    "weightsOnlyPos = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'onlyPositiveWeights')\n",
    "\n",
    "test_eq(len(weightsOnlyPos), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsOnlyPos)):\n",
    "    weights = weightsOnlyPos[i][0]\n",
    "    indices = weightsOnlyPos[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    assert np.allclose(weights, 1 / binSizesReal[i])\n",
    "    \n",
    "    test_eq(set(neighborsMatrix[i, 0:binSizesReal[i]]), set(indices))\n",
    "    \n",
    "    if len(indices) > 100:\n",
    "        assert np.allclose(np.diff(distancesMatrix[i, 99:binSizesReal[i]]), 0)\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsSummarized = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'summarized')\n",
    "\n",
    "test_eq(len(weightsSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsSummarized)):\n",
    "    weights = weightsSummarized[i][0]\n",
    "    values = weightsSummarized[i][1]\n",
    "    valuesByHand = yTrain[neighborsMatrix[i, 0:binSizesReal[i]]]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    assert np.all(weights >= 1 / binSizesReal[i])\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(set(valuesByHand), set(values))\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsCumDistr = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'cumulativeDistribution')\n",
    "\n",
    "test_eq(len(weightsCumDistr), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsCumDistr)):\n",
    "    cumProb = weightsCumDistr[i][0]\n",
    "    values = weightsCumDistr[i][1]\n",
    "    valuesByHand = yTrain[neighborsMatrix[i, 0:binSizesReal[i]]]\n",
    "    \n",
    "    assert all(cumProb > 0)\n",
    "    assert isclose(cumProb.max(), 1)\n",
    "    test_eq(cumProb, np.sort(cumProb))\n",
    "    assert np.allclose(np.diff(cumProb), np.diff(cumProb)[0])\n",
    "    \n",
    "    test_eq(values, np.sort(values))\n",
    "    test_eq(np.sort(valuesByHand), values)\n",
    "\n",
    "#---\n",
    "\n",
    "weightsDistrSummarized = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'cumulativeDistributionSummarized')\n",
    "\n",
    "test_eq(len(weightsDistrSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsDistrSummarized)):\n",
    "    cumProb = weightsDistrSummarized[i][0]\n",
    "    values = weightsDistrSummarized[i][1]\n",
    "    valuesByHand = yTrain[neighborsMatrix[i, 0:binSizesReal[i]]]\n",
    "    \n",
    "    assert all(cumProb > 0)\n",
    "    assert isclose(cumProb.max(), 1)\n",
    "    test_eq(cumProb, np.sort(cumProb))\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(values, np.sort(values))\n",
    "    test_eq(set(valuesByHand), set(values))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b1924f-7ec9-4915-bd66-04b443020e1d",
   "metadata": {},
   "source": [
    "#### Distance Based Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f8c0ec-e5eb-40c5-ac16-6e7d87e963e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights-Output Test\n",
    "\n",
    "# Modifying XTrain to enforce test-predictions being identical to train predictions\n",
    "XTrainMod = np.concatenate([XTest[0:2, :], XTrain], axis = 0)\n",
    "yTrainMod = np.concatenate([yTest[0:2], yTrain], axis = 0)\n",
    "\n",
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 100, weightsByDistance = True,)\n",
    "LS_KDEx_kNN.fit(XTrainMod, yTrainMod)\n",
    "\n",
    "#---\n",
    "\n",
    "nn = LS_KDEx_kNN.nearestNeighborsOnPreds\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "yPredTest_reshaped = np.reshape(yPredTest, newshape = (len(yPredTest), 1))\n",
    "\n",
    "weightsList = LS_KDEx_kNN.getWeights(X = XTest,  \n",
    "                                     outputType = 'onlyPositiveWeights')\n",
    "\n",
    "#---\n",
    "\n",
    "binSizesReal = [len(weightsList[i][1]) for i in range(XTest.shape[0])]\n",
    "distancesMatrix, neighborsMatrix = nn.kneighbors(X = yPredTest_reshaped, n_neighbors = max(binSizesReal))\n",
    "\n",
    "# Check if all bins either contain at least 100 observations or if not all weights have to equal\n",
    "for i in range(len(binSizesReal)):\n",
    "    if binSizesReal[i] < 100:\n",
    "        assert np.allclose(weightsList[i][0], 1 / len(weightsList[i][0]))\n",
    "        \n",
    "# Because of our above modification of XTrain and yTrain, for the first and second test observation \n",
    "# the special case applies where the test prediction is identical to at least 1 train prediction.\n",
    "assert np.allclose(weightsList[0][0], 1 / len(weightsList[0][0]))\n",
    "assert np.allclose(weightsList[1][0], 1 / len(weightsList[0][0]))\n",
    "\n",
    "assert 0 in weightsList[0][1]\n",
    "assert 1 in weightsList[1][1]\n",
    "\n",
    "#---\n",
    "\n",
    "weightsAll = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'all')\n",
    "\n",
    "test_eq(len(weightsAll), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsAll)):\n",
    "    neighbors = neighborsMatrix[i, 0:binSizesReal[i]]\n",
    "    distances = distancesMatrix[i, 0:binSizesReal[i]]\n",
    "    weights = weightsAll[i]\n",
    "    \n",
    "    assert all(weights >= 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        assert np.allclose(weights[neighborsPredDistanceZero], 1 / sum(predDistanceCloseZero))\n",
    "        test_eq(np.sort(neighborsPredDistanceZero), np.sort(np.where(weights > 0)[0]))\n",
    "        \n",
    "    else:\n",
    "        inverseDistances = 1 / distances\n",
    "        np.allclose(np.sort(weights[neighbors]), np.sort(inverseDistances / sum(inverseDistances)))\n",
    "        test_eq(np.sort(neighbors), np.sort(np.where(weights > 0)[0]))\n",
    "\n",
    "#---\n",
    "\n",
    "weightsOnlyPos = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'onlyPositiveWeights')\n",
    "\n",
    "test_eq(len(weightsOnlyPos), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsOnlyPos)):\n",
    "    neighbors = neighborsMatrix[i, 0:binSizesReal[i]]\n",
    "    distances = distancesMatrix[i, 0:binSizesReal[i]]\n",
    "    weights = weightsOnlyPos[i][0]\n",
    "    indices = weightsOnlyPos[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        assert np.allclose(weights, 1 / sum(predDistanceCloseZero))\n",
    "        test_eq(np.sort(neighborsPredDistanceZero), np.sort(indices))\n",
    "            \n",
    "    else:\n",
    "        inverseDistances = 1 / distances\n",
    "        assert np.allclose(weights, inverseDistances / sum(inverseDistances))\n",
    "        test_eq(np.sort(neighbors), np.sort(indices))\n",
    "    \n",
    "    if len(indices) > 100:\n",
    "        assert np.allclose(np.diff(distancesMatrix[i, 99:binSizesReal[i]]), 0)\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsSummarized = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'summarized')\n",
    "\n",
    "test_eq(len(weightsSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsSummarized)):\n",
    "    neighbors = neighborsMatrix[i, 0:binSizesReal[i]]\n",
    "    distances = distancesMatrix[i, 0:binSizesReal[i]]\n",
    "    weights = weightsSummarized[i][0]\n",
    "    values = weightsSummarized[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n",
    "            \n",
    "    else:\n",
    "        valuesByHand = yTrainMod[neighborsMatrix[i, 0:binSizesReal[i]]]\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(set(valuesByHand), set(values))\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsCumDistr = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'cumulativeDistribution')\n",
    "\n",
    "test_eq(len(weightsCumDistr), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsCumDistr)):\n",
    "    neighbors = neighborsMatrix[i, 0:binSizesReal[i]]\n",
    "    distances = distancesMatrix[i, 0:binSizesReal[i]]\n",
    "    cumProb = weightsCumDistr[i][0]\n",
    "    values = weightsCumDistr[i][1]\n",
    "    \n",
    "    assert all(cumProb > 0)\n",
    "    assert isclose(cumProb.max(), 1)\n",
    "    test_eq(cumProb, np.sort(cumProb))\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n",
    "        nCloseZero = sum(predDistanceCloseZero)\n",
    "        assert np.allclose(cumProb, np.cumsum(np.repeat(1 / nCloseZero, nCloseZero)))\n",
    "        \n",
    "    else:\n",
    "        # The following test works if we use 'valuesByHand = yTrainMod[weightsOnlyPos[i][1]' to grab the yTrain values\n",
    "        # because the getWeights-function does nothing else. If we grab them differently here (e.g. via neighborsMatrix),\n",
    "        # the sorting can become different for identical yTrain values which will change the cumulated probabilities\n",
    "        # for exactly those indices (and only these). This has no practical implications for the usage of the computed\n",
    "        # cumulated distribution function, but it has for the exact value testing we are doing here.\n",
    "        inverseDistances = 1 / distances\n",
    "        valuesByHand = yTrainMod[weightsOnlyPos[i][1]]\n",
    "        valuesByHandIndicesSort = np.argsort(valuesByHand)\n",
    "        assert np.allclose(cumProb, np.cumsum((inverseDistances / sum(inverseDistances))[valuesByHandIndicesSort]))\n",
    "    \n",
    "    test_eq(values, np.sort(values))\n",
    "    test_eq(np.sort(valuesByHand), values)\n",
    "\n",
    "#---\n",
    "\n",
    "weightsDistrSummarized = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'cumulativeDistributionSummarized')\n",
    "\n",
    "test_eq(len(weightsDistrSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsDistrSummarized)):\n",
    "    neighbors = neighborsMatrix[i, 0:binSizesReal[i]]\n",
    "    distances = distancesMatrix[i, 0:binSizesReal[i]]\n",
    "    cumProb = weightsDistrSummarized[i][0]\n",
    "    values = weightsDistrSummarized[i][1]\n",
    "    \n",
    "    \n",
    "    assert all(cumProb > 0)\n",
    "    assert isclose(cumProb.max(), 1)\n",
    "    test_eq(cumProb, np.sort(cumProb))\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n",
    "    \n",
    "    else:\n",
    "        inverseDistances = 1 / distances\n",
    "        valuesByHand = yTrainMod[neighborsMatrix[i, 0:binSizesReal[i]]]\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(values, np.sort(values))\n",
    "    test_eq(set(valuesByHand), set(values))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c669976c-c64c-4776-8e7d-912eb4352eee",
   "metadata": {},
   "source": [
    "#### Artificially Big Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb16f73-c72f-4344-8825-7f528b92b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enforcing bins with size bigger than binSize\n",
    "binSize = 10\n",
    "\n",
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 10)\n",
    "\n",
    "# Done to ensure that bins with binSize > 100 happen\n",
    "XTrainDuplicated = np.concatenate([XTrain] * (binSize + 1), axis = 0)\n",
    "yTrainDuplicated = np.concatenate([yTrain] * (binSize + 1), axis = 0)\n",
    "\n",
    "LS_KDEx_kNN.fit(XTrainDuplicated, yTrainDuplicated)\n",
    "\n",
    "#---\n",
    "\n",
    "nn = LS_KDEx_kNN.nearestNeighborsOnPreds\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "yPredTest_reshaped = np.reshape(yPredTest, newshape = (len(yPredTest), 1))\n",
    "\n",
    "distancesMatrix, neighborsMatrix = nn.kneighbors(X = yPredTest_reshaped, n_neighbors = binSize + 1)\n",
    "\n",
    "#---\n",
    "\n",
    "weightsOnlyPos = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'onlyPositiveWeights')\n",
    "\n",
    "test_eq(len(weightsOnlyPos), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsOnlyPos)):\n",
    "    weights = weightsOnlyPos[i][0]\n",
    "    indices = weightsOnlyPos[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    assert set(neighborsMatrix[i, 0:binSize]) <= set(indices)\n",
    "    \n",
    "    if len(indices) > 100:\n",
    "        test_eq(distancesMatrix[i, binSize-1], distancesMatrix[i, binSize])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e3303e-760d-46f5-8f4f-661a6da81fd9",
   "metadata": {},
   "source": [
    "#### Bins with only 1 Unique Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c9e4d9-07cc-4fb4-9212-6dae36c4e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enforcing bins with only one unique value\n",
    "binSize = 10\n",
    "\n",
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 10)\n",
    "\n",
    "# Done to ensure that bins with binSize > 100 happen\n",
    "XTrainDuplicated = np.concatenate([XTrain] * binSize, axis = 0)\n",
    "yTrainDuplicated = np.concatenate([yTrain] * binSize, axis = 0)\n",
    "\n",
    "LS_KDEx_kNN.fit(XTrainDuplicated, yTrainDuplicated)\n",
    "\n",
    "#---\n",
    "\n",
    "weightsOnlyPos = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'summarized')\n",
    "\n",
    "test_eq(len(weightsOnlyPos), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsOnlyPos)):\n",
    "    weights = weightsOnlyPos[i][0]\n",
    "    values = weightsOnlyPos[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    test_eq(len(values), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a450e8de-2bb7-4253-b411-083b26ea0631",
   "metadata": {},
   "source": [
    "#### ScalingList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ccda98-430f-4f72-a38e-f9ba090ab1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing scalingList \n",
    "binSize = 20\n",
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = binSize)\n",
    "\n",
    "#---\n",
    "\n",
    "LS_KDEx_kNN.fit(XTrain, yTrain)\n",
    "nn = LS_KDEx_kNN.nearestNeighborsOnPreds\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "yPredTest_reshaped = np.reshape(yPredTest, newshape = (len(yPredTest), 1))\n",
    "\n",
    "distancesMatrix, neighborsMatrix = nn.kneighbors(X = yPredTest_reshaped, n_neighbors = binSize)\n",
    "\n",
    "#---\n",
    "\n",
    "weightsSummarized = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'summarized', scalingList = scalingList)\n",
    "\n",
    "test_eq(len(weightsSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsSummarized)):\n",
    "    weights = weightsSummarized[i][0]\n",
    "    values = weightsSummarized[i][1]\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    assert set(yTrain[neighborsMatrix[i, :]] * scalingList[i]) <= set(values)\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsCumDistr = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'cumulativeDistribution', scalingList = scalingList)\n",
    "\n",
    "test_eq(len(weightsCumDistr), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsCumDistr)):\n",
    "    cumProb = weightsCumDistr[i][0]\n",
    "    values = weightsCumDistr[i][1]\n",
    "    \n",
    "    test_eq(values, np.sort(values))\n",
    "    assert set(yTrain[neighborsMatrix[i, :]] * scalingList[i]) <= set(values)\n",
    "\n",
    "#---\n",
    "\n",
    "weightsDistrSummarized = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'cumulativeDistributionSummarized', scalingList = scalingList)\n",
    "\n",
    "test_eq(len(weightsDistrSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsDistrSummarized)):\n",
    "    cumProb = weightsDistrSummarized[i][0]\n",
    "    values = weightsDistrSummarized[i][1]\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(values, np.sort(values))\n",
    "    assert set(yTrain[neighborsMatrix[i, :]] * scalingList[i]) <= set(values)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55172450-e90f-43ef-bf41-29bc6fff14ac",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403f0b52-c2ec-47eb-ba70-99b75e20be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing predict-method\n",
    "binSize = 15\n",
    "\n",
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = binSize)\n",
    "\n",
    "LS_KDEx_kNN.fit(XTrain, yTrain)\n",
    "nn = LS_KDEx_kNN.nearestNeighborsOnPreds\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "yPredTest_reshaped = np.reshape(yPredTest, newshape = (len(yPredTest), 1))\n",
    "\n",
    "weightsList = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'onlyPositiveWeights')\n",
    "binSizesReal = [len(weightsList[i][1]) for i in range(XTest.shape[0])]\n",
    "distancesMatrix, neighborsMatrix = nn.kneighbors(X = yPredTest_reshaped, n_neighbors = max(binSizesReal))\n",
    "\n",
    "#---\n",
    "\n",
    "probs = [0.001, 0.5, 0.999]\n",
    "quantileDict = LS_KDEx_kNN.predict(X = XTest, probs = probs, outputAsDf = False, scalingList = None)\n",
    "quantileDf = LS_KDEx_kNN.predict(X = XTest, probs = probs, outputAsDf = True, scalingList = None)\n",
    "\n",
    "test_eq(pd.DataFrame(quantileDict), quantileDf)\n",
    "test_eq(list(quantileDict.keys()), probs)\n",
    "\n",
    "for i in range(quantileDf.shape[0]):\n",
    "    \n",
    "    assert((np.diff(quantileDf.iloc[i,:]) >= 0).all())\n",
    "    \n",
    "    binSizeReal = binSizesReal[i]\n",
    "    valuesByHand = yTrain[neighborsMatrix[i, 0:binSizeReal]]\n",
    "    \n",
    "    test_eq(valuesByHand.min(), quantileDf.loc[i, 0.001])\n",
    "    test_eq(valuesByHand.max(), quantileDf.loc[i, 0.999])\n",
    "    test_eq(np.quantile(a = valuesByHand, q = 0.5, method = 'inverted_cdf'), quantileDf.loc[i, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bce23c-19b9-4d9e-8c0a-db2b11396026",
   "metadata": {},
   "source": [
    "### Set and Get Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b82fa9-626d-4b71-82bc-02f825467399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 100, weightsByDistance = False)\n",
    "LS_KDEx_kNN.fit(XTrain, yTrain)\n",
    "\n",
    "#---\n",
    "\n",
    "assert all([param in LS_KDEx_kNN.get_params() for param in ['binSize', 'estimator', 'weightsByDistance']])\n",
    "\n",
    "#---\n",
    "\n",
    "LS_KDEx_kNN.set_params(estimator = LGBMRegressor(min_child_samples = 10000))\n",
    "LS_KDEx_kNN.fit(X = XTrain, y = yTrain)\n",
    "test_eq(len(np.unique(LS_KDEx_kNN.estimator.predict(XTest))), 1)\n",
    "\n",
    "LS_KDEx_kNN.set_params(estimator = LGBM, binSize = yTrain.shape[0] - 1)\n",
    "LS_KDEx_kNN.fit(X = XTrain, y = yTrain)\n",
    "test_eq(len(np.unique(LS_KDEx_kNN.predict(XTest, probs = [0.5]).values.flatten())), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4309652-8b4e-49d8-b208-bce9c1222d5e",
   "metadata": {},
   "source": [
    "### Point Estimator Fit and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b5281-768f-4d91-8a42-4d7a978fbb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM2 = LGBMRegressor(n_jobs = 1, max_depth = 2)\n",
    "\n",
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM2, binSize = 100, weightsByDistance = False)\n",
    "assert 'fitted_' not in dir(LS_KDEx_kNN.estimator)\n",
    "LS_KDEx_kNN.fit(XTrain, yTrain)\n",
    "assert LS_KDEx_kNN.estimator.fitted_\n",
    "\n",
    "# Check whether original estimator has been unintentionally modified\n",
    "assert 'fitted_' not in dir(LGBM2)\n",
    "\n",
    "#---\n",
    "\n",
    "LGBM2 = LGBMRegressor(n_jobs = 1, max_depth = 2)\n",
    "\n",
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM2, binSize = 100, weightsByDistance = False)\n",
    "assert 'fitted_' not in dir(LS_KDEx_kNN.estimator)\n",
    "LS_KDEx_kNN.refitPointEstimator(XTrain, yTrain)\n",
    "assert LS_KDEx_kNN.estimator.fitted_\n",
    "\n",
    "# Check whether original estimator has been unintentionally modified\n",
    "assert 'fitted_' not in dir(LGBM2)\n",
    "\n",
    "#---\n",
    "\n",
    "LGBM2 = LGBMRegressor(n_jobs = 1, max_depth = 2)\n",
    "\n",
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM2, binSize = 100, weightsByDistance = False)\n",
    "LS_KDEx_kNN.set_params(estimator = LGBMRegressor(min_child_samples = 10000))\n",
    "\n",
    "assert 'fitted_' not in dir(LS_KDEx_kNN.estimator)\n",
    "LS_KDEx_kNN.refitPointEstimator(XTrain, yTrain)\n",
    "assert LS_KDEx_kNN.estimator.fitted_\n",
    "test_eq(len(np.unique(LS_KDEx_kNN.estimator.predict(XTest))), 1)\n",
    "test_eq(len(np.unique(LS_KDEx_kNN.pointPredict(XTest))), 1)\n",
    "\n",
    "# Check whether original estimator has been unintentionally modified\n",
    "assert 'fitted_' not in dir(LGBM2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e7b9c9-0575-42aa-8fa8-08134cba1f18",
   "metadata": {},
   "source": [
    "## Generate Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568736df-bd7c-456a-97c1-47d5a80474a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing various artificial inputs of 'generateBins'\n",
    "\n",
    "yPred = np.arange(100)\n",
    "indicesPerBin, lowerBoundPerBin = generateBins(binSize = 10, yPred = yPred)\n",
    "\n",
    "test_eq(list(indicesPerBin.keys()), [i for i in range(10)])\n",
    "\n",
    "indicesPerBinTest = {0: np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
    "                     1: np.array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]),\n",
    "                     2: np.array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
    "                     3: np.array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39]),\n",
    "                     4: np.array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n",
    "                     5: np.array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59]),\n",
    "                     6: np.array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69]),\n",
    "                     7: np.array([70, 71, 72, 73, 74, 75, 76, 77, 78, 79]),\n",
    "                     8: np.array([80, 81, 82, 83, 84, 85, 86, 87, 88, 89]),\n",
    "                     9: np.array([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])}\n",
    "\n",
    "indicesTracker = list()\n",
    "for i in range(len(indicesPerBin)):\n",
    "    test_eq(set(indicesPerBin[i]), set(indicesPerBinTest[i]))\n",
    "    test_eq(len(indicesPerBin[i]), len(np.unique(indicesPerBin[i])))\n",
    "    \n",
    "    indicesTracker.extend(indicesPerBin[i].tolist())\n",
    "\n",
    "test_eq(len(indicesTracker), len(np.unique(indicesTracker)))\n",
    "test_eq(np.sort(indicesTracker), np.arange(len(yPred)))\n",
    "\n",
    "lowerBoundPerBinTest = [np.NINF, 9.5, 19.5, 29.5, 39.5, 49.5, 59.5, 69.5, 79.5, 89.5]\n",
    "test_eq(list(lowerBoundPerBin), lowerBoundPerBinTest)\n",
    "test_eq(list(lowerBoundPerBin.index), [i for i in range(10)])\n",
    "\n",
    "#---\n",
    "\n",
    "yPred = np.append(np.arange(100), np.arange(100))\n",
    "indicesPerBin, lowerBoundPerBin = generateBins(binSize = 10, yPred = yPred)\n",
    "\n",
    "test_eq(list(indicesPerBin.keys()), [i for i in range(20)])\n",
    "\n",
    "indicesPerBinTest = {0: np.array([   0, 100,   1, 101,   2, 102,   3, 103,   4, 104]),\n",
    "                     1: np.array([   5, 105,   6, 106,   7, 107,   8, 108,   9, 109]),\n",
    "                     2: np.array([  10, 110,  11, 111,  12, 112,  13, 113,  14, 114]),\n",
    "                     3: np.array([  15, 115,  16, 116,  17, 117,  18, 118,  19, 119]),\n",
    "                     4: np.array([  20, 120,  21, 121,  22, 122,  23, 123,  24, 124]),\n",
    "                     5: np.array([  25, 125,  26, 126,  27, 127,  28, 128,  29, 129]),\n",
    "                     6: np.array([  30, 130,  31, 131,  32, 132,  33, 133,  34, 134]),\n",
    "                     7: np.array([  35, 135,  36, 136,  37, 137,  38, 138,  39, 139]),\n",
    "                     8: np.array([  40, 140,  41, 141,  42, 142,  43, 143,  44, 144]),\n",
    "                     9: np.array([  45, 145,  46, 146,  47, 147,  48, 148,  49, 149]),\n",
    "                     10: np.array([ 50, 150,  51, 151,  52, 152,  53, 153,  54, 154]),\n",
    "                     11: np.array([ 55, 155,  56, 156,  57, 157,  58, 158,  59, 159]),\n",
    "                     12: np.array([ 60, 160,  61, 161,  62, 162,  63, 163,  64, 164]),\n",
    "                     13: np.array([ 65, 165,  66, 166,  67, 167,  68, 168,  69, 169]),\n",
    "                     14: np.array([ 70, 170,  71, 171,  72, 172,  73, 173,  74, 174]),\n",
    "                     15: np.array([ 75, 175,  76, 176,  77, 177,  78, 178,  79, 179]),\n",
    "                     16: np.array([ 80, 180,  81, 181,  82, 182,  83, 183,  84, 184]),\n",
    "                     17: np.array([ 85, 185,  86, 186,  87, 187,  88, 188,  89, 189]),\n",
    "                     18: np.array([ 90, 190,  91, 191,  92, 192,  93, 193,  94, 194]),\n",
    "                     19: np.array([ 95, 195,  96, 196,  97, 197,  98, 198,  99, 199])}\n",
    "\n",
    "indicesTracker = list()\n",
    "for i in range(len(indicesPerBin)):\n",
    "    test_eq(set(indicesPerBin[i]), set(indicesPerBinTest[i]))\n",
    "    test_eq(len(indicesPerBin[i]), len(np.unique(indicesPerBin[i])))\n",
    "    \n",
    "    indicesTracker.extend(indicesPerBin[i].tolist())\n",
    "\n",
    "test_eq(len(indicesTracker), len(np.unique(indicesTracker)))\n",
    "test_eq(np.sort(indicesTracker), np.arange(len(yPred)))\n",
    "    \n",
    "lowerBoundPerBinTest = [np.NINF] + list(np.arange(4.5, 99.5, 5))\n",
    "test_eq(list(lowerBoundPerBin), lowerBoundPerBinTest)\n",
    "test_eq(list(lowerBoundPerBin.index), [i for i in range(20)])\n",
    "\n",
    "#---\n",
    "\n",
    "# Check if creation of last bin works correctly\n",
    "yPred = np.append(np.arange(10), np.arange(10))\n",
    "indicesPerBin, lowerBoundPerBin = generateBins(binSize = 5, yPred = yPred)\n",
    "\n",
    "test_eq(list(indicesPerBin.keys()), [i for i in range(3)])\n",
    "\n",
    "indicesPerBinTest = {0: np.array([ 0, 10,  1, 11,  2, 12]),\n",
    "                     1: np.array([ 3, 13,  4, 14,  5, 15]),\n",
    "                     2: np.array([ 6, 16,  7, 17,  8, 18,  9, 19])}\n",
    "\n",
    "indicesTracker = list()\n",
    "for i in range(len(indicesPerBin)):\n",
    "    test_eq(set(indicesPerBin[i]), set(indicesPerBinTest[i]))\n",
    "    test_eq(len(indicesPerBin[i]), len(np.unique(indicesPerBin[i])))\n",
    "    \n",
    "    indicesTracker.extend(indicesPerBin[i].tolist())\n",
    "\n",
    "test_eq(len(indicesTracker), len(np.unique(indicesTracker)))\n",
    "test_eq(np.sort(indicesTracker), np.arange(len(yPred)))\n",
    "    \n",
    "lowerBoundPerBinTest = [np.NINF, 2.5, 5.5]\n",
    "test_eq(list(lowerBoundPerBin), lowerBoundPerBinTest)\n",
    "test_eq(list(lowerBoundPerBin.index), [i for i in range(3)])\n",
    "\n",
    "#---\n",
    "\n",
    "# yPred.unique() == 1\n",
    "yPred = np.repeat(1, 100)\n",
    "indicesPerBin, lowerBoundPerBin = generateBins(binSize = 5, yPred = yPred)\n",
    "\n",
    "test_eq(list(indicesPerBin.keys()), [0])\n",
    "\n",
    "indicesPerBinTest = {0: np.arange(0, 100, 1)}\n",
    "\n",
    "indicesTracker = list()\n",
    "for i in range(len(indicesPerBin)):\n",
    "    test_eq(set(indicesPerBin[i]), set(indicesPerBinTest[i]))\n",
    "    test_eq(len(indicesPerBin[i]), len(np.unique(indicesPerBin[i])))\n",
    "    \n",
    "    indicesTracker.extend(indicesPerBin[i].tolist())\n",
    "\n",
    "test_eq(len(indicesTracker), len(np.unique(indicesTracker)))\n",
    "test_eq(np.sort(indicesTracker), np.arange(len(yPred)))\n",
    "    \n",
    "lowerBoundPerBinTest = [np.NINF]\n",
    "test_eq(list(lowerBoundPerBin), lowerBoundPerBinTest)\n",
    "test_eq(list(lowerBoundPerBin.index), [i for i in range(1)])\n",
    "\n",
    "#---\n",
    "\n",
    "# binSize > len(yPred)\n",
    "yPred = np.arange(10)\n",
    "indicesPerBin, lowerBoundPerBin = generateBins(binSize = 100, yPred = yPred)\n",
    "\n",
    "test_eq(list(indicesPerBin.keys()), [0])\n",
    "\n",
    "indicesPerBinTest = {0: np.arange(0, 10, 1)}\n",
    "\n",
    "indicesTracker = list()\n",
    "for i in range(len(indicesPerBin)):\n",
    "    test_eq(set(indicesPerBin[i]), set(indicesPerBinTest[i]))\n",
    "    test_eq(len(indicesPerBin[i]), len(np.unique(indicesPerBin[i])))\n",
    "    \n",
    "    indicesTracker.extend(indicesPerBin[i].tolist())\n",
    "\n",
    "test_eq(len(indicesTracker), len(np.unique(indicesTracker)))\n",
    "test_eq(np.sort(indicesTracker), np.arange(len(yPred)))\n",
    "    \n",
    "lowerBoundPerBinTest = [np.NINF]\n",
    "test_eq(list(lowerBoundPerBin), lowerBoundPerBinTest)\n",
    "test_eq(list(lowerBoundPerBin.index), [i for i in range(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeb06f8-72fb-434f-88ab-6e592a15f327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b78a5d-cc2a-45c5-a4bf-81d5b584531e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99819d-ec03-4147-a1c7-30db22ef2579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LevelSetKDEx.getWeights() and LevelSetKDEx_kNN.getWeights()\n",
    "# for i in range(len(neighborsList)):\n",
    "#     if len(neighborsList[i]) < self.binSize:\n",
    "#         ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ba712-307c-4c2b-9496-98288c8fa992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generateBins\n",
    "# indices = np.array([])\n",
    "# for k in range(len(indicesPerBin.keys())):\n",
    "#     indices = np.append(indices, indicesPerBin[k])\n",
    "\n",
    "# if len(indices) != len(yPred):\n",
    "#     ipdb.set_trace()\n",
    "\n",
    "# predCheck = np.array([pred in binPerPred.keys() for pred in yPred])\n",
    "# keyCheck = np.array([key in yPred for key in binPerPred.keys()])\n",
    "\n",
    "# if (all(predCheck) & all(keyCheck)) is False:\n",
    "#     ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0c6e34-3490-453d-8302-910815a5260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LevelSetKDEx.getWeights()\n",
    "# check = [i for i in range(len(weightsDataList)) if len(weightsDataList[i][1]) > 100]\n",
    "# check2 = [i for i in range(len(weightsDataList)) if len(weightsDataList[i][1]) > 100 and binPerPred[i] != self.lowerBoundPerBin.index.max()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HC-Scheduling",
   "language": "python",
   "name": "hc-scheduling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
