{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61516f21-8606-49d3-8907-c0190315ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd6b76-2644-458b-8436-da808dd134c7",
   "metadata": {},
   "source": [
    "# Level-Set Based Kernel Density Estimation\n",
    "> Defining the classes `LevelSetKDEx` and `LevelSetKDEx_kNN` which turn any point predictor into a conditional kernel density estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7668fd2-5361-43a1-ba2b-42506a2419ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp levelSetKDEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8cef21-4158-4307-b898-6bc03398a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "# from nbdev.qmd import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d95d3a6-a5e0-46de-b191-d1de0281f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from fastcore.docments import *\n",
    "from fastcore.test import *\n",
    "from fastcore.utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from dddex.baseClasses import BaseWeightsBasedEstimator\n",
    "from dddex.wSAA import SampleAverageApproximation\n",
    "from dddex.utils import restructureWeightsDataList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b8315b-c072-4e14-b477-5856b5d922fe",
   "metadata": {},
   "source": [
    "In the following we define the classes `LevelSetKDEx` and `LevelSetKDEx_kNN` where KDE is short for 'Kernel Density Estimator' and the 'x' is supposed to signal that both classes can be defined based on any arbitrary point predictor. The name 'LevelSet' stems from the fact that every approach presented in this notebook interprets the values of the point forecasts as a similarity measure between samples. The point predictor is specified by the argument `estimator` and must have a `.predict()`-method and should have been trained before hand. \n",
    "\n",
    "Both classes `LevelSetKDEx` and `LevelSetKDEx_kNN` fulfill the same task: By first running `.fit(XTrain, yTrain)` and then calling `.generateWeights(XTest)`, they both output an estimation of the conditional density of every sample specified by 'XTest'. The basic idea for both approaches is also identical: Suppose we have a single test sample at hand. At first, we compare the value of the point prediction of this sample and the values of the point predictions of the training samples computed via `estimator.predict(XTrain)` and `estimator.predict(XTest)`, respectively. Based on this comparison, we select 'binSize'-many training samples that we deem the most similar to the test sample at hand. The concrete way we select the training samples constitutes the only difference between `LevelSetKDEx` and `LevelSetKDEx_kNN`. Finally, the empirical distribution of the y-values of these training samples then acts as our estimation of the conditional distribution.\n",
    "\n",
    "Further details on how both approaches work approaches can be found below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a870226b-528e-490a-b0b7-273f277cf1da",
   "metadata": {},
   "source": [
    "## Base Level-Set Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a712302d-46fb-4c47-8c4f-bad683afc9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BaseLSx:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 estimator, # (Fitted) object with a .predict-method.\n",
    "                 binSize: int = None, # Size of the bins created to group the training samples.\n",
    "                 weightsByDistance: bool = False,\n",
    "                 ):\n",
    "        \n",
    "        if not (hasattr(estimator, 'predict') and callable(estimator.predict)):\n",
    "            raise ValueError(\"'estimator' has to have a 'predict'-method!\")\n",
    "            \n",
    "        if not (isinstance(binSize, (int, np.integer)) or binSize is None):\n",
    "            raise ValueError(\"'binSize' has to be an integer!\")\n",
    "            \n",
    "        self.estimator = copy.deepcopy(estimator)\n",
    "        self.binSize = binSize\n",
    "        self.weightsByDistance = weightsByDistance      \n",
    "        \n",
    "    #---\n",
    "    \n",
    "    def pointPredict(self, \n",
    "                     X):\n",
    "        \n",
    "        return self.estimator.predict(X)\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    def refitPointEstimator(self,\n",
    "                            X, \n",
    "                            y\n",
    "                            ):\n",
    "        \n",
    "        setattr(self, 'estimator', self.estimator.fit(X = X, y = y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794a75d0-8a2c-4482-b372-6e67bf394d86",
   "metadata": {},
   "source": [
    "## Level-Set Approach based on Bin Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cebd8e-52d0-4a7f-af8f-75af78972824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class LevelSetKDEx(BaseWeightsBasedEstimator, BaseLSx):\n",
    "    \"\"\"\n",
    "    `LevelSetKDEx`\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 estimator, # Object with a .predict-method (fitted).\n",
    "                 binSize: int | None = None, # Size of the neighbors considered to compute conditional density.\n",
    "                 weightsByDistance: bool = False,\n",
    "                 ):\n",
    "        \n",
    "        super(BaseEstimator, self).__init__(estimator = estimator,\n",
    "                                            binSize = binSize,\n",
    "                                            weightsByDistance = weightsByDistance)\n",
    "\n",
    "        self.yTrain = None\n",
    "        self.yTrainPred = None\n",
    "        self.indicesPerBin = None\n",
    "        self.lowerBoundPerBin = None\n",
    "        self.fitted = False\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    def fit(self, \n",
    "            X: np.ndarray, # Feature matrix used by 'estimator' to predict 'y'.\n",
    "            y: np.ndarray, # 1-dimensional target variable corresponding to the features 'X'.\n",
    "            ):\n",
    "        \n",
    "        # Checks\n",
    "        if self.binSize is None:\n",
    "            raise ValueError(\"'binSize' must be specified to fit the LSx estimator!\")\n",
    "            \n",
    "        if self.binSize > y.shape[0]:\n",
    "            raise ValueError(\"'binSize' mustn't be bigger than the size of 'y'!\")\n",
    "        \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(\"'X' and 'y' must contain the same number of samples!\")\n",
    "        \n",
    "        # IMPORTANT: In case 'y' is given as a pandas.Series, we can potentially run into indexing \n",
    "        # problems later on.\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.ravel()\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        try:\n",
    "            yPred = self.estimator.predict(X)\n",
    "        except NotFittedError:\n",
    "            # warnings.warn(\"The object 'estimator' must have been fitted already!\"\n",
    "            #               \"'estimator' will be fitted with 'X' and 'y' to enable point predicting!\",\n",
    "            #               stacklevel = 2)\n",
    "            try:\n",
    "                self.estimator.fit(X = X, y = y)                \n",
    "            except:\n",
    "                raise ValueError(\"Couldn't fit 'estimator' with user specified 'X' and 'y'!\")\n",
    "            else:\n",
    "                yPred = self.estimator.predict(X)\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        indicesPerBin, lowerBoundPerBin = generateBins(binSize = self.binSize,\n",
    "                                                       yPred = yPred)\n",
    "\n",
    "        self.yTrain = y\n",
    "        self.yTrainPred = yPred\n",
    "        self.indicesPerBin = indicesPerBin\n",
    "        self.lowerBoundPerBin = lowerBoundPerBin\n",
    "        self.fitted = True\n",
    "        \n",
    "    #---\n",
    "    \n",
    "    def getWeights(self, \n",
    "                   X: np.ndarray, # Feature matrix of samples for which conditional density estimates are computed.\n",
    "                   outputType: 'all' | # Specifies structure of output.\n",
    "                               'onlyPositiveWeights' | \n",
    "                               'summarized' | \n",
    "                               'cumulativeDistribution' | \n",
    "                               'cumulativeDistributionSummarized' = 'onlyPositiveWeights', \n",
    "                   scalingList: list | np.ndarray | None = None, # List or array with same size as self.yTrain containing floats being multiplied with self.yTrain.\n",
    "                   ):\n",
    "        \n",
    "        if not self.fitted:\n",
    "            raise NotFittedError(\"This LevelSetKDEx instance is not fitted yet. Call 'fit' with \"\n",
    "                                 \"appropriate arguments before trying to compute weights.\")\n",
    "        \n",
    "        yPred = self.estimator.predict(X)\n",
    "        \n",
    "        binPerPred = np.searchsorted(a = self.lowerBoundPerBin, v = yPred, side = 'right') - 1\n",
    "        neighborsList = [self.indicesPerBin[binIndex] for binIndex in binPerPred]\n",
    "        \n",
    "        if self.weightsByDistance:\n",
    "\n",
    "            predDistances = [np.abs(self.yTrainPred[neighborsList[i]] - yPred[i]) for i in range(len(neighborsList))]\n",
    "\n",
    "            weightsDataList = list()\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                distances = predDistances[i]\n",
    "                distancesCloseZero = np.isclose(distances, 0)\n",
    "                \n",
    "                if np.any(distancesCloseZero):\n",
    "                    indicesCloseZero = neighborsList[i][np.where(distancesCloseZero)[0]]\n",
    "                    weightsDataList.append((np.repeat(1 / len(indicesCloseZero), len(indicesCloseZero)),\n",
    "                                            indicesCloseZero))\n",
    "                    \n",
    "                else:                                 \n",
    "                    inverseDistances = 1 / distances\n",
    "\n",
    "                    weightsDataList.append((inverseDistances / inverseDistances.sum(), \n",
    "                                            np.array(neighborsList[i])))\n",
    "            \n",
    "            weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "                                                         outputType = outputType, \n",
    "                                                         y = self.yTrain,\n",
    "                                                         scalingList = scalingList,\n",
    "                                                         equalWeights = False)\n",
    "        \n",
    "        else:\n",
    "            weightsDataList = [(np.repeat(1 / len(neighbors), len(neighbors)), np.array(neighbors)) for neighbors in neighborsList]\n",
    "\n",
    "            weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "                                                         outputType = outputType, \n",
    "                                                         y = self.yTrain,\n",
    "                                                         scalingList = scalingList,\n",
    "                                                         equalWeights = True)\n",
    "        \n",
    "        return weightsDataList\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8a8982-2492-463b-93c1-6a4eb0db2e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(LevelSetKDEx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdb5bf-f39d-470f-b7cc-8679e733b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(LevelSetKDEx.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca538d-96ff-48df-9e29-8573a6442a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(LevelSetKDEx.getWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661e147-5acc-4593-b3a5-e93f2d82447f",
   "metadata": {},
   "source": [
    "#### Generate Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0d9778-557b-4618-80a8-c440a81b2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def generateBins(binSize: int, # Size of the bins of values being grouped together.\n",
    "                 yPred: np.ndarray, # 1-dimensional array of predicted values.\n",
    "                 ):\n",
    "    \"Used to generate the bin-structure induced by the Level-Set-Forecaster algorithm\"\n",
    "    \n",
    "    predIndicesSort = np.argsort(yPred)\n",
    "    yPredSorted = yPred[predIndicesSort]\n",
    "\n",
    "    currentBinSize = 0\n",
    "    binIndex = 0\n",
    "    trainIndicesLeft = len(yPred)\n",
    "    indicesPerBin = defaultdict(list)\n",
    "    lowerBoundPerBin = dict()\n",
    "    \n",
    "    for i in range(len(yPred)):\n",
    "        \n",
    "        if i == 0:\n",
    "            lowerBoundPerBin[binIndex] = np.NINF\n",
    "            \n",
    "        currentBinSize += 1\n",
    "        trainIndicesLeft -= 1\n",
    "\n",
    "        indicesPerBin[binIndex].append(predIndicesSort[i])\n",
    "        \n",
    "        if trainIndicesLeft < binSize:\n",
    "            indicesPerBin[binIndex].extend(predIndicesSort[np.arange(i+1, len(yPred), 1)])\n",
    "            break\n",
    "\n",
    "        if currentBinSize >= binSize and yPredSorted[i] < yPredSorted[i+1]:\n",
    "            lowerBoundPerBin[binIndex + 1] = (yPredSorted[i] + yPredSorted[i+1]) / 2\n",
    "            binIndex += 1\n",
    "            currentBinSize = 0\n",
    "           \n",
    "    indicesPerBin = {binIndex: np.array(indices) for binIndex, indices in indicesPerBin.items()}\n",
    "    \n",
    "    lowerBoundPerBin = pd.Series(lowerBoundPerBin)\n",
    "    lowerBoundPerBin.index.name = 'binIndex'\n",
    "    \n",
    "    return indicesPerBin, lowerBoundPerBin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd550e-ae6e-44fe-a91b-f0ffee0096bc",
   "metadata": {},
   "source": [
    "## Level-Set Approach based on kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b41f2-b012-428e-a18c-6fa6c20690ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class LevelSetKDEx_kNN(BaseWeightsBasedEstimator, BaseLSx):\n",
    "    \"\"\"\n",
    "     `LevelSetKDEx_kNN` turns any point predictor that has a .predict-method \n",
    "    into an estimator of the condititional density of the underlying distribution.\n",
    "    The basic idea of each level-set based approach is to interprete the point forecast\n",
    "    generated by the underlying point predictor as a similarity measure of samples.\n",
    "    In the case of the `LevelSetKDEx_kNN` defined here, for every new samples\n",
    "    'binSize'-many training samples are computed whose point forecast is closest\n",
    "    to the point forecast of the new sample.\n",
    "    The resulting empirical distribution of these 'nearest' training samples are \n",
    "    viewed as our estimation of the conditional distribution of each the new sample \n",
    "    at hand.\n",
    "    \n",
    "    NOTE 1: The `LevelSetKDEx_kNN` class can only be applied to estimators that \n",
    "    have been fitted already.\n",
    "    \n",
    "    NOTE 2: In contrast to the standard `LevelSetKDEx`, it is possible to apply\n",
    "    `LevelSetKDEx_kNN` to arbitrary dimensional point predictors.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 estimator, # Object with a .predict-method (fitted).\n",
    "                 binSize: int | None = None, # Size of the neighbors considered to compute conditional density.\n",
    "                 weightsByDistance: bool = False,\n",
    "                 ):\n",
    "        \n",
    "        super(BaseEstimator, self).__init__(estimator = estimator,\n",
    "                                            binSize = binSize,\n",
    "                                            weightsByDistance = weightsByDistance)\n",
    "        \n",
    "        self.yTrain = None\n",
    "        self.yTrainPred = None\n",
    "        self.nearestNeighborsOnPreds = None\n",
    "        self.fitted = False\n",
    "        \n",
    "    #---\n",
    "    \n",
    "    def fit(self: LevelSetKDEx_kNN, \n",
    "            X: np.ndarray, # Feature matrix used by 'estimator' to predict 'y'.\n",
    "            y: np.ndarray, # Target variable corresponding to features 'X'.\n",
    "            ):\n",
    "        \n",
    "        # Checks\n",
    "        if self.binSize is None:\n",
    "            raise ValueError(\"'binSize' must be specified to fit the LSx estimator!\")\n",
    "            \n",
    "        if self.binSize > y.shape[0]:\n",
    "            raise ValueError(\"'binSize' mustn't be bigger than the size of 'y'!\")\n",
    "            \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(\"'X' and 'y' must contain the same number of samples!\")\n",
    "            \n",
    "        # IMPORTANT: In case 'y' is given as a pandas.Series, we can potentially run into indexing \n",
    "        # problems later on.\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.ravel()\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        try:\n",
    "            yPred = self.estimator.predict(X)\n",
    "        except NotFittedError:\n",
    "            # warnings.warn(\"The object 'estimator' must have been fitted already!\"\n",
    "            #               \"'estimator' will be fitted with 'X' and 'y' to enable point predicting!\",\n",
    "            #               stacklevel = 2)\n",
    "            try:\n",
    "                self.estimator.fit(X = X, y = y)                \n",
    "            except:\n",
    "                raise ValueError(\"Couldn't fit 'estimator' with user specified 'X' and 'y'!\")\n",
    "            else:\n",
    "                yPred = self.estimator.predict(X)\n",
    "\n",
    "        #---\n",
    "        \n",
    "        yPred_reshaped = np.reshape(yPred, newshape = (len(yPred), 1))\n",
    "        \n",
    "        nn = NearestNeighbors(algorithm = 'kd_tree')\n",
    "        nn.fit(X = yPred_reshaped)\n",
    "\n",
    "        #---\n",
    "\n",
    "        self.yTrain = y\n",
    "        self.yTrainPred = yPred\n",
    "        self.nearestNeighborsOnPreds = nn\n",
    "        self.fitted = True\n",
    "        \n",
    "    #---\n",
    "    \n",
    "    def getWeights(self: LevelSetKDEx_kNN, \n",
    "                   X: np.ndarray, # Feature matrix of samples for which conditional density estimates are computed.\n",
    "                   outputType: 'all' | # Specifies structure of output.\n",
    "                               'onlyPositiveWeights' | \n",
    "                               'summarized' | \n",
    "                               'cumulativeDistribution' | \n",
    "                               'cumulativeDistributionSummarized' = 'onlyPositiveWeights', \n",
    "                   scalingList: list | np.ndarray | None = None, # List or array with same size as self.yTrain containing floats being multiplied with self.yTrain.\n",
    "                  ):\n",
    "        \n",
    "        if not self.fitted:\n",
    "            raise NotFittedError(\"This LevelSetKDEx_kNN instance is not fitted yet. Call 'fit' with \"\n",
    "                                 \"appropriate arguments before trying to compute weights.\")\n",
    "            \n",
    "        #---\n",
    "\n",
    "        nn = self.nearestNeighborsOnPreds\n",
    "\n",
    "        #---\n",
    "\n",
    "        yPred = self.estimator.predict(X)   \n",
    "        yPred_reshaped = np.reshape(yPred, newshape = (len(yPred), 1))\n",
    "\n",
    "        distancesMatrix, neighborsMatrix = nn.kneighbors(X = yPred_reshaped, \n",
    "                                                         n_neighbors = self.binSize + 1)\n",
    "\n",
    "        #---\n",
    "\n",
    "        neighborsList = list(neighborsMatrix[:, 0:self.binSize])\n",
    "        distanceCheck = np.where(distancesMatrix[:, self.binSize - 1] == distancesMatrix[:, self.binSize])\n",
    "        indicesToMod = distanceCheck[0]\n",
    "\n",
    "        for index in indicesToMod:\n",
    "            distanceExtremePoint = np.absolute(yPred[index] - self.yTrainPred[neighborsMatrix[index, self.binSize-1]])\n",
    "\n",
    "            neighborsByRadius = nn.radius_neighbors(X = yPred_reshaped[index:index + 1], \n",
    "                                                    radius = distanceExtremePoint, return_distance = False)[0]\n",
    "            neighborsList[index] = neighborsByRadius\n",
    "\n",
    "        #---\n",
    "        \n",
    "        if self.weightsByDistance:\n",
    "            binSizesReal = [len(neighbors) for neighbors in neighborsList]\n",
    "            binSizeMax = max(binSizesReal)\n",
    "            \n",
    "            distancesMatrix, neighborsMatrix = nn.kneighbors(X = yPred_reshaped, \n",
    "                                                             n_neighbors = binSizeMax)\n",
    "            \n",
    "            weightsDataList = list()\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                distances = distancesMatrix[i, 0:binSizesReal[i]]\n",
    "                distancesCloseZero = np.isclose(distances, 0)\n",
    "                \n",
    "                if np.any(distancesCloseZero):\n",
    "                    indicesCloseZero = neighborsMatrix[i, np.where(distancesCloseZero)[0]]\n",
    "                    weightsDataList.append((np.repeat(1 / len(indicesCloseZero), len(indicesCloseZero)),\n",
    "                                            indicesCloseZero))\n",
    "                    \n",
    "                else:                                 \n",
    "                    inverseDistances = 1 / distances\n",
    "\n",
    "                    weightsDataList.append((inverseDistances / inverseDistances.sum(), \n",
    "                                            np.array(neighborsList[i])))\n",
    "            \n",
    "            weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "                                                         outputType = outputType, \n",
    "                                                         y = self.yTrain,\n",
    "                                                         scalingList = scalingList,\n",
    "                                                         equalWeights = False)\n",
    "            \n",
    "        else:\n",
    "            weightsDataList = [(np.repeat(1 / len(neighbors), len(neighbors)), np.array(neighbors)) for neighbors in neighborsList]\n",
    "\n",
    "            weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "                                                         outputType = outputType, \n",
    "                                                         y = self.yTrain,\n",
    "                                                         scalingList = scalingList,\n",
    "                                                         equalWeights = True)\n",
    "\n",
    "        return weightsDataList\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08104da-f4fb-4b87-b86c-66867fb6cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(LevelSetKDEx_kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9daa50-ef7b-4858-b343-b212f07a02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(LevelSetKDEx_kNN.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97f4603-b305-464c-a67b-45ff7be439ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(LevelSetKDEx_kNN.getWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7dafad-822e-4399-9dac-c2c07e14a870",
   "metadata": {},
   "source": [
    "## Bin-Size CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9efbd-4d21-4bc5-8bd9-82015cbb2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class binSizeCV:\n",
    "\n",
    "    def __init__(self,\n",
    "                 estimatorLSx, # Object with a .predict-method (fitted).\n",
    "                 cvFolds, # Specifies cross-validation-splits. Identical to 'cv' used for cross-validation in sklearn.\n",
    "                 binSizeGrid: list | np.ndarray = [4, 7, 10, 15, 20, 30, 40, 50, 60, 70, 80, \n",
    "                                                   100, 125, 150, 200, 250, 300, 350, 400, 450, 500, 600, 700, 800, 900,\n",
    "                                                   1000, 1250, 1500, 1750, 2000, 2500, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000], # binSize (int) values being evaluated.                \n",
    "                 probs: list | np.ndarray = [i / 100 for i in range(1, 100, 1)], # list or array of floats between 0 and 1. p-quantiles being predicted to evaluate performance of LSF.\n",
    "                 refitPerProb: bool = False, # If True, for each p-quantile a fitted LSF with best binSize to predict it is returned. Otherwise only one LSF is returned that is best over all probs.\n",
    "                 n_jobs: int | None = None, # number of folds being computed in parallel.\n",
    "                 ):\n",
    "        \n",
    "        # CHECKS  \n",
    "        if not isinstance(estimatorLSx, (LevelSetKDEx, LevelSetKDEx_kNN)):\n",
    "            raise ValueError(\"'estimatorLSx' has to be a 'LevelSetKDEx'- or a 'LevelSetKDEx_kNN'-object!\")               \n",
    "            \n",
    "        if np.any(np.array(probs) > 1) or np.any(np.array(probs) < 0): \n",
    "            raise ValueError(\"probs must only contain numbers between 0 and 1!\")            \n",
    "            \n",
    "        if any([not isinstance(binSize, int) for binSize in binSizeGrid]): \n",
    "            raise ValueError(\"'binSizeGrid' may only contain integer values!\")\n",
    "        \n",
    "        self.estimatorLSx = copy.deepcopy(estimatorLSx)\n",
    "        self.probs = probs\n",
    "        self.binSizeGrid = binSizeGrid        \n",
    "        self.cvFolds = cvFolds\n",
    "        self.refitPerProb = refitPerProb\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "        self.bestBinSize = None\n",
    "        self.bestBinSize_perProb = None\n",
    "        self.bestEstimatorLSx = None\n",
    "        self.cv_results = None\n",
    "        self.cv_results_raw = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f38ec08-8835-4c32-9979-5a71d90fd150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(binSizeCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee798f7-e38d-4fe1-a359-f16ae255f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def fit(self: binSizeCV, \n",
    "        X, \n",
    "        y):\n",
    "    \n",
    "    # Making sure that X and y are arrays to ensure correct subsetting via implicit indices.\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    nSmallestTrainSample = len(self.cvFolds[0][0])\n",
    "    self.binSizeGrid = [binSize for binSize in self.binSizeGrid if binSize <= nSmallestTrainSample]\n",
    "    \n",
    "    scoresPerFold = Parallel(n_jobs = self.n_jobs)(delayed(scoresForFold)(cvFold = cvFold,\n",
    "                                                                          binSizeGrid = self.binSizeGrid,\n",
    "                                                                          probs = self.probs,\n",
    "                                                                          estimatorLSx = copy.deepcopy(self.estimatorLSx),\n",
    "                                                                          y = y,\n",
    "                                                                          X = X) for cvFold in self.cvFolds)\n",
    "    \n",
    "    # scoresPerFold = [scoresForFold(cvFold = cvFold,\n",
    "    #                                binSizeGrid = self.binSizeGrid,\n",
    "    #                                probs = self.probs,\n",
    "    #                                estimatorLSx = copy.deepcopy(self.estimatorLSx),\n",
    "    #                                y = y,\n",
    "    #                                X = X) for cvFold in self.cvFolds]\n",
    "\n",
    "    self.cv_results_raw = scoresPerFold\n",
    "    meanCostsDf = sum(scoresPerFold) / len(scoresPerFold)\n",
    "    self.cv_results = meanCostsDf\n",
    "    \n",
    "    #---\n",
    "\n",
    "    meanCostsPerBinSize = meanCostsDf.mean(axis = 1)\n",
    "    binSizeBestOverall = meanCostsPerBinSize.index[np.argmin(meanCostsPerBinSize)]\n",
    "    self.bestBinSize = binSizeBestOverall\n",
    "\n",
    "    binSizeBestPerProb = meanCostsDf.idxmin(axis = 0)\n",
    "    self.bestBinSize_perProb = binSizeBestPerProb\n",
    "\n",
    "    #---\n",
    "\n",
    "    if self.refitPerProb:\n",
    "        bestEstimatorDict = dict()\n",
    "        \n",
    "        for prob in self.probs:\n",
    "            # Note: In future versions this could has to be flexible in the sense\n",
    "            # to be able to create new objects with the best parameters found via CV\n",
    "            # where the tuned parameters can vary (currently only binSize).\n",
    "            estimatorLSx = copy.deepcopy(self.estimatorLSx)\n",
    "            estimatorLSx.set_params(binSize = binSizeBestPerProb.loc[prob])\n",
    "            estimatorLSx.fit(X = X, y = y)\n",
    "\n",
    "            bestEstimatorDict[prob] = estimatorLSx\n",
    "\n",
    "        self.bestEstimatorLSx = bestEstimatorDict\n",
    "\n",
    "    else:\n",
    "        estimatorLSx = copy.deepcopy(self.estimatorLSx)\n",
    "        estimatorLSx.set_params(binSize = binSizeBestOverall)\n",
    "        estimatorLSx.fit(X = X, y = y)\n",
    "\n",
    "        self.bestEstimatorLSx = estimatorLSx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6475323-2d18-489d-88f2-1675a3f7198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(binSizeCV.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf7bd61-adb2-42cc-93f9-9734d6d39f57",
   "metadata": {},
   "source": [
    "#### Scores for Single Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e17b4-a9ca-4d19-a8db-c2b6879cbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# This function evaluates the newsvendor performance for different bin sizes for one specific fold.\n",
    "# The considered bin sizes\n",
    "\n",
    "def scoresForFold(cvFold, binSizeGrid, probs, estimatorLSx, y, X):\n",
    "    \n",
    "    indicesTrain = cvFold[0]\n",
    "    indicesTest = cvFold[1]\n",
    "    \n",
    "    yTrainFold = y[indicesTrain]\n",
    "    XTrainFold = X[indicesTrain]\n",
    "    \n",
    "    yTestFold = y[indicesTest]\n",
    "    XTestFold = X[indicesTest]\n",
    "    \n",
    "    estimatorLSx.refitPointEstimator(X = XTrainFold, y = yTrainFold)\n",
    "    \n",
    "    #---\n",
    "       \n",
    "    SAA_fold = SampleAverageApproximation()\n",
    "    SAA_fold.fit(y = yTrainFold)\n",
    "    \n",
    "    # By setting 'X = None', the SAA results are only computed for a single observation (they are independent of X anyway).\n",
    "    # In order to receive the final dataframe of SAA results, we simply duplicate this single row as many times as needed.\n",
    "    quantilesDictSAAOneOb = SAA_fold.predict(X = None, probs = probs, outputAsDf = False)\n",
    "    quantilesDictSAA = {prob: np.repeat(quantile, len(XTestFold)) for prob, quantile in quantilesDictSAAOneOb.items()}\n",
    "    \n",
    "    #---\n",
    "                                                   \n",
    "    costRatiosPerBinSize = defaultdict(dict)\n",
    "\n",
    "    for binSize in iter(binSizeGrid):\n",
    "        \n",
    "        estimatorLSx.set_params(binSize = binSize)\n",
    "        \n",
    "        estimatorLSx.fit(X = XTrainFold,\n",
    "                         y = yTrainFold)\n",
    "        \n",
    "        quantilesDict = estimatorLSx.predict(X = XTestFold,\n",
    "                                             probs = probs,\n",
    "                                             outputAsDf = False)\n",
    "        \n",
    "        #---\n",
    "\n",
    "        costRatioDict = dict()\n",
    "        \n",
    "        for prob in probs:            \n",
    "            costRatioDict[prob] = getCostRatio(decisions = quantilesDict[prob], \n",
    "                                               decisionsSAA = quantilesDictSAA[prob], \n",
    "                                               yTest = yTestFold, \n",
    "                                               prob = prob)\n",
    "        \n",
    "        costRatiosPerBinSize[binSize] = costRatioDict\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    costRatioDf = pd.DataFrame.from_dict(costRatiosPerBinSize, orient = 'index')\n",
    "    \n",
    "    return costRatioDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5121f5c4-fab2-4788-8691-ffbef17d703f",
   "metadata": {},
   "source": [
    "##### Get Cost Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a49f19-5f88-4600-bb1d-ff237b7daf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def getCostRatio(decisions, decisionsSAA, yTest, prob):\n",
    "\n",
    "    # Newsvendor Costs of our model\n",
    "    cost = np.array([prob * (yTest[i] - decisions[i]) if yTest[i] > decisions[i] \n",
    "                     else (1 - prob) * (decisions[i] - yTest[i]) \n",
    "                     for i in range(len(yTest))]).sum()\n",
    "    \n",
    "    # Newsvendor Costs of SAA\n",
    "    costSAA = np.array([prob * (yTest[i] - decisionsSAA[i]) if yTest[i] > decisionsSAA[i] \n",
    "                        else (1 - prob) * (decisionsSAA[i] - yTest[i]) \n",
    "                        for i in range(len(yTest))]).sum()\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    # We have to capture the special case of costSAA == 0, because then we can't compute the \n",
    "    # Cost-Ratio using the actual definition.\n",
    "    if costSAA > 0:\n",
    "        costRatio = cost / costSAA\n",
    "    else:\n",
    "        if cost == 0:\n",
    "            costRatio = 0\n",
    "        else:\n",
    "            costRatio = 1\n",
    "    \n",
    "    return costRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79762a-1427-49d7-b8b2-42ecde48e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81936321-7fe7-4b27-91e3-a4a1444bd29e",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f055de-89ce-4943-8242-8f434ee8a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from dddex.loadData import *\n",
    "\n",
    "# data, XTrain, yTrain, XTest, yTest = loadDataYaz(testDays = 14, \n",
    "#                                                  returnXY = True,\n",
    "#                                                  daysToCut = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd2880-1b9e-4d07-ab84-4ba8a2bef226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# LGBM = LGBMRegressor(boosting_type = 'gbdt',\n",
    "#                      n_jobs = 1)\n",
    "\n",
    "# LGBM.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1533bbef-fe12-4600-85a7-07cd9dc05fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# LS_KDEx = LevelSetKDEx(estimator = LGBM, binSize = 200, weightsByDistance = True)\n",
    "# LS_KDEx.fit(XTrain, yTrain)\n",
    "\n",
    "# LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 100)\n",
    "# # LS_KDEx_kNN.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f41dfeb-6655-4cf0-8961-74bb4d14ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# from dddex.utils import groupedTimeSeriesSplit\n",
    "\n",
    "# dataTrain = data[data.label == 'train']\n",
    "\n",
    "# cvFolds = groupedTimeSeriesSplit(data = dataTrain, \n",
    "#                                  kFolds = 3, \n",
    "#                                  testLength = 28, \n",
    "#                                  groupFeature = 'id', \n",
    "#                                  timeFeature = 'dayIndex')\n",
    "\n",
    "# CV = binSizeCV(estimatorLSx = LS_KDEx,\n",
    "#                cvFolds = cvFolds,\n",
    "#                binSizeGrid = [10, 100, 1000],\n",
    "#                probs = [0.001, 0.5, 0.999],\n",
    "#                refitPerProb = False)\n",
    "\n",
    "# CV.fit(X = XTrain, y = yTrain)\n",
    "\n",
    "# CV2 = binSizeCV(estimatorLSx = LS_KDEx_kNN,\n",
    "#                 cvFolds = cvFolds,\n",
    "#                 binSizeGrid = [10, 100, 1000],\n",
    "#                 probs = [0.001, 0.5, 0.999],\n",
    "#                 refitPerProb = False)\n",
    "\n",
    "# CV2.fit(X = XTrain, y = yTrain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HC-Scheduling",
   "language": "python",
   "name": "hc-scheduling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
