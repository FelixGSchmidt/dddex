{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61516f21-8606-49d3-8907-c0190315ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd6b76-2644-458b-8436-da808dd134c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# LSF\n",
    "\n",
    "> Module description for LSF classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7668fd2-5361-43a1-ba2b-42506a2419ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp levelSetForecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8cef21-4158-4307-b898-6bc03398a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "# \n",
    "# from nbdev.qmd import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a90d0f-dcd4-4306-81d0-3ceb810708a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d95d3a6-a5e0-46de-b191-d1de0281f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from fastcore.docments import *\n",
    "from fastcore.test import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors \n",
    "from collections import Counter, defaultdict\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "\n",
    "from dddex.core import BaseWeightsBasedPredictor, restructureWeightsDataList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794a75d0-8a2c-4482-b372-6e67bf394d86",
   "metadata": {},
   "source": [
    "# LSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8cebd8e-52d0-4a7f-af8f-75af78972824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class LevelSetForecaster(BaseWeightsBasedPredictor):\n",
    "    \"\"\"`LevelSetForecaster` turns any estimator that has a .predict-method into\n",
    "    a condititional density estimator. The `LevelSetForecaster`-class is supposed\n",
    "    to be applied to estimators that have been fit already.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 estimator, # (Fitted) object with a .predict-method.\n",
    "                 binSize: int = None # Size of the bins created during fitting.\n",
    "                 ):\n",
    "        \n",
    "        if not (hasattr(estimator, 'predict') and callable(estimator.predict)):\n",
    "            raise ValueError(\"'estimator' has to have a 'predict'-method!\")\n",
    "        else:\n",
    "            self.estimator = estimator\n",
    "            \n",
    "        if not (isinstance(binSize, (int, np.integer)) or binSize is None):\n",
    "            raise ValueError(\"'binSize' has to be integer (or None if it is supposed to be tuned)!\")\n",
    "        else:\n",
    "            self.binSize = binSize\n",
    "        \n",
    "        self.estimator = estimator\n",
    "        self.binSize = binSize\n",
    "        \n",
    "        self.Y = None\n",
    "        self.YPred = None\n",
    "        self.binPerTrainPred = None\n",
    "        self.indicesPerBin = None\n",
    "        self.nearestNeighborsOnPreds = None\n",
    "        \n",
    "    #---\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"LevelSetForecaster(estimator = {self.estimator}, binSize = {self.binSize})\"\n",
    "    __repr__ = __str__\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    def fit(self, \n",
    "            X: np.ndarray, # Feature matrix used by 'estimator' to predict 'Y'.\n",
    "            Y: np.ndarray, # 1-dimensional target variable corresponding to the features 'X'.\n",
    "            ):\n",
    "        \n",
    "        YPredTrain = self.estimator.predict(X)\n",
    "        \n",
    "        binPerTrainPred, indicesPerBin = generateBins(binSize = self.binSize,\n",
    "                                                      YPredTrain = YPredTrain)\n",
    "\n",
    "        #---\n",
    "        \n",
    "        nn = NearestNeighbors(algorithm = 'kd_tree')\n",
    "        YPredTrain_reshaped = np.reshape(YPredTrain, newshape = (len(YPredTrain), 1))\n",
    "\n",
    "        nn.fit(X = YPredTrain_reshaped)\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        self.Y = Y\n",
    "        self.YPredTrain = YPredTrain\n",
    "        self.binPerTrainPred = binPerTrainPred\n",
    "        self.indicesPerBin = indicesPerBin\n",
    "        self.nearestNeighborsOnPreds = nn\n",
    "        \n",
    "    #---\n",
    "        \n",
    "    def getWeightsData(self, \n",
    "                       X: np.ndarray, # Feature matrix for whose rows conditional density estimates are computed.\n",
    "                       outputType: 'all' | # Specifies structure of output.\n",
    "                                   'onlyPositiveWeights' | \n",
    "                                   'summarized' | \n",
    "                                   'cumulativeDistribution' | \n",
    "                                   'cumulativeDistributionSummarized' = 'onlyPositiveWeights', \n",
    "                       scalingList: list | np.ndarray | None = None, # List or array with same size as self.Y containing floats being multiplied with self.Y.\n",
    "                       ):\n",
    "        \n",
    "        binPerTrainPred = self.binPerTrainPred\n",
    "        indicesPerBin = self.indicesPerBin\n",
    "        nearestNeighborsOnPreds = self.nearestNeighborsOnPreds\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        YPred = self.estimator.predict(X)   \n",
    "        YPred_reshaped = np.reshape(YPred, newshape = (len(YPred), 1))\n",
    "        \n",
    "        nearestPredIndex = nearestNeighborsOnPreds.kneighbors(X = YPred_reshaped, \n",
    "                                                              n_neighbors = 1, \n",
    "                                                              return_distance = False).ravel()\n",
    "        \n",
    "        nearestPredNeighbor = self.YPredTrain[nearestPredIndex]\n",
    "\n",
    "        neighborsList = [indicesPerBin[binPerTrainPred[nearestPredNeighbor[i]]] for i in range(len(YPred))]\n",
    "\n",
    "        #---\n",
    "        \n",
    "        # Checks        \n",
    "        for i in range(len(neighborsList)):\n",
    "            if len(neighborsList[i]) < self.binSize:\n",
    "                ipdb.set_trace()\n",
    "\n",
    "        #---\n",
    "        \n",
    "        # weightsDataList is a list whose elements correspond to one test prediction each. \n",
    "        weightsDataList = [(np.repeat(1 / len(neighbors), len(neighbors)), np.array(neighbors)) for neighbors in neighborsList]\n",
    "\n",
    "        weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "                                                     outputType = outputType, \n",
    "                                                     Y = self.Y,\n",
    "                                                     scalingList = scalingList,\n",
    "                                                     equalWeights = True)\n",
    "\n",
    "        return weightsDataList\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56716375-a99f-4e06-a7bf-1d88a1deb06c",
   "metadata": {},
   "source": [
    "## Generate Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeff05d2-7747-437c-9fcc-ebeaec04b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def generateBins(binSize: int, # Size of the bins of values being grouped together.\n",
    "                 YPredTrain: np.ndarray, # 1-dimensional array of predicted values.\n",
    "                 ):\n",
    "    \"Used to generate the bin-structure induced by the Level-Set-Forecaster algorithm\"\n",
    "    \n",
    "    YPredTrainUnique = pd.Series(YPredTrain).unique()\n",
    "    predIndicesSort = np.argsort(YPredTrainUnique)\n",
    "    \n",
    "    YPredTrainUniqueSorted = YPredTrainUnique[predIndicesSort]\n",
    "    indicesByPredTrain = [np.where(pred == YPredTrain)[0] for pred in YPredTrainUniqueSorted]\n",
    "    \n",
    "    currentBinSize = 0\n",
    "    binIndex = 0\n",
    "    binExisting = False\n",
    "    trainIndicesLeft = len(YPredTrain)\n",
    "    binPerPred = dict()\n",
    "    indicesPerBin = dict()\n",
    "\n",
    "    for i in range(len(indicesByPredTrain)):\n",
    "        currentBinSize += len(indicesByPredTrain[i])\n",
    "        binPerPred[YPredTrainUniqueSorted[i]] = binIndex\n",
    "        \n",
    "        if binExisting:\n",
    "            indicesPerBin[binIndex] = np.append(indicesPerBin[binIndex], indicesByPredTrain[i])\n",
    "        else:\n",
    "            indicesPerBin[binIndex] = indicesByPredTrain[i]\n",
    "            binExisting = True\n",
    "\n",
    "        trainIndicesLeft -= len(indicesByPredTrain[i])\n",
    "        if trainIndicesLeft < binSize:\n",
    "            for j in np.arange(i+1, len(indicesByPredTrain), 1):\n",
    "                binPerPred[YPredTrainUniqueSorted[j]] = binIndex\n",
    "                indicesPerBin[binIndex] = np.append(indicesPerBin[binIndex], indicesByPredTrain[j])\n",
    "            break\n",
    "\n",
    "        if currentBinSize >= binSize:\n",
    "            binIndex += 1\n",
    "            currentBinSize = 0\n",
    "            binExisting = False\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    # Checks\n",
    "    \n",
    "    indices = np.array([])\n",
    "    for k in range(len(indicesPerBin.keys())):\n",
    "        indices = np.append(indices, indicesPerBin[k])\n",
    " \n",
    "    if len(indices) != len(YPredTrain):\n",
    "        ipdb.set_trace()\n",
    "    \n",
    "    predCheck = np.array([pred in binPerPred.keys() for pred in YPredTrain])\n",
    "    keyCheck = np.array([key in YPredTrain for key in binPerPred.keys()])\n",
    "    \n",
    "    if (all(predCheck) & all(keyCheck)) is False:\n",
    "        ipdb.set_trace()\n",
    "    \n",
    "    return binPerPred, indicesPerBin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd550e-ae6e-44fe-a91b-f0ffee0096bc",
   "metadata": {},
   "source": [
    "# LSF kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6155ad90-4e15-40ae-8e84-6b9394babd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class LevelSetForecaster_kNN(BaseWeightsBasedPredictor):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 estimator, # Object with a .predict-method (fitted).\n",
    "                 binSize: int | None = None, # Size of the bins created during fitting.\n",
    "                 ):\n",
    "        \n",
    "        if not (hasattr(estimator, 'predict') and callable(estimator.predict)):\n",
    "            raise ValueError(\"'estimator' has to have a 'predict'-method!\")\n",
    "        else:\n",
    "            self.estimator = estimator\n",
    "            \n",
    "        if not isinstance(binSize, (int, np.integer)):\n",
    "            raise ValueError(\"'binSize' has to be integer!\")\n",
    "        else:\n",
    "            self.binSize = binSize\n",
    "        \n",
    "        self.estimator = estimator\n",
    "        self.binSize = binSize\n",
    "        \n",
    "        self.Y = None\n",
    "        self.YPred = None\n",
    "        self.nearestNeighborsOnPreds = None\n",
    "        \n",
    "    #---\n",
    "    \n",
    "    def setBinSize(self, binSize):\n",
    "        self.binSize = binSize\n",
    "        \n",
    "    #---\n",
    "    \n",
    "    def fit(self, \n",
    "            X: np.ndarray, # Feature matrix used by 'estimator' to predict 'Y'.\n",
    "            Y: np.ndarray, # 1-dimensional target variable corresponding to features 'X'.\n",
    "            ):\n",
    "        \n",
    "        YPredTrain = self.estimator.predict(X)\n",
    "        YPredTrain_reshaped = np.reshape(YPredTrain, newshape = (len(YPredTrain), 1))\n",
    "        \n",
    "        nn = NearestNeighbors(algorithm = 'kd_tree')\n",
    "        nn.fit(X = YPredTrain_reshaped)\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        self.Y = Y\n",
    "        self.YPredTrain = YPredTrain\n",
    "        self.nearestNeighborsOnPreds = nn\n",
    "        \n",
    "    #---\n",
    "        \n",
    "    def getWeightsData(self, \n",
    "                       X: np.ndarray, # Feature matrix for whose rows conditional density estimates are computed.\n",
    "                       outputType: 'all' | # Specifies structure of output.\n",
    "                                   'onlyPositiveWeights' | \n",
    "                                   'summarized' | \n",
    "                                   'cumulativeDistribution' | \n",
    "                                   'cumulativeDistributionSummarized' = 'onlyPositiveWeights', \n",
    "                       scalingList: list | np.ndarray | None = None, # List or array with same size as self.Y containing floats being multiplied with self.Y.\n",
    "                       ):\n",
    "        \n",
    "        nn = self.nearestNeighborsOnPreds\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        YPred = self.estimator.predict(X)   \n",
    "        YPred_reshaped = np.reshape(YPred, newshape = (len(YPred), 1))\n",
    "        \n",
    "        distancesDf, neighborsMatrix = nn.kneighbors(X = YPred_reshaped, \n",
    "                                                     n_neighbors = self.binSize + 1)\n",
    "        \n",
    "        #---\n",
    "\n",
    "        neighborsList = list(neighborsMatrix[:, 0:self.binSize])\n",
    "        distanceCheck = np.where(distancesDf[:, self.binSize - 1] == distancesDf[:, self.binSize])\n",
    "        indicesToMod = distanceCheck[0]\n",
    "\n",
    "        for index in indicesToMod:\n",
    "            distanceExtremePoint = np.absolute(YPred[index] - self.YPredTrain[neighborsMatrix[index, self.binSize-1]])\n",
    "            \n",
    "            neighborsByRadius = nn.radius_neighbors(X = YPred_reshaped[index:index + 1], \n",
    "                                                    radius = distanceExtremePoint, return_distance = False)[0]\n",
    "            neighborsList[index] = neighborsByRadius\n",
    "\n",
    "        #---\n",
    "        \n",
    "        for i in range(len(neighborsList)):\n",
    "            if len(neighborsList[i]) < self.binSize:\n",
    "                ipdb.set_trace()\n",
    "\n",
    "        #---\n",
    "                        \n",
    "        # weightsDataList is a list whose elements correspond to one test prediction each. \n",
    "        weightsDataList = [(np.repeat(1 / len(neighbors), len(neighbors)), np.array(neighbors)) for neighbors in neighborsList]\n",
    "\n",
    "        weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "                                                     outputType = outputType, \n",
    "                                                     Y = self.Y,\n",
    "                                                     scalingList = scalingList,\n",
    "                                                     equalWeights = True)\n",
    "\n",
    "        return weightsDataList\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7dafad-822e-4399-9dac-c2c07e14a870",
   "metadata": {},
   "source": [
    "# LSF Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cb9efbd-4d21-4bc5-8bd9-82015cbb2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class binSizeCV:\n",
    "\n",
    "    def __init__(self,\n",
    "                 estimator, # Object with a .predict-method (fitted).\n",
    "                 cv, # Specifies cross-validation-splits. Identical to 'cv' used for cross-validation in sklearn.\n",
    "                 LSF_type: 'LSF' | 'LSF_kNN', # Specifies which LSF-Object we work with during cross-validation.\n",
    "                 binSizeGrid: list | np.ndarray = [4, 7, 10, 15, 20, 30, 40, 50, 60, 70, 80, \n",
    "                                                   100, 125, 150, 200, 250, 300, 350, 400, 450, 500, 600, 700, 800, 900,\n",
    "                                                   1000, 1250, 1500, 1750, 2000, 2500, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000], # binSize (int) values being evaluated.                \n",
    "                 probs: list | np.ndarray = [i / 100 for i in range(1, 100, 1)], # list or array of floats between 0 and 1. p-quantiles being predicted to evaluate performance of LSF.\n",
    "                 refitPerProb: bool = False, # If True, for each p-quantile a fitted LSF with best binSize to predict it is returned. Otherwise only one LSF is returned that is best over all probs.\n",
    "                 n_jobs: int | None = None, # number of folds being computed in parallel.\n",
    "                 ):\n",
    "        \n",
    "        # CHECKS\n",
    "        \n",
    "        if isinstance(estimator, (LevelSetForecaster, LevelSetForecaster_kNN)):\n",
    "            raise ValueError(\"'estimator' has to be a point predictor and not a LevelSetForecaster-Object!\")   \n",
    "        elif not (hasattr(estimator, 'predict') and callable(estimator.predict)):\n",
    "            raise ValueError(\"'estimator' has to have a 'predict'-method!\")\n",
    "        else:\n",
    "            self.estimator = estimator\n",
    "            \n",
    "        if LSF_type is None or not LSF_type in [\"LSF\", \"LSF_kNN\"]:\n",
    "            raise ValueError(\"LSF_type must be specified and must either be 'LSF' or 'LSF_kNN'!\")\n",
    "        else:\n",
    "            self.LSF_type = LSF_type\n",
    "            \n",
    "        if np.any(np.array(probs) > 1) or np.any(np.array(probs) < 0): \n",
    "            raise ValueError(\"probs must only contain numbers between 0 and 1!\")\n",
    "        else:\n",
    "            self.probs = probs\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        self.binSizeGrid = binSizeGrid        \n",
    "        self.cv = cv\n",
    "        self.refitPerProb = refitPerProb\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "        self.best_binSize = None\n",
    "        self.best_binSize_perProb = None\n",
    "        self.best_estimatorLSF = None\n",
    "        self.cv_results = None\n",
    "        self.cv_results_raw = None\n",
    "        \n",
    "    #---\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "    \n",
    "        scoresPerFold = Parallel(n_jobs = self.n_jobs)(delayed(scoresForFold)(cvFold = cvFold,\n",
    "                                                                              binSizeGrid = self.binSizeGrid,\n",
    "                                                                              probs = self.probs,\n",
    "                                                                              estimator = self.estimator,\n",
    "                                                                              LSF_type = self.LSF_type,\n",
    "                                                                              Y = Y,\n",
    "                                                                              X = X) for cvFold in cvFolds)    \n",
    "        \n",
    "        self.cv_results_raw = scoresPerFold\n",
    "        \n",
    "        #---\n",
    "\n",
    "        nvCostsMatrix = scoresPerFold[0]\n",
    "\n",
    "        for i in range(1, len(scoresPerFold)):\n",
    "            nvCostsMatrix = nvCostsMatrix + scoresPerFold[i]\n",
    "\n",
    "        nvCostsMatrix = nvCostsMatrix / len(cvFolds)\n",
    "        \n",
    "        self.cv_results = nvCostsMatrix\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        meanCostsDf = nvCostsMatrix.mean(axis = 1)\n",
    "        binSizeBestOverall = meanCostsDf.index[np.argmax(meanCostsDf)]\n",
    "        self.best_binSize = binSizeBestOverall\n",
    "        \n",
    "        binSizeBestPerProb = nvCostsMatrix.idxmax(axis = 0)\n",
    "        self.best_binSize_perProb = binSizeBestPerProb\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        if self.refitPerProb:\n",
    "            \n",
    "            LSFDict = dict()\n",
    "            for binSize in binSizeBestPerProb.unique():\n",
    "                \n",
    "                if self.LSF_type == 'LSF':\n",
    "                    LSF = LevelSetForecaster(estimator = self.estimator, \n",
    "                                             binSize = binSize)\n",
    "                else:\n",
    "                    LSF = LevelSetForecaster_kNN(estimator = self.estimator, \n",
    "                                                 binSize = binSize)\n",
    "                \n",
    "                LSF.fit(X = X, Y = Y)\n",
    "                LSFDict[binSize] = LSF\n",
    "            \n",
    "            self.best_estimatorLSF = {prob: LSFDict[binSizeBestPerProb.loc[prob]] \n",
    "                                      for prob in binSizeBestPerProb.index}\n",
    "        \n",
    "        else:\n",
    "            if self.LSF_type == 'LSF':\n",
    "                LSF = LevelSetForecaster(estimator = self.estimator, \n",
    "                                         binSize = binSizeBestOverall)\n",
    "            else:\n",
    "                LSF = LevelSetForecaster_kNN(estimator = self.estimator, \n",
    "                                             binSize = binSizeBestOverall)\n",
    "            \n",
    "            LSF.fit(X = X, Y = Y)\n",
    "            \n",
    "            self.best_estimatorLSF = LSF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf7bd61-adb2-42cc-93f9-9734d6d39f57",
   "metadata": {},
   "source": [
    "## Scores for Single Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c332bea-53fe-41b2-9706-fa0129bbbfeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf5e17b4-a9ca-4d19-a8db-c2b6879cbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# This function evaluates the newsvendor performance for different bin sizes for one specific fold.\n",
    "# The considered bin sizes\n",
    "\n",
    "def scoresForFold(cvFold, binSizeGrid, probs, estimator, LSF_type, Y, X):\n",
    "   \n",
    "    indicesTrain = cvFold[0]\n",
    "    indicesTest = cvFold[1]\n",
    "    \n",
    "    YTrainFold = Y[indicesTrain]\n",
    "    XTrainFold = X[indicesTrain]\n",
    "    \n",
    "    YTestFold = Y[indicesTest]\n",
    "    XTestFold = X[indicesTest]\n",
    "    \n",
    "    estimator.fit(X = XTrainFold, y = YTrainFold)\n",
    "    \n",
    "    #---\n",
    "       \n",
    "    SAA_fold = SAA()\n",
    "    SAA_fold.fit(Y = YTrainFold)\n",
    "    \n",
    "    # By setting 'X = None', the SAA results are only computed for a single observation (they are independent of X anyway).\n",
    "    # In order to receive the final dataframe of SAA results, we simply duplicate this single row as many times as needed.\n",
    "    quantilesDictSAAOneOb = SAA_fold.predict(X = None, probs = probs, outputAsDf = False)\n",
    "    quantilesDictSAA = {prob: np.repeat(quantile, len(XTestFold)) for prob, quantile in quantilesDictSAAOneOb.items()}\n",
    "    \n",
    "    #---\n",
    "                                                   \n",
    "    coefPresPerBinSize = list()\n",
    "    \n",
    "    binSizeGrid = [binSize for binSize in binSizeGrid if binSize <= len(YTrainFold)]\n",
    "    \n",
    "    for binSize in iter(binSizeGrid):\n",
    "        \n",
    "        if LSF_type == 'LSF':\n",
    "            estimatorLSF = LevelSetForecaster(estimator = estimator,\n",
    "                                              binSize = binSize)\n",
    "        else:\n",
    "            estimatorLSF = LevelSetForecaster_kNN(estimator = estimator,\n",
    "                                                  binSize = binSize)\n",
    "        \n",
    "        estimatorLSF.fit(X = XTrainFold,\n",
    "                         Y = YTrainFold)\n",
    "        \n",
    "        quantilesDict = estimatorLSF.predict(X = XTestFold,\n",
    "                                             probs = probs,\n",
    "                                             outputAsDf = False)\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        # coeffPres = Coefficient of Prescriptiveness\n",
    "        \n",
    "        coefPresDict = {prob: [] for prob in probs}\n",
    "        \n",
    "        for prob in probs:            \n",
    "            coefPres = getCoefPres(decisions = quantilesDict[prob], \n",
    "                                   decisionsSAA = quantilesDictSAA[prob], \n",
    "                                   YTest = YTestFold, \n",
    "                                   prob = prob)\n",
    "            \n",
    "            coefPresDict[prob].append(coefPres)\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    coefPresDf = pd.DataFrame(coefPresDict, index = binSizeGrid)\n",
    "    \n",
    "    return coefPresDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5121f5c4-fab2-4788-8691-ffbef17d703f",
   "metadata": {},
   "source": [
    "### Coefficient of Prescriptiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a49f19-5f88-4600-bb1d-ff237b7daf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def getCoefPres(decisions, decisionsSAA, YTest, prob):\n",
    "\n",
    "    # Newsvendor Costs of our model\n",
    "    cost = np.array([prob * (YTest[i] - decisions[i]) if YTest[i] > decisions[i] \n",
    "                     else (1 - prob) * (decisions[i] - YTest[i]) \n",
    "                     for i in range(len(YTest))]).sum()\n",
    "    \n",
    "    # Newsvendor Costs of SAA\n",
    "    costSAA = np.array([prob * (YTest[i] - decisionsSAA[i]) if YTest[i] > decisionsSAA[i] \n",
    "                        else (1 - prob) * (decisionsSAA[i] - YTest[i]) \n",
    "                        for i in range(len(YTest))]).sum()\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    # We have to capture the special case of costSAA == 0, because then we can't compute the \n",
    "    # Coefficient of Prescriptiveness using the actual definition.\n",
    "    if costSAA > 0:\n",
    "        coefPres = 1 - cost / costSAA\n",
    "    else:\n",
    "        if cost == 0:\n",
    "            coefPres = 1\n",
    "        else:\n",
    "            coefPres = 0\n",
    "    \n",
    "    return coefPres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e79762a-1427-49d7-b8b2-42ecde48e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87eb7761-038b-41ba-89d0-5562212bb0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(LevelSetForecaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4c8b381-4f39-4787-9be4-0ecceac1cc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetForecaster.py#L244){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetForecaster_kNN.getWeightsData\n",
       "\n",
       ">      LevelSetForecaster_kNN.getWeightsData (X:numpy.ndarray, outputType:Union[\n",
       ">                                             ForwardRef('all'),ForwardRef('only\n",
       ">                                             PositiveWeights'),ForwardRef('summ\n",
       ">                                             arized'),ForwardRef('cumulativeDis\n",
       ">                                             tribution'),ForwardRef('cumulative\n",
       ">                                             DistributionSummarized')]='onlyPos\n",
       ">                                             itiveWeights', scalingList:Union[l\n",
       ">                                             ist,numpy.ndarray,NoneType]=None)\n",
       "\n",
       "Compute weights of feature array X\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | np.ndarray |  | Feature matrix for whose rows conditional density estimates are computed. |\n",
       "| outputType | 'all' \\| 'onlyPositiveWeights' \\| 'summarized' \\| 'cumulativeDistribution' \\| 'cumulativeDistributionSummarized' | onlyPositiveWeights | specifies structure of output. |\n",
       "| scalingList | list \\| np.ndarray \\| None | None | List or array with same size as self.Y containing floats being multiplied with self.Y. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetForecaster.py#L244){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetForecaster_kNN.getWeightsData\n",
       "\n",
       ">      LevelSetForecaster_kNN.getWeightsData (X:numpy.ndarray, outputType:Union[\n",
       ">                                             ForwardRef('all'),ForwardRef('only\n",
       ">                                             PositiveWeights'),ForwardRef('summ\n",
       ">                                             arized'),ForwardRef('cumulativeDis\n",
       ">                                             tribution'),ForwardRef('cumulative\n",
       ">                                             DistributionSummarized')]='onlyPos\n",
       ">                                             itiveWeights', scalingList:Union[l\n",
       ">                                             ist,numpy.ndarray,NoneType]=None)\n",
       "\n",
       "Compute weights of feature array X\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | np.ndarray |  | Feature matrix for whose rows conditional density estimates are computed. |\n",
       "| outputType | 'all' \\| 'onlyPositiveWeights' \\| 'summarized' \\| 'cumulativeDistribution' \\| 'cumulativeDistributionSummarized' | onlyPositiveWeights | specifies structure of output. |\n",
       "| scalingList | list \\| np.ndarray \\| None | None | List or array with same size as self.Y containing floats being multiplied with self.Y. |"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show_doc(LevelSetForecaster_kNN.getWeightsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fdebe72-8686-4b73-ae59-b9cbf6014c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(binSizeCV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HC-Scheduling",
   "language": "python",
   "name": "hc-scheduling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
