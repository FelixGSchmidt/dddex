{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Class\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp baseClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "# from nbdev.qmd import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from fastcore.docments import *\n",
    "from fastcore.test import *\n",
    "from fastcore.utils import *\n",
    "from fastcore.script import *\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from numpy.random import uniform\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights-Based Predictor - Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BaseWeightsBasedEstimator(BaseEstimator):\n",
    "    \"\"\" \n",
    "    Base class that implements the 'prediction'-method for approaches based \n",
    "    on a reweighting of the empirical distribution. This class is not supposed\n",
    "    to be used directly.\n",
    "    \"\"\"\n",
    "    \n",
    "    def getWeights(self, \n",
    "                   X: np.ndarray, # Feature matrix for which conditional density estimates are computed.\n",
    "                   # Specifies structure of the returned density estimates. One of: \n",
    "                   # 'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized'\n",
    "                   outputType: str='onlyPositiveWeights', \n",
    "                   # Optional. List with length X.shape[0]. Values are multiplied to the estimated \n",
    "                   # density of each sample for scaling purposes.\n",
    "                   scalingList: list=None,\n",
    "                   ) -> list: # List whose elements are the conditional density estimates for the samples specified by `X`.\n",
    "        \"\"\"\n",
    "        Computes estimated conditional density for each sample specified by `X`. The concrete structure of each element \n",
    "        of the returned list depends on the specified value of `outputType`:\n",
    "        \n",
    "        - **all**: An array with the same length as the number of training samples. Each entry represents the probability \n",
    "          of each training sample.\n",
    "        - **onlyPositiveWeights**: A tuple. The first element of the tuple represents the probabilities and the second \n",
    "          one the indices of the corresponding training sample. Only probalities greater than zero are returned. \n",
    "          Note: This is the most memory and computationally efficient output type.\n",
    "        - **summarized**: A tuple. The first element of the tuple represents the probabilities and the second one the \n",
    "          corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
    "        - **cumDistribution**: A tuple. The first element of the tuple represents the probabilities and the second \n",
    "          one the corresponding value of `yTrain`.\n",
    "        - **cumDistributionSummarized**: A tuple. The first element of the tuple represents the probabilities and \n",
    "          the second one the corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    def predict(self : BaseWeightsBasedEstimator, \n",
    "                X: np.ndarray, # Feature matrix for which conditional quantiles are computed.\n",
    "                probs: list, # Probabilities for which quantiles are computed.\n",
    "                outputAsDf: bool=True, # Determines output. Either a dataframe with probs as columns or a dict with probs as keys.\n",
    "                # Optional. List with length X.shape[0]. Values are multiplied to the predictions\n",
    "                # of each sample to rescale values.\n",
    "                scalingList: list=None, \n",
    "                ): \n",
    "        \"\"\" Predict p-quantiles based on a reweighting of the empirical distribution function.\"\"\"\n",
    "        \n",
    "        # Checks\n",
    "        if isinstance(probs, int) or isinstance(probs, float):\n",
    "            if probs >= 0 and probs <= 1:\n",
    "                probs = [probs]\n",
    "            else:\n",
    "                raise ValueError(\"The values specified via 'probs' must lie between 0 and 1!\")           \n",
    "                 \n",
    "        if any([prob > 1 or prob < 0 for prob in probs]):\n",
    "            raise ValueError(\"The values specified via 'probs' must lie between 0 and 1!\")\n",
    "        \n",
    "        #---\n",
    "                             \n",
    "        distributionDataList = self.getWeights(X = X,\n",
    "                                               outputType = 'cumulativeDistribution',\n",
    "                                               scalingList = scalingList)\n",
    "\n",
    "        quantilesDict = {prob: [] for prob in probs}\n",
    "\n",
    "        for probsDistributionFunction, yDistributionFunction in distributionDataList:\n",
    "\n",
    "            for prob in probs:\n",
    "                \n",
    "                # A tolerance term of 10^-8 is substracted from prob to account for rounding errors due to numerical precision. \n",
    "                quantileIndex = np.where(probsDistributionFunction >= prob - 10**-8)[0][0]\n",
    "                    \n",
    "                quantile = yDistributionFunction[quantileIndex]\n",
    "                quantilesDict[prob].append(quantile)\n",
    "\n",
    "        quantilesDf = pd.DataFrame(quantilesDict)\n",
    "\n",
    "        # Just done to make the dictionary contain arrays rather than lists of the quantiles.\n",
    "        quantilesDict = {prob: np.array(quantiles) for prob, quantiles in quantilesDict.items()}\n",
    "\n",
    "        #---\n",
    "\n",
    "        if outputAsDf:\n",
    "            return quantilesDf\n",
    "\n",
    "        else:\n",
    "            return quantilesDict\n",
    "        \n",
    "    #---    \n",
    "    \n",
    "    def sampleScenarios(self,\n",
    "                        X: np.ndarray, # Feature matrix for which samples are computed.\n",
    "                        n: int,\n",
    "                        # Optional. List with length X.shape[0]. Values are multiplied to the estimated \n",
    "                        # density of each sample for scaling purposes.\n",
    "                        scalingList: list=None,\n",
    "                        ) -> np.ndarray: # array-like of shape (n_samples_in, n_scenarios)\n",
    "        \n",
    "        distributionData = self.getWeights(X = X,\n",
    "                                           outputType = 'cumulativeDistribution',\n",
    "                                           scalingList = scalingList)\n",
    "        \n",
    "        sampleList = list()\n",
    "        for probs, values in distributionData:\n",
    "            randomProbs = uniform(size = n)\n",
    "            randomProbs = randomProbs.reshape(n, 1)\n",
    "            sample = values[np.argmax(probs >= randomProbs, axis = 1)]\n",
    "\n",
    "            sampleList.append(sample)\n",
    "        \n",
    "        sampleMatrix = np.concatenate([sampleList], axis = 0)\n",
    "        \n",
    "        return sampleMatrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(BaseWeightsBasedEstimator.getWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(BaseWeightsBasedEstimator.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights-Based Predictor - Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BaseWeightsBasedEstimator_multivariate(BaseEstimator):\n",
    "    \"\"\" \n",
    "    Base class that implements the 'prediction'-method for approaches based \n",
    "    on a reweighting of the empirical distribution. This class is not supposed\n",
    "    to be used directly.\n",
    "    \"\"\"\n",
    "    \n",
    "    def getWeights(self, \n",
    "                   X: np.ndarray, # Feature matrix for which conditional density estimates are computed.\n",
    "                   # Specifies structure of the returned density estimates. One of: \n",
    "                   # 'all', 'onlyPositiveWeights', 'summarized'\n",
    "                   outputType: str='onlyPositiveWeights', \n",
    "                   # Optional. List with length X.shape[0]. Values are multiplied to the estimated \n",
    "                   # density of each sample for scaling purposes.\n",
    "                   scalingList: list=None,\n",
    "                   ) -> list: # List whose elements are the conditional density estimates for the samples specified by `X`.\n",
    "        \"\"\"\n",
    "        Computes estimated conditional density for each sample specified by `X`. The concrete structure of each element \n",
    "        of the returned list depends on the specified value of `outputType`:\n",
    "        \n",
    "        - **all**: An array with the same length as the number of training samples. Each entry represents the probability \n",
    "          of each training sample.\n",
    "        - **onlyPositiveWeights**: A tuple. The first element of the tuple represents the probabilities and the second \n",
    "          one the indices of the corresponding training sample. Only probalities greater than zero are returned. \n",
    "          Note: This is the most memory and computationally efficient output type.\n",
    "        - **summarized**: A tuple. The first element of the tuple represents the probabilities and the second one the \n",
    "          corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
    "        \"\"\"\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HC-Scheduling",
   "language": "python",
   "name": "hc-scheduling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
