{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Class\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp basePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "# from nbdev.qmd import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from fastcore.docments import *\n",
    "from fastcore.test import *\n",
    "from fastcore.utils import *\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Class - Weights-Based Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BasePredictor(ABC):\n",
    "    \"\"\" \n",
    "    Base class that implements the 'prediction'-method for approaches based \n",
    "    on a reweighting of the empirical distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        \"\"\"Define weights-based predictor\"\"\"\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit weights-based predictor on training samples\"\"\"\n",
    "        \n",
    "    def getWeights(self, X):\n",
    "        \"\"\"Compute weights for every sample specified by feature matrix 'X'\"\"\"\n",
    "\n",
    "    # def predictQuantiles(self: BasePredictor, \n",
    "    #                      X: np.ndarray, # Feature matrix of samples for which conditional quantiles are computed.\n",
    "    #                      probs: list | np.ndarray = [0.1, 0.5, 0.9], # Probabilities for which the estimated conditional p-quantiles are computed.\n",
    "    #                      outputAsDf: bool = False, # Output is either a dataframe with 'probs' as cols or a dict with 'probs' as keys.\n",
    "    #                      scalingList: list | np.ndarray | None = None, # List or array with same size as self.Y containing floats being multiplied with self.Y.\n",
    "    #                      ):\n",
    "    \n",
    "    def predictQ(self, \n",
    "                 X,\n",
    "                 probs = [0.1, 0.5, 0.9], \n",
    "                 outputAsDf = False, \n",
    "                 scalingList = None, \n",
    "                 ):\n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "\n",
    "        distributionDataList = self.getWeights(X = X,\n",
    "                                               outputType = 'cumulativeDistribution',\n",
    "                                               scalingList = scalingList)\n",
    "\n",
    "        quantilesDict = {prob: [] for prob in probs}\n",
    "\n",
    "        for probsDistributionFunction, yDistributionFunction in distributionDataList:\n",
    "\n",
    "            for prob in probs:\n",
    "                quantileIndex = np.where(probsDistributionFunction >= prob)[0][0]\n",
    "                quantile = yDistributionFunction[quantileIndex]\n",
    "                quantilesDict[prob].append(quantile)\n",
    "\n",
    "        quantilesDf = pd.DataFrame(quantilesDict)\n",
    "\n",
    "        # Just done to make the dictionary contain arrays rather than lists of the quantiles.\n",
    "        quantilesDict = {prob: np.array(quantiles) for prob, quantiles in quantilesDict.items()}\n",
    "\n",
    "        #---\n",
    "\n",
    "        if outputAsDf:\n",
    "            return quantilesDf\n",
    "\n",
    "        else:\n",
    "            return quantilesDict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/basePredictor.py#L18){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BasePredictor\n",
       "\n",
       ">      BasePredictor ()\n",
       "\n",
       "Base class that implements the 'prediction'-method for approaches based \n",
       "on a reweighting of the empirical distribution."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/basePredictor.py#L18){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BasePredictor\n",
       "\n",
       ">      BasePredictor ()\n",
       "\n",
       "Base class that implements the 'prediction'-method for approaches based \n",
       "on a reweighting of the empirical distribution."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BasePredictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### BasePredictor.predictQ\n",
       "\n",
       ">      BasePredictor.predictQ (X, probs=[0.1, 0.5, 0.9], outputAsDf=False,\n",
       ">                              scalingList=None)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### BasePredictor.predictQ\n",
       "\n",
       ">      BasePredictor.predictQ (X, probs=[0.1, 0.5, 0.9], outputAsDf=False,\n",
       ">                              scalingList=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BasePredictor.predictQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restructure Weights Data List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def restructureWeightsDataList(weightsDataList, outputType = 'onlyPositiveWeights', y= None, scalingList = None, equalWeights = False):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if outputType == 'all':\n",
    "        \n",
    "        weightsDataListAll = list()\n",
    "        \n",
    "        for weights, indicesPosWeight in weightsDataList:\n",
    "            weightsAll = np.zeros(len(y))\n",
    "            weightsAll[indicesPosWeight] = weights\n",
    "            weightsDataListAll.append(weightsAll)\n",
    "        \n",
    "        return weightsDataListAll\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    elif outputType == 'onlyPositiveWeights':\n",
    "        \n",
    "        return weightsDataList\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    elif outputType == 'summarized':\n",
    "        \n",
    "        weightsDataListSummarized = list()\n",
    "\n",
    "        for i in range(len(weightsDataList)):\n",
    "            weightsPos, yWeightPos = weightsDataList[i][0], y[weightsDataList[i][1]]\n",
    "            \n",
    "            weightsSummarized, yUnique = summarizeWeightsData(weightsPos = weightsPos, \n",
    "                                                              yWeightPos = yWeightPos,\n",
    "                                                              equalWeights = equalWeights)\n",
    "            \n",
    "            if not scalingList is None:\n",
    "                yUnique = yUnique * scalingList[i]\n",
    "                \n",
    "            weightsDataListSummarized.append((weightsSummarized, yUnique))\n",
    "            \n",
    "        return weightsDataListSummarized\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    elif outputType == 'cumulativeDistribution':\n",
    "        \n",
    "        distributionDataList = list()\n",
    "        \n",
    "        for i in range(len(weightsDataList)):\n",
    "            weightsPos, yWeightPos = weightsDataList[i][0], y[weightsDataList[i][1]]\n",
    "            \n",
    "            indicesSort = np.argsort(yWeightPos)\n",
    "            \n",
    "            weightsPosSorted = weightsPos[indicesSort]\n",
    "            yWeightPosSorted = yWeightPos[indicesSort]\n",
    "            \n",
    "            cumulativeProbs = np.cumsum(weightsPosSorted)\n",
    "            \n",
    "            if not scalingList is None:\n",
    "                yWeightPosSorted = yWeightPosSorted * scalingList[i]\n",
    "                \n",
    "            distributionDataList.append((cumulativeProbs, yWeightPosSorted))\n",
    "            \n",
    "        return distributionDataList\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    elif outputType == 'cumulativeDistributionSummarized':\n",
    "        \n",
    "        distributionDataList = list()\n",
    "        \n",
    "        for i in range(len(weightsDataList)):\n",
    "            weightsPos, yWeightPos = weightsDataList[i][0], y[weightsDataList[i][1]]\n",
    "            \n",
    "            weightsSummarizedSorted, yPosWeightUniqueSorted = summarizeWeightsData(weightsPos = weightsPos, \n",
    "                                                                                   yWeightPos = yWeightPos,\n",
    "                                                                                   equalWeights = equalWeights)\n",
    "            \n",
    "            cumulativeProbs = np.cumsum(weightsSummarizedSorted)\n",
    "            \n",
    "            if not scalingList is None:\n",
    "                yPosWeightUniqueSorted = yPosWeightUniqueSorted * scalingList[i]\n",
    "                \n",
    "            distributionDataList.append((cumulativeProbs, yPosWeightUniqueSorted))\n",
    "            \n",
    "        return distributionDataList\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize Weights Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def summarizeWeightsData(weightsPos, yWeightPos, equalWeights = False):\n",
    "    \n",
    "    if equalWeights:\n",
    "        counterDict = Counter(yWeightPos)\n",
    "        yUniqueSorted = np.sort(list(counterDict.keys()))\n",
    "\n",
    "        weightsSummarizedSorted = np.array([counterDict[value] / len(yWeightPos) for value in yUniqueSorted])\n",
    "    \n",
    "    else:\n",
    "        duplicationDict = defaultdict(list)\n",
    "\n",
    "        for i, item in enumerate(yWeightPos):\n",
    "            duplicationDict[item].append(i)\n",
    "\n",
    "        #---\n",
    "\n",
    "        weightsSummarized = list()\n",
    "        yUnique = list()\n",
    "\n",
    "        for value, indices in duplicationDict.items():        \n",
    "\n",
    "            weightsSummarized.append(weightsPos[indices].sum())\n",
    "            yUnique.append(value)\n",
    "\n",
    "        weightsSummarized, yUnique = np.array(weightsSummarized), np.array(yUnique)\n",
    "\n",
    "        #---\n",
    "\n",
    "        indicesSort = np.argsort(yUnique)\n",
    "        weightsSummarizedSorted, yUniqueSorted = weightsSummarized[indicesSort], yUnique[indicesSort]\n",
    "    \n",
    "    return weightsSummarizedSorted, yUniqueSorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HC-Scheduling",
   "language": "python",
   "name": "hc-scheduling"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
