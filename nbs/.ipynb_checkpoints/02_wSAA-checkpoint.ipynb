{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a9df2e7-fdc8-44e7-b16c-d8b15ed01db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfbaad6-3667-46e6-b25e-efa0822452ae",
   "metadata": {},
   "source": [
    "# wSAA\n",
    "\n",
    "> Module description for wSAA classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c687b2c-941e-4e2a-9855-aa227ccb8490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp wSAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a1faac0-5c0d-4c70-80e9-7d959811b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "# from nbdev.qmd import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451e786a-e401-43d8-91e9-97c175eba23a",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b86f92e6-67ad-492b-9779-7b9acfc3d3df",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BasePredictor' from 'dddex.basePredictor' (/home/kagu/dddex/dddex/basePredictor.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdddex\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasePredictor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BasePredictor, restructureWeightsDataList\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'BasePredictor' from 'dddex.basePredictor' (/home/kagu/dddex/dddex/basePredictor.py)"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from fastcore.docments import *\n",
    "from fastcore.test import *\n",
    "from fastcore.utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from dddex.basePredictor import BasePredictor, restructureWeightsDataList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a331bd1d-ceaa-4b36-a42e-aaa2e4062c22",
   "metadata": {},
   "source": [
    "## wSAA - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b775c4-ca57-4539-a0b8-e282bdf963cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "\n",
    "class RandomForestWSAA(RandomForestRegressor, BasePredictor):\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        super(RandomForestRegressor, self).fit(X = X, y = y)\n",
    "        \n",
    "        self.y = y\n",
    "        self.leafIndicesTrain = self.apply(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db18d0f-bdb7-4f08-a8cf-ac07a49e7d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(RandomForestWSAA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a240e3b-5acc-4f82-8f4d-29391f5692b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(RandomForestWSAA.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4915159d-b5ac-414f-9bd4-202c0e2da08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "@patch\n",
    "def getWeightsData(self: RandomForestWSAA, \n",
    "                   X: np.ndarray, # Feature matrix of samples for which conditional density estimates are computed.\n",
    "                   outputType: 'all' | # Specifies structure of output.\n",
    "                               'onlyPositiveWeights' | \n",
    "                               'summarized' | \n",
    "                               'cumulativeDistribution' | \n",
    "                               'cumulativeDistributionSummarized' = 'onlyPositiveWeights', \n",
    "                   scalingList: list | np.ndarray | None = None, # List or array with same size as self.y containing floats being multiplied with self.y.\n",
    "                   ):\n",
    "\n",
    "    leafIndicesDf = self.apply(X)\n",
    "\n",
    "    weightsDataList = list()\n",
    "\n",
    "    for leafIndices in leafIndicesDf:\n",
    "        leafComparisonMatrix = (self.leafIndicesTrain == leafIndices) * 1\n",
    "        nObsInSameLeaf = np.sum(leafComparisonMatrix, axis = 0)\n",
    "\n",
    "        # It can happen that RF decides that the best strategy is to fit no tree at\n",
    "        # all and simply average all results (happens when min_child_sample is too high, for example).\n",
    "        # In this case 'leafComparisonMatrix' mustn't be averaged because there has been only a single tree.\n",
    "        if len(leafComparisonMatrix.shape) == 1:\n",
    "            weights = leafComparisonMatrix / nObsInSameLeaf\n",
    "        else:\n",
    "            weights = np.mean(leafComparisonMatrix / nObsInSameLeaf, axis = 1)\n",
    "\n",
    "        weightsPosIndex = np.where(weights > 0)[0]\n",
    "\n",
    "        weightsDataList.append((weights[weightsPosIndex], weightsPosIndex))\n",
    "\n",
    "    #---\n",
    "\n",
    "    weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "                                                 outputType = outputType, \n",
    "                                                 y = self.y, \n",
    "                                                 scalingList = scalingList,\n",
    "                                                 equalWeights = False)\n",
    "\n",
    "    return weightsDataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ebe067-f51e-4038-ae00-06bafa7ca014",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(RandomForestWSAA.getWeightsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f259e0-c201-4074-85a8-468d3f3c3a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "\n",
    "# @patch\n",
    "# def predict(self: RandomForestWSAA, \n",
    "#             X: np.ndarray, # Feature matrix of samples for which an estimation of conditional quantiles is computed.\n",
    "#             probs: list | np.ndarray = [0.1, 0.5, 0.9], # Probabilities for which the estimated conditional p-quantiles are computed.\n",
    "#             outputAsDf: bool = False, # Output is either a dataframe with 'probs' as cols or a dict with 'probs' as keys.\n",
    "#             scalingList: list | np.ndarray | None = None, # List or array with same size as self.y containing floats being multiplied with self.y.\n",
    "#             ):\n",
    "\n",
    "#     quantileRes = super(BaseWeightsBasedPredictor, self).predict(X = X,\n",
    "#                                                                  probs = probs,\n",
    "#                                                                  outputAsDf = outputAsDf,\n",
    "#                                                                  scalingList = scalingList)\n",
    "\n",
    "#     return quantileRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c673580e-9772-44db-ab59-1f81ace73467",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(RandomForestWSAA.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f471bba6-50ec-49a9-980d-1c10f4361938",
   "metadata": {},
   "source": [
    "## SAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b21e7-4c15-4c6d-8ebd-236740ec71e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SAA(BasePredictor):\n",
    "    \"\"\"SAA is a featureless approach that assumes the density of the target variable is given\n",
    "    by assigning equal probability to each historical observation of said target variable.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.y = None\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"SAA()\"\n",
    "    __repr__ = __str__     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc67de5-0fcb-47b3-82dd-908cbedaae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SAA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afd98f3-44c9-44f6-af9c-6430afa6fca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def fit(self: SAA, \n",
    "        y: np.ndarray, # Target values which form the estimated density function based on the SAA algorithm.\n",
    "        ):\n",
    "    self.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9520933-6480-4e96-bace-8b9f164cd922",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SAA.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db11f98-11b2-420f-9420-0bcbd3ebf7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def getWeightsData(self: SAA, \n",
    "                   X: np.ndarray, # Feature matrix for whose rows conditional density estimates are computed.\n",
    "                   outputType: 'all' | # Specifies structure of output.\n",
    "                               'onlyPositiveWeights' | \n",
    "                               'summarized' | \n",
    "                               'cumulativeDistribution' | \n",
    "                               'cumulativeDistributionSummarized' = 'onlyPositiveWeights', \n",
    "                   scalingList: list | np.ndarray | None = None, # List or array with same size as self.y containing floats being multiplied with self.y.\n",
    "                   ):\n",
    "\n",
    "    if X is None:\n",
    "        neighborsList = [np.arange(len(self.y))]\n",
    "    else:\n",
    "        neighborsList = [np.arange(len(self.y)) for i in range(X.shape[0])]\n",
    "\n",
    "    # weightsDataList is a list whose elements correspond to one test prediction each. \n",
    "    weightsDataList = [(np.repeat(1 / len(neighbors), len(neighbors)), np.array(neighbors)) for neighbors in neighborsList]\n",
    "\n",
    "    weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "                                                 outputType = outputType, \n",
    "                                                 y = self.y,\n",
    "                                                 scalingList = scalingList,\n",
    "                                                 equalWeights = True)\n",
    "\n",
    "    return weightsDataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e77e0d-5cb8-4c29-b356-0f0e61bccde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SAA.getWeightsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79762a-1427-49d7-b8b2-42ecde48e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HC-Scheduling",
   "language": "python",
   "name": "hc-scheduling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
