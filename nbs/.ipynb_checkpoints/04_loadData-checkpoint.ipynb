{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6febe163-9721-4b15-8266-2a27e361d37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb72158-9c27-4551-b03d-7d621714b399",
   "metadata": {},
   "source": [
    "# Load Datasets\n",
    "\n",
    "> The functions in this notebook load datasets that can be used to test the presented procedures of this package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9288a302-2d75-4fc4-b221-705f86345a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp loadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf1e3ed-8793-4e8d-bead-c0a21bb3e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from fastcore.docments import *\n",
    "from fastcore.test import *\n",
    "from fastcore.utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os.path import join\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series\n",
    "from tsfresh import extract_features\n",
    "import pathlib\n",
    "\n",
    "import pkg_resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f4ac80-295e-4787-b587-68517b1be286",
   "metadata": {},
   "source": [
    "## Yaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7666477b-b4a2-4ab5-957a-f8531cddb8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def loadDataYaz(testDays = 28, returnXY = True, daysToCut = 0):\n",
    "    \n",
    "#     currentFile = __file__\n",
    "#     scriptPath = os.path.realpath(currentFile)  # /home/user/test/my_script.py\n",
    "#     dirPath = os.path.dirname(scriptPath)  # /home/user/test\n",
    "    \n",
    "#     dataDirPath = join(dirPath, 'datasets')\n",
    "#     dataPath = join(dataDirPath, 'dataYaz.csv')\n",
    "    \n",
    "    dataPath = pkg_resources.resource_stream(__name__, 'datasets/dataYaz.csv')\n",
    "    data = pd.read_csv(dataPath)\n",
    "    \n",
    "    # Cutting away daysToCut-many at end of data: Useful for evaluating\n",
    "    # evaluation on data in a rolled manner\n",
    "    cutOffDate = data.dayIndex.max() - daysToCut\n",
    "    data = data[data['dayIndex'] <= cutOffDate].reset_index(drop = True)\n",
    "    \n",
    "    # Label\n",
    "    if isinstance(testDays, int):\n",
    "        nDaysTest = testDays\n",
    "    else:\n",
    "        tsSizes = data.groupby(['id']).size()\n",
    "        nDaysTest = int(tsSizes.iloc[0] * testDays)\n",
    "        \n",
    "    cutoffDateTest = data.dayIndex.max() - nDaysTest\n",
    "    data['label'] = ['train' if data.dayIndex.iloc[i] <= cutoffDateTest else 'test' for i in range(data.shape[0])]    \n",
    "\n",
    "    # Normalize Demand\n",
    "    scalingData = data[data.label == 'train'].groupby('id')['demand'].agg('max').reset_index()\n",
    "    scalingData.rename(columns = {'demand': 'scalingValue'}, inplace = True)\n",
    "    data = pd.merge(data, scalingData, on = 'id')\n",
    "\n",
    "    data['demand'] = data.demand / data.scalingValue\n",
    "\n",
    "    #---\n",
    "\n",
    "    # Add lag features\n",
    "    y = pd.DataFrame(data['demand'])\n",
    "    X = data.drop(columns = ['demand'])\n",
    "\n",
    "    # set lag features\n",
    "    fc_parameters = MinimalFCParameters()\n",
    "\n",
    "    # delete length features\n",
    "    del fc_parameters['length']\n",
    "\n",
    "    # create lag features\n",
    "    X, y = add_lag_features(X = X, \n",
    "                            y = y, \n",
    "                            column_id = ['id'], \n",
    "                            column_sort = 'dayIndex', \n",
    "                            feature_dict = fc_parameters, \n",
    "                            time_windows = [(7, 7), (14, 14), (28, 28)])\n",
    "    \n",
    "    data = pd.concat([y, X], axis = 1)\n",
    "                      \n",
    "    # Turn y from Series or dataframe to flatted array\n",
    "    y = np.ravel(y)\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    X = np.array(data.drop(['demand', 'label', 'id'], axis = 1))\n",
    "    \n",
    "    XTrain = X[data['label'] == 'train']\n",
    "    yTrain = y[data['label'] == 'train']\n",
    "    \n",
    "    XTest = X[data['label'] == 'test']\n",
    "    yTest = y[data['label'] == 'test']\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    if returnXY:\n",
    "        return data, XTrain, yTrain, XTest, yTest\n",
    "    else:\n",
    "        return data    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4a9c2c-9dba-47f6-9da1-5bdc78fe505c",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bf68ed-a09f-4d7a-8e01-3bc0a5b24bb6",
   "metadata": {},
   "source": [
    "### Add lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c543ff14-fa9f-4c32-887c-87a820357428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def add_lag_features(X, y, column_id, column_sort, feature_dict, time_windows):\n",
    "    \"\"\"\n",
    "    Create lag features for y and add them to X\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X: pandas.DataFrame \n",
    "    feature matrix to which TS features are added.\n",
    "    y: pandas.DataFrame, \n",
    "    time series to compute the features for.\n",
    "    column_id: list, \n",
    "    list of column names to group by, e.g. [\"shop\",\"product\"]. If set to None, \n",
    "    either there should be nothing to groupby or each group should be \n",
    "    represented by a separate target column in y. \n",
    "    column_sort: str,\n",
    "    column name used to sort the DataFrame. If None, will be filled by an \n",
    "    increasing number, meaning that the order of the passed dataframes are used \n",
    "    as “time” for the time series.\n",
    "    feature_dict: dict,\n",
    "    dictionary containing feature calculator names with the corresponding \n",
    "    parameters\n",
    "    time_windows : list of tuples, \n",
    "    each tuple (min_timeshift, max_timeshift), represents the time shifts for \n",
    "    ech time windows to comupute e.g. [(7,7),(1,14)] for two time windos \n",
    "    a) time window with a fix size of 7 and b) time window that starts with size\n",
    "    1 and increases up to 14. Then shifts by 1 for each step. \n",
    "    \"\"\"\n",
    "\n",
    "    if column_id == None:\n",
    "        X['id'] = 1\n",
    "\n",
    "    else:\n",
    "        X['id'] = X[column_id].astype(str).agg('_'.join, axis = 1)\n",
    "\n",
    "    if column_sort == None:\n",
    "        X['time'] = range(X.shape[0])  \n",
    "\n",
    "    else:\n",
    "        X[\"time\"] = X[column_sort].copy()\n",
    "    \n",
    "    y = pd.concat([y, X[['id', 'time']]], axis = 1)\n",
    "    X = X.set_index(['id', 'time'])\n",
    "  \n",
    "    for window in time_windows:\n",
    "        \n",
    "        # create time series for given time window \n",
    "        df_rolled = roll_time_series(y, \n",
    "                                     column_id = \"id\", \n",
    "                                     column_sort = \"time\", \n",
    "                                     min_timeshift = window[0]-1, \n",
    "                                     max_timeshift = window[1]-1,\n",
    "                                     disable_progressbar = True)\n",
    "        \n",
    "        df_rolled['id'] = df_rolled['id'].apply(lambda x: (x[0], x[1] + 1))\n",
    "\n",
    "        # create lag features for given time window \n",
    "        df_features = extract_features(df_rolled, \n",
    "                                       column_id = \"id\", \n",
    "                                       column_sort = \"time\",\n",
    "                                       default_fc_parameters = feature_dict,\n",
    "                                       disable_progressbar = True)\n",
    "\n",
    "        # Add time window to feature name for clarification \n",
    "        feature_names = df_features.columns.to_list()\n",
    "        feature_names = [name + \"_\" + str(window[1]) for name in feature_names]\n",
    "        df_features.columns = feature_names\n",
    "        \n",
    "        # add features for given time window to feature matrix temp\n",
    "        X = pd.concat([X, df_features], axis = 1)\n",
    "    \n",
    "    y = y.set_index(['id', 'time'])\n",
    "    y_column_names = y.columns.to_list()\n",
    "\n",
    "    df = pd.concat([X, y],axis = 1)\n",
    "    df = df.dropna()\n",
    "    df.index.names = names = ['id', 'time']\n",
    "    df = df.reset_index(drop = False, inplace = False).drop(['time'], axis = 1, inplace = False)\n",
    "\n",
    "    y = df[y_column_names]\n",
    "    X = df.drop(y_column_names, axis = 1)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104fd2df-c40f-4103-8d0f-7c00753d7a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mroll_time_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdf_or_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolumn_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolumn_sort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolumn_kind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrolling_direction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_timeshift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_timeshift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshow_warnings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdisable_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdistributor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "This method creates sub windows of the time series. It rolls the (sorted) data frames for each kind and each id\n",
       "separately in the \"time\" domain (which is represented by the sort order of the sort column given by `column_sort`).\n",
       "\n",
       "For each rolling step, a new id is created by the scheme ({id}, {shift}), here id is the former id of\n",
       "the column and shift is the amount of \"time\" shifts.\n",
       "You can think of it as having a window of fixed length (the max_timeshift) moving one step at a time over\n",
       "your time series.\n",
       "Each cut-out seen by the window is a new time series with a new identifier.\n",
       "\n",
       "A few remarks:\n",
       "\n",
       " * This method will create new IDs!\n",
       " * The sign of rolling defines the direction of time rolling, a positive value means we are shifting\n",
       "   the cut-out window foreward in time. The name of each new sub time series is given by the last time point.\n",
       "   This means, the time series named `([id=]4,[timeshift=]5)` with a `max_timeshift` of 3 includes the data\n",
       "   of the times 3, 4 and 5.\n",
       "   A negative rolling direction means, you go in negative time direction over your data.\n",
       "   The time series named `([id=]4,[timeshift=]5)` with `max_timeshift` of 3 would then include the data\n",
       "   of the times 5, 6 and 7.\n",
       "   The absolute value defines how much time to shift at each step.\n",
       " * It is possible to shift time series of different lengths, but:\n",
       " * We assume that the time series are uniformly sampled\n",
       " * For more information, please see :ref:`forecasting-label`.\n",
       "\n",
       ":param df_or_dict: a pandas DataFrame or a dictionary. The required shape/form of the object depends on the rest of\n",
       "    the passed arguments.\n",
       ":type df_or_dict: pandas.DataFrame or dict\n",
       "\n",
       ":param column_id: it must be present in the pandas DataFrame or in all DataFrames in the dictionary.\n",
       "    It is not allowed to have NaN values in this column.\n",
       ":type column_id: basestring\n",
       "\n",
       ":param column_sort: if not None, sort the rows by this column. It is not allowed to\n",
       "    have NaN values in this column. If not given, will be filled by an increasing number,\n",
       "    meaning that the order of the passed dataframes are used as \"time\" for the time series.\n",
       ":type column_sort: basestring or None\n",
       "\n",
       ":param column_kind: It can only be used when passing a pandas DataFrame (the dictionary is already assumed to be\n",
       "    grouped by the kind). Is must be present in the DataFrame and no NaN values are allowed.\n",
       "    If the kind column is not passed, it is assumed that each column in the pandas DataFrame (except the id or\n",
       "    sort column) is a possible kind.\n",
       ":type column_kind: basestring or None\n",
       "\n",
       ":param rolling_direction: The sign decides, if to shift our cut-out window backwards or forwards in \"time\".\n",
       "    The absolute value decides, how much to shift at each step.\n",
       ":type rolling_direction: int\n",
       "\n",
       ":param max_timeshift: If not None, the cut-out window is at maximum `max_timeshift` large. If none, it grows\n",
       "     infinitely.\n",
       ":type max_timeshift: int\n",
       "\n",
       ":param min_timeshift: Throw away all extracted forecast windows smaller or equal than this. Must be larger\n",
       "     than or equal 0.\n",
       ":type min_timeshift: int\n",
       "\n",
       ":param n_jobs: The number of processes to use for parallelization. If zero, no parallelization is used.\n",
       ":type n_jobs: int\n",
       "\n",
       ":param chunksize: How many shifts per job should be calculated.\n",
       ":type chunksize: None or int\n",
       "\n",
       ":param show_warnings: Show warnings during the feature extraction (needed for debugging of calculators).\n",
       ":type show_warnings: bool\n",
       "\n",
       ":param disable_progressbar: Do not show a progressbar while doing the calculation.\n",
       ":type disable_progressbar: bool\n",
       "\n",
       ":param distributor: Advanced parameter: set this to a class name that you want to use as a\n",
       "         distributor. See the utilities/distribution.py for more information. Leave to None, if you want\n",
       "         TSFresh to choose the best distributor.\n",
       ":type distributor: class\n",
       "\n",
       ":return: The rolled data frame or dictionary of data frames\n",
       ":rtype: the one from df_or_dict\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.conda/envs/HC-Scheduling/lib/python3.8/site-packages/tsfresh/utilities/dataframe_functions.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roll_time_series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9301ffb7-77e3-4493-b3e3-874d54a397c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba747cf3-2c08-405b-8f1a-ab7595d5e933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cbd2dd-8961-4e45-b7d6-8542a8d25300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HC-Scheduling",
   "language": "python",
   "name": "hc-scheduling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
