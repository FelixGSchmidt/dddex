{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "451e786a-e401-43d8-91e9-97c175eba23a",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f92e6-67ad-492b-9779-7b9acfc3d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors \n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from joblib import Parallel, delayed, dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25091b83-e370-45ec-9a62-02d74eb36ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsf.core import BaseWeightsBasedPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8fed08-e349-44f9-9bda-52b6fe7df1dc",
   "metadata": {},
   "source": [
    "# LSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cebd8e-52d0-4a7f-af8f-75af78972824",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LevelSetForecaster(BaseWeightsBasedPredictor):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 estimator, \n",
    "                 binSize = None):\n",
    "        \n",
    "        if not (hasattr(estimator, 'predict') and callable(estimator.predict)):\n",
    "            raise ValueError(\"'estimator' has to have a 'predict'-method!\")\n",
    "        else:\n",
    "            self.estimator = estimator\n",
    "            \n",
    "        if not (isinstance(binSize, (int, np.integer)) or binSize is None):\n",
    "            raise ValueError(\"'binSize' has to be integer (or None if it is supposed to be tuned)!\")\n",
    "        else:\n",
    "            self.binSize = binSize\n",
    "        \n",
    "        self.estimator = estimator\n",
    "        self.binSize = binSize\n",
    "        \n",
    "        self.Y = None\n",
    "        self.YPred = None\n",
    "        self.binPerTrainPred = None\n",
    "        self.indicesPerBin = None\n",
    "        self.nearestNeighborsOnPreds = None\n",
    "        \n",
    "    #---        \n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        YPredTrain = self.estimator.predict(X)\n",
    "        \n",
    "        binPerTrainPred, indicesPerBin = generateBins(binSize = self.binSize,\n",
    "                                                      YPredTrain = YPredTrain)\n",
    "\n",
    "        #---\n",
    "        \n",
    "        nn = NearestNeighbors(algorithm = 'kd_tree')\n",
    "        YPredTrain_reshaped = np.reshape(YPredTrain, newshape = (len(YPredTrain), 1))\n",
    "\n",
    "        nn.fit(X = YPredTrain_reshaped)\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        self.Y = Y\n",
    "        self.YPredTrain = YPredTrain\n",
    "        self.binPerTrainPred = binPerTrainPred\n",
    "        self.indicesPerBin = indicesPerBin\n",
    "        self.nearestNeighborsOnPreds = nn\n",
    "        \n",
    "    #---\n",
    "        \n",
    "    def getWeightsData(self, X, outputType = 'onlyPositiveWeights', scalingList = None):\n",
    "        \n",
    "        binPerTrainPred = self.binPerTrainPred\n",
    "        indicesPerBin = self.indicesPerBin\n",
    "        nearestNeighborsOnPreds = self.nearestNeighborsOnPreds\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        YPred = self.estimator.predict(X)   \n",
    "        YPred_reshaped = np.reshape(YPred, newshape = (len(YPred), 1))\n",
    "        \n",
    "        nearestPredIndex = nearestNeighborsOnPreds.kneighbors(X = YPred_reshaped, \n",
    "                                                              n_neighbors = 1, \n",
    "                                                              return_distance = False).ravel()\n",
    "        \n",
    "        nearestPredNeighbor = self.YPredTrain[nearestPredIndex]\n",
    "\n",
    "        neighborsList = [indicesPerBin[binPerTrainPred[nearestPredNeighbor[i]]] for i in range(len(YPred))]\n",
    "\n",
    "        #---\n",
    "        \n",
    "        # Checks        \n",
    "        for i in range(len(neighborsList)):\n",
    "            if len(neighborsList[i]) < self.binSize:\n",
    "                ipdb.set_trace()\n",
    "\n",
    "        #---\n",
    "        \n",
    "        # weightsDataList is a list whose elements correspond to one test prediction each. \n",
    "        weightsDataList = [(np.repeat(1 / len(neighbors), len(neighbors)), np.array(neighbors)) for neighbors in neighborsList]\n",
    "\n",
    "        weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "                                                     outputType = outputType, \n",
    "                                                     Y = self.Y,\n",
    "                                                     scalingList = scalingList,\n",
    "                                                     equalWeights = True)\n",
    "\n",
    "        return weightsDataList\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80055a5c-dbfd-4817-8ecf-95acf0c04af2",
   "metadata": {},
   "source": [
    "## Generate Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff05d2-7747-437c-9fcc-ebeaec04b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBins(binSize, YPredTrain):\n",
    "    \n",
    "    \"\"\"\n",
    "    Used to generate the bin-structure induced by the Level-Set-Forecaster algorithm for\n",
    "    ``neighborStrategy == 'bins'``.\n",
    "    Bins are created by starting at the lowest value of YPredTrain and then succesively \n",
    "    adding the closest next prediction to the current bin until ``binSize``-many observations\n",
    "    have been allocated. Then the generation of a new bin is started in the same manner\n",
    "    until all values of YPredTrain have been assigned to exactly one bin.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    binSize : int\n",
    "        The size of each bin that is being created. Every bin is going to have this size\n",
    "        apart from the one containing the predictions with the highest values (see remarks)\n",
    "    YPredTrain : array\n",
    "        The predictions for the training observations.\n",
    "\n",
    "    Output\n",
    "    ----------\n",
    "    binPerPred : dict\n",
    "        A dictionary whose keys are given by all unique values of YPredTrain.\n",
    "        binPrePred[pred] returns the bin to which the current prediction 'pred'\n",
    "        belongs to.\n",
    "    indicesPerBin : dict\n",
    "        A dictionary whose keys are given by all bins (the keys begin at zero).\n",
    "        indicesPerBin[j] contains all indices of YPredTrain that belong to the same bin.\n",
    "\n",
    "    Notes\n",
    "    ----------\n",
    "    The binning strategy leads to the bin of the highest prediction values being smaller\n",
    "    than ``binSize``. As a convention, no bin is allowed to be smaller than ``binSize``.\n",
    "    For that reason, the bin of the highest value is joined with the next bin to it, \n",
    "    so the final bin containing the highest prediction values is the only bin to contain\n",
    "    more observations than ``binSize``.\n",
    "    \"\"\"\n",
    "    \n",
    "    YPredTrainUnique = pd.Series(YPredTrain).unique()\n",
    "    predIndicesSort = np.argsort(YPredTrainUnique)\n",
    "    \n",
    "    YPredTrainUniqueSorted = YPredTrainUnique[predIndicesSort]\n",
    "    indicesByPredTrain = [np.where(pred == YPredTrain)[0] for pred in YPredTrainUniqueSorted]\n",
    "    \n",
    "    currentBinSize = 0\n",
    "    binIndex = 0\n",
    "    binExisting = False\n",
    "    trainIndicesLeft = len(YPredTrain)\n",
    "    binPerPred = dict()\n",
    "    indicesPerBin = dict()\n",
    "\n",
    "    for i in range(len(indicesByPredTrain)):\n",
    "        currentBinSize += len(indicesByPredTrain[i])\n",
    "        binPerPred[YPredTrainUniqueSorted[i]] = binIndex\n",
    "        \n",
    "        if binExisting:\n",
    "            indicesPerBin[binIndex] = np.append(indicesPerBin[binIndex], indicesByPredTrain[i])\n",
    "        else:\n",
    "            indicesPerBin[binIndex] = indicesByPredTrain[i]\n",
    "            binExisting = True\n",
    "\n",
    "        trainIndicesLeft -= len(indicesByPredTrain[i])\n",
    "        if trainIndicesLeft < binSize:\n",
    "            for j in np.arange(i+1, len(indicesByPredTrain), 1):\n",
    "                binPerPred[YPredTrainUniqueSorted[j]] = binIndex\n",
    "                indicesPerBin[binIndex] = np.append(indicesPerBin[binIndex], indicesByPredTrain[j])\n",
    "            break\n",
    "\n",
    "        if currentBinSize >= binSize:\n",
    "            binIndex += 1\n",
    "            currentBinSize = 0\n",
    "            binExisting = False\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    # Checks\n",
    "    \n",
    "    indices = np.array([])\n",
    "    for k in range(len(indicesPerBin.keys())):\n",
    "        indices = np.append(indices, indicesPerBin[k])\n",
    " \n",
    "    if len(indices) != len(YPredTrain):\n",
    "        ipdb.set_trace()\n",
    "    \n",
    "    predCheck = np.array([pred in binPerPred.keys() for pred in YPredTrain])\n",
    "    keyCheck = np.array([key in YPredTrain for key in binPerPred.keys()])\n",
    "    \n",
    "    if (all(predCheck) & all(keyCheck)) is False:\n",
    "        ipdb.set_trace()\n",
    "    \n",
    "    return binPerPred, indicesPerBin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7b5f71-dda7-4f4e-b575-32f4f516f87e",
   "metadata": {},
   "source": [
    "# LSF kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6155ad90-4e15-40ae-8e84-6b9394babd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LevelSetForecaster_kNN(BaseWeightsBasedPredictor):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 estimator, \n",
    "                 binSize = 100):\n",
    "        \n",
    "        if not (hasattr(estimator, 'predict') and callable(estimator.predict)):\n",
    "            raise ValueError(\"'estimator' has to have a 'predict'-method!\")\n",
    "        else:\n",
    "            self.estimator = estimator\n",
    "            \n",
    "        if not isinstance(binSize, (int, np.integer)):\n",
    "            raise ValueError(\"'binSize' has to be integer!\")\n",
    "        else:\n",
    "            self.binSize = binSize\n",
    "        \n",
    "        self.estimator = estimator\n",
    "        self.binSize = binSize\n",
    "        \n",
    "        self.Y = None\n",
    "        self.YPred = None\n",
    "        self.nearestNeighborsOnPreds = None\n",
    "        \n",
    "    #---\n",
    "    \n",
    "    def setBinSize(self, binSize):\n",
    "        self.binSize = binSize\n",
    "        \n",
    "    #---\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        YPredTrain = self.estimator.predict(X)\n",
    "        YPredTrain_reshaped = np.reshape(YPredTrain, newshape = (len(YPredTrain), 1))\n",
    "        \n",
    "        nn = NearestNeighbors(algorithm = 'kd_tree')\n",
    "        nn.fit(X = YPredTrain_reshaped)\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        self.Y = Y\n",
    "        self.YPredTrain = YPredTrain\n",
    "        self.nearestNeighborsOnPreds = nn\n",
    "        \n",
    "    #---\n",
    "        \n",
    "    def getWeightsData(self, X, outputType = 'onlyPositiveWeights', scalingList = None):\n",
    "        \n",
    "        nn = self.nearestNeighborsOnPreds\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        YPred = self.estimator.predict(X)   \n",
    "        YPred_reshaped = np.reshape(YPred, newshape = (len(YPred), 1))\n",
    "        \n",
    "        distancesDf, neighborsMatrix = nn.kneighbors(X = YPred_reshaped, \n",
    "                                                     n_neighbors = self.binSize + 1)\n",
    "        \n",
    "        #---\n",
    "\n",
    "        neighborsList = list(neighborsMatrix[:, 0:self.binSize])\n",
    "        distanceCheck = np.where(distancesDf[:, self.binSize - 1] == distancesDf[:, self.binSize])\n",
    "        indicesToMod = distanceCheck[0]\n",
    "\n",
    "        for index in indicesToMod:\n",
    "            distanceExtremePoint = np.absolute(YPred[index] - self.YPredTrain[neighborsMatrix[index, self.binSize-1]])\n",
    "            \n",
    "            neighborsByRadius = nn.radius_neighbors(X = YPred_reshaped[index:index + 1], \n",
    "                                                    radius = distanceExtremePoint, return_distance = False)[0]\n",
    "            neighborsList[index] = neighborsByRadius\n",
    "\n",
    "        #---\n",
    "        \n",
    "        for i in range(len(neighborsList)):\n",
    "            if len(neighborsList[i]) < self.binSize:\n",
    "                ipdb.set_trace()\n",
    "\n",
    "        #---\n",
    "                        \n",
    "        # weightsDataList is a list whose elements correspond to one test prediction each. \n",
    "        weightsDataList = [(np.repeat(1 / len(neighbors), len(neighbors)), np.array(neighbors)) for neighbors in neighborsList]\n",
    "\n",
    "        weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "                                                     outputType = outputType, \n",
    "                                                     Y = self.Y,\n",
    "                                                     scalingList = scalingList,\n",
    "                                                     equalWeights = True)\n",
    "\n",
    "        return weightsDataList\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fa5278-f73a-4316-9637-65fdd76433b0",
   "metadata": {},
   "source": [
    "# LSF Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9efbd-4d21-4bc5-8bd9-82015cbb2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "class binSizeCV:\n",
    "\n",
    "    def __init__(self,\n",
    "                 estimator,\n",
    "                 cv,\n",
    "                 LSF_type = None,\n",
    "                 binSizeGrid = np.array([4, 7, 10, 15, 20, 30, 40, 50, 60, 70, 80, \n",
    "                                         100, 125, 150, 200, 250, 300, 350, 400, 450, 500, 600, 700, 800, 900,\n",
    "                                         1000, 1250, 1500, 1750, 2000, 2500, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]),                 \n",
    "                 probs = np.array([i / 100 for i in range(1, 100, 1)]),\n",
    "                 refitPerProb = False,\n",
    "                 n_jobs = None):\n",
    "        \n",
    "        # CHECKS\n",
    "        \n",
    "        if isinstance(estimator, (LevelSetForecaster, LevelSetForecaster_kNN)):\n",
    "            raise ValueError(\"'estimator' has to be a point predictor and not a LevelSetForecaster-Object!\")   \n",
    "        elif not (hasattr(estimator, 'predict') and callable(estimator.predict)):\n",
    "            raise ValueError(\"'estimator' has to have a 'predict'-method!\")\n",
    "        else:\n",
    "            self.estimator = estimator\n",
    "            \n",
    "        if LSF_type is None or not LSF_type in [\"LSF\", \"LSF_kNN\"]:\n",
    "            raise ValueError(\"LSF_type must be specified and must either be 'LSF' or 'LSF_kNN'!\")\n",
    "        else:\n",
    "            self.LSF_type = LSF_type\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        # Ensure that binSizeGrid is an array if it is given by the user\n",
    "        binSizeGrid = np.array(binSizeGrid) \n",
    "        self.binSizeGrid = binSizeGrid\n",
    "        \n",
    "        self.probs = probs\n",
    "        self.cv = cv\n",
    "        self.refitPerProb = refitPerProb\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "        self.best_binSize = None\n",
    "        self.best_binSize_perProb = None\n",
    "        self.best_EstimatorLSF = None\n",
    "        self.cv_results = None\n",
    "        self.cv_results_raw = None\n",
    "        \n",
    "    #---\n",
    "\n",
    "    \"\"\"\n",
    "    Helper function. Creates weights-output by specifying considered\n",
    "    neighbors of training observations for every test observation of interest.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    LSF : LSF-object\n",
    "        A object of that type is instantiated for each grid point. This is assumed \n",
    "        to implement the scikit-learn estimator interface. Either estimator needs to \n",
    "        provide a score function, or scoring must be passed.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "    \n",
    "        scoresPerFold = Parallel(n_jobs = self.n_jobs)(delayed(scoresForFold)(binSizeGrid = self.binSizeGrid,\n",
    "                                                                              probs = self.probs,\n",
    "                                                                              foldNumber = foldNumber,\n",
    "                                                                              cvFolds = self.cv,\n",
    "                                                                              estimator = self.estimator,\n",
    "                                                                              LSF_type = self.LSF_type,\n",
    "                                                                              Y = Y,\n",
    "                                                                              X = X) for foldNumber in range(len(cvFolds)))    \n",
    "        \n",
    "        self.cv_results_raw = scoresPerFold\n",
    "        \n",
    "        #---\n",
    "\n",
    "        nvCostsMatrix = scoresPerFold[0]\n",
    "\n",
    "        for i in range(1, len(scoresPerFold)):\n",
    "            nvCostsMatrix = nvCostsMatrix + scoresPerFold[i]\n",
    "\n",
    "        nvCostsMatrix = nvCostsMatrix / len(cvFolds)\n",
    "        \n",
    "        self.cv_results = nvCostsMatrix\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        meanCostsDf = nvCostsMatrix.mean(axis = 1)\n",
    "        binSizeBestOverall = meanCostsDf.index[np.argmax(meanCostsDf)]\n",
    "        self.best_binSize = binSizeBestOverall\n",
    "        \n",
    "        binSizeBestPerProb = nvCostsMatrix.idxmax(axis = 0)\n",
    "        self.best_binSize_perProb = binSizeBestPerProb\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        if self.refitPerProb:\n",
    "            \n",
    "            LSFDict = dict()\n",
    "            for binSize in binSizeBestPerProb.unique():\n",
    "                \n",
    "                if self.LSF_type == 'LSF':\n",
    "                    LSF = LevelSetForecaster(estimator = self.estimator, \n",
    "                                             binSize = binSize)\n",
    "                else:\n",
    "                    LSF = LevelSetForecaster_kNN(estimator = self.estimator, \n",
    "                                                 binSize = binSize)\n",
    "                \n",
    "                LSF.fit(X = X, Y = Y)\n",
    "                LSFDict[binSize] = LSF\n",
    "            \n",
    "            self.best_estimatorLSF = {prob: LSFDict[binSizeBestPerProb.loc[prob]] \n",
    "                                      for prob in binSizeBestPerProb.index}\n",
    "        \n",
    "        else:\n",
    "            if self.LSF_type == 'LSF':\n",
    "                LSF = LevelSetForecaster(estimator = self.estimator, \n",
    "                                         binSize = binSizeBestOverall)\n",
    "            else:\n",
    "                LSF = LevelSetForecaster_kNN(estimator = self.estimator, \n",
    "                                             binSize = binSizeBestOverall)\n",
    "            \n",
    "            LSF.fit(X = X, Y = Y)\n",
    "            \n",
    "            self.best_estimatorLSF = LSF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e8431-0dbc-46b4-bacb-f43fba5e5576",
   "metadata": {},
   "source": [
    "## Scores for Single Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e17b4-a9ca-4d19-a8db-c2b6879cbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates the newsvendor performance for different bin sizes for one specific fold.\n",
    "# The considered bin sizes\n",
    "\n",
    "def scoresForFold(binSizeGrid, probs, foldNumber, cvFolds, estimator, LSF_type, Y, X):\n",
    "   \n",
    "    indicesTrain = cvFolds[foldNumber][0]\n",
    "    indicesTest = cvFolds[foldNumber][1]\n",
    "    \n",
    "    YTrainFold = Y[indicesTrain]\n",
    "    XTrainFold = X[indicesTrain]\n",
    "    \n",
    "    YTestFold = Y[indicesTest]\n",
    "    XTestFold = X[indicesTest]\n",
    "    \n",
    "    estimator.fit(X = XTrainFold, y = YTrainFold)\n",
    "    \n",
    "    #---\n",
    "       \n",
    "    SAA_fold = SAA()\n",
    "    SAA_fold.fit(Y = YTrainFold)\n",
    "    \n",
    "    # By setting 'X = None', the SAA results are only computed for a single observation (they are independent of X anyway).\n",
    "    # In order to receive the final dataframe of SAA results, we simply duplicate this single row as many times as needed.\n",
    "    quantilesDictSAAOneOb = SAA_fold.predict(X = None, probs = probs, outputAsDf = False)\n",
    "    quantilesDictSAA = {prob: np.repeat(quantile, len(XTestFold)) for prob, quantile in quantilesDictSAAOneOb.items()}\n",
    "    \n",
    "    #---\n",
    "                                                   \n",
    "    coefPresPerBinSize = list()\n",
    "    \n",
    "    binSizeGrid = [binSize for binSize in binSizeGrid if binSize <= len(YTrainFold)]\n",
    "    \n",
    "    for binSize in iter(binSizeGrid):\n",
    "        \n",
    "        if LSF_type == 'LSF':\n",
    "            estimatorLSF = LevelSetForecaster(estimator = estimator,\n",
    "                                              binSize = binSize)\n",
    "        else:\n",
    "            estimatorLSF = LevelSetForecaster_kNN(estimator = estimator,\n",
    "                                                  binSize = binSize)\n",
    "        \n",
    "        estimatorLSF.fit(X = XTrainFold,\n",
    "                         Y = YTrainFold)\n",
    "        \n",
    "        quantilesDict = estimatorLSF.predict(X = XTestFold,\n",
    "                                             probs = probs,\n",
    "                                             outputAsDf = False)\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        # coeffPres = Coefficient of Prescriptiveness\n",
    "        \n",
    "        coefPresDict = {prob: [] for prob in probs}\n",
    "        \n",
    "        for prob in probs:            \n",
    "            coefPres = getCoefPres(decisions = quantilesDict[prob], \n",
    "                                   decisionsSAA = quantilesDictSAA[prob], \n",
    "                                   YTest = YTestFold, \n",
    "                                   prob = prob)\n",
    "            \n",
    "            coefPresDict[prob].append(coefPres)\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    coefPresDf = pd.DataFrame(coefPresDict, index = binSizeGrid)\n",
    "    \n",
    "    return coefPresDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63171bdb-1e7b-4407-b6ea-c56ff0dee7e2",
   "metadata": {},
   "source": [
    "### Coefficient of Prescriptiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a49f19-5f88-4600-bb1d-ff237b7daf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCoefPres(decisions, decisionsSAA, YTest, prob):\n",
    "\n",
    "    # Newsvendor Costs of our model\n",
    "    cost = np.array([prob * (YTest[i] - decisions[i]) if YTest[i] > decisions[i] \n",
    "                     else (1 - prob) * (decisions[i] - YTest[i]) \n",
    "                     for i in range(len(YTest))]).sum()\n",
    "    \n",
    "    # Newsvendor Costs of SAA\n",
    "    costSAA = np.array([prob * (YTest[i] - decisionsSAA[i]) if YTest[i] > decisionsSAA[i] \n",
    "                        else (1 - prob) * (decisionsSAA[i] - YTest[i]) \n",
    "                        for i in range(len(YTest))]).sum()\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    # We have to capture the special case of costSAA == 0, because then we can't compute the \n",
    "    # Coefficient of Prescriptiveness using the actual definition.\n",
    "    if costSAA > 0:\n",
    "        coefPres = 1 - cost / costSAA\n",
    "    else:\n",
    "        if cost == 0:\n",
    "            coefPres = 1\n",
    "        else:\n",
    "            coefPres = 0\n",
    "    \n",
    "    return coefPres"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HC-Scheduling",
   "language": "python",
   "name": "hc-scheduling"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
