{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114de996-a4fe-43f9-998e-38796e1a4412",
   "metadata": {},
   "source": [
    "## Loading Yaz Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac897f-05f7-4086-9694-4d18265d7e63",
   "metadata": {},
   "source": [
    "## Grouped Time Series Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8f9421-8c1d-4ce4-91f7-233efc5a4c4b",
   "metadata": {},
   "source": [
    "## Bin Size Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a821af90-5aa5-41d1-8903-73f145e84ffb",
   "metadata": {},
   "source": [
    "### LSx Bin-Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9bd45b-5812-470e-9843-2681a9a32061",
   "metadata": {},
   "source": [
    "#### Normal Weights, no refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a8f4a6-e341-4826-895a-8a6c40dc179e",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "kFolds = 2\n",
    "probs = [0.001, 0.01, 0.1, 0.5, 0.9, 0.99, 0.999]\n",
    "binSizeGrid = [1, 100, 1000, 10000]\n",
    "LSF_type = 'LSF'\n",
    "\n",
    "dataTrain = data[data['label'] == 'train']\n",
    "\n",
    "cvFolds = groupedTimeSeriesSplit(data = dataTrain, \n",
    "                                 kFolds = kFolds, \n",
    "                                 testLength = 28, \n",
    "                                 groupFeature = 'id', \n",
    "                                 timeFeature = 'dayIndex')\n",
    "\n",
    "CV = binSizeCV(estimator = LGBM, \n",
    "               cvFolds = cvFolds, \n",
    "               LSF_type = LSF_type, \n",
    "               weightsByDistance = False,\n",
    "               binSizeGrid = binSizeGrid,\n",
    "               probs = probs,\n",
    "               refitPerProb = False,\n",
    "               n_jobs = None)\n",
    "\n",
    "CV.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a361aa6-7603-444b-b796-84fb939db348",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "test_eq(CV.cvFolds, cvFolds)\n",
    "test_eq(CV.probs, probs)\n",
    "assert not CV.weightsByDistance\n",
    "assert not CV.refitPerProb\n",
    "\n",
    "#---\n",
    "\n",
    "# Stored binSize-Grid\n",
    "binSizesFiltered = [binSize for binSize in CV.binSizeGrid if binSize <= len(cvFolds[0][0])]\n",
    "test_eq(CV.binSizeGrid, binSizesFiltered)\n",
    "\n",
    "#---\n",
    "\n",
    "# Estimator the same?\n",
    "test_eq(CV.estimator, LGBM)\n",
    "# test_eq(CV.estimator.predict(XTest), LGBM.predict(XTest))\n",
    "\n",
    "#---\n",
    "\n",
    "# CV results raw\n",
    "assert isinstance(CV.cv_results_raw, list)\n",
    "test_eq(len(CV.cv_results_raw), kFolds)\n",
    "\n",
    "for resDf in CV.cv_results_raw:\n",
    "    test_eq(resDf.shape, (len(binSizesFiltered), len(probs)))\n",
    "    test_eq(resDf.index, binSizesFiltered)\n",
    "    test_eq(resDf.columns, probs)\n",
    "    assert np.all(resDf >= 0)\n",
    "    \n",
    "#---\n",
    "\n",
    "# CV results aggregated\n",
    "meanCostMatrix = 0\n",
    "for i in range(0, kFolds, 1):\n",
    "    meanCostMatrix += CV.cv_results_raw[i]\n",
    "    \n",
    "meanCostMatrix = meanCostMatrix / kFolds\n",
    "\n",
    "assert np.allclose(CV.cv_results, meanCostMatrix)\n",
    "\n",
    "test_eq(CV.cv_results.shape, (len(binSizesFiltered), len(probs)))\n",
    "test_eq(CV.cv_results.index, binSizesFiltered)\n",
    "test_eq(CV.cv_results.columns, probs)\n",
    "assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# best bin size\n",
    "averageCostsPerBin = CV.cv_results.mean(axis = 1)\n",
    "best_binSize_test = CV.cv_results.index[np.argmin(averageCostsPerBin)]\n",
    "test_eq(CV.best_binSize, best_binSize_test)\n",
    "assert CV.best_binSize in binSizeGrid\n",
    "\n",
    "#---\n",
    "\n",
    "# best bin size per prob\n",
    "test_eq(len(CV.best_binSize_perProb), len(probs))\n",
    "assert [binSize in binSizeGrid for binSize in CV.best_binSize_perProb]\n",
    "\n",
    "best_binSize_perProb_test = CV.cv_results.idxmin(axis = 0)\n",
    "test_eq(CV.best_binSize_perProb, best_binSize_perProb_test)\n",
    "\n",
    "#---\n",
    "\n",
    "# refitted LSx object\n",
    "assert isinstance(CV.best_estimatorLSx, LevelSetKDEx)\n",
    "test_eq(CV.best_estimatorLSx.estimator, LGBM)\n",
    "test_eq(CV.best_estimatorLSx.binSize, best_binSize_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad267426-a8ab-4c1a-813f-73506ec71ff0",
   "metadata": {},
   "source": [
    "#### Normal Weights, refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c804f50-c5b5-4c65-b765-3d5a4c7bdf04",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "kFolds = 2\n",
    "probs = [0.001, 0.01, 0.1, 0.5, 0.9, 0.99, 0.999]\n",
    "binSizeGrid = [1, 100, 1000, 10000]\n",
    "LSF_type = 'LSF'\n",
    "\n",
    "dataTrain = data[data['label'] == 'train']\n",
    "\n",
    "cvFolds = groupedTimeSeriesSplit(data = dataTrain, \n",
    "                                 kFolds = kFolds, \n",
    "                                 testLength = 28, \n",
    "                                 groupFeature = 'id', \n",
    "                                 timeFeature = 'dayIndex')\n",
    "\n",
    "CV = binSizeCV(estimator = LGBM, \n",
    "               cvFolds = cvFolds, \n",
    "               LSF_type = LSF_type, \n",
    "               weightsByDistance = False,\n",
    "               binSizeGrid = binSizeGrid,\n",
    "               probs = probs,\n",
    "               refitPerProb = True,\n",
    "               n_jobs = None)\n",
    "\n",
    "CV.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3134136-bccc-44ff-9581-af0463f9b663",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "test_eq(CV.cvFolds, cvFolds)\n",
    "test_eq(CV.probs, probs)\n",
    "assert not CV.weightsByDistance\n",
    "assert CV.refitPerProb\n",
    "\n",
    "#---\n",
    "\n",
    "# Stored binSize-Grid\n",
    "binSizesFiltered = [binSize for binSize in CV.binSizeGrid if binSize <= len(cvFolds[0][0])]\n",
    "test_eq(CV.binSizeGrid, binSizesFiltered)\n",
    "\n",
    "#---\n",
    "\n",
    "# Estimator the same?\n",
    "test_eq(CV.estimator, LGBM)\n",
    "# test_eq(CV.estimator.predict(XTest), LGBM.predict(XTest))\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Raw\n",
    "assert isinstance(CV.cv_results_raw, list)\n",
    "test_eq(len(CV.cv_results_raw), kFolds)\n",
    "\n",
    "for resDf in CV.cv_results_raw:\n",
    "    test_eq(resDf.shape, (len(binSizesFiltered), len(probs)))\n",
    "    test_eq(resDf.index, binSizesFiltered)\n",
    "    test_eq(resDf.columns, probs)\n",
    "    assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Aggregated\n",
    "meanCostMatrix = 0\n",
    "for i in range(0, kFolds, 1):\n",
    "    meanCostMatrix += CV.cv_results_raw[i]\n",
    "    \n",
    "meanCostMatrix = meanCostMatrix / kFolds\n",
    "\n",
    "assert np.allclose(CV.cv_results, meanCostMatrix)\n",
    "\n",
    "test_eq(CV.cv_results.shape, (len(binSizesFiltered), len(probs)))\n",
    "test_eq(CV.cv_results.index, binSizesFiltered)\n",
    "test_eq(CV.cv_results.columns, probs)\n",
    "assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size\n",
    "averageCostsPerBin = CV.cv_results.mean(axis = 1)\n",
    "best_binSize_test = CV.cv_results.index[np.argmin(averageCostsPerBin)]\n",
    "test_eq(CV.best_binSize, best_binSize_test)\n",
    "assert CV.best_binSize in binSizeGrid\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size per prob\n",
    "test_eq(len(CV.best_binSize_perProb), len(probs))\n",
    "assert [binSize in binSizeGrid for binSize in CV.best_binSize_perProb]\n",
    "\n",
    "best_binSize_perProb_test = CV.cv_results.idxmin(axis = 0)\n",
    "test_eq(CV.best_binSize_perProb, best_binSize_perProb_test)\n",
    "\n",
    "#---\n",
    "\n",
    "# refitted LSx objects\n",
    "assert isinstance(CV.best_estimatorLSx, dict)\n",
    "test_eq(list(CV.best_estimatorLSx.keys()), probs)\n",
    "\n",
    "for prob, LSx in CV.best_estimatorLSx.items():\n",
    "    assert isinstance(LSx, LevelSetKDEx)\n",
    "    test_eq(LSx.estimator, LGBM)\n",
    "    test_eq(LSx.binSize, best_binSize_perProb_test.loc[prob])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1af564-fa1b-46bf-9f3b-0094f8df9df2",
   "metadata": {},
   "source": [
    "#### Distance Weights, no refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1634a77-cb75-4456-bdb7-5b9326e9e462",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "kFolds = 2\n",
    "probs = [0.001, 0.01, 0.1, 0.5, 0.9, 0.99, 0.999]\n",
    "binSizeGrid = [1, 100, 1000, 10000]\n",
    "LSF_type = 'LSF'\n",
    "\n",
    "dataTrain = data[data['label'] == 'train']\n",
    "\n",
    "cvFolds = groupedTimeSeriesSplit(data = dataTrain, \n",
    "                                 kFolds = kFolds, \n",
    "                                 testLength = 28, \n",
    "                                 groupFeature = 'id', \n",
    "                                 timeFeature = 'dayIndex')\n",
    "\n",
    "CVDistance = binSizeCV(estimator = LGBM, \n",
    "                       cvFolds = cvFolds, \n",
    "                       LSF_type = LSF_type, \n",
    "                       weightsByDistance = True,\n",
    "                       binSizeGrid = binSizeGrid,\n",
    "                       probs = probs,\n",
    "                       refitPerProb = False,\n",
    "                       n_jobs = None)\n",
    "\n",
    "CVDistance.fit(X = XTrain, y = yTrain)\n",
    "\n",
    "#---\n",
    "\n",
    "CVStandard = binSizeCV(estimator = LGBM, \n",
    "                       cvFolds = cvFolds, \n",
    "                       LSF_type = LSF_type, \n",
    "                       weightsByDistance = False,\n",
    "                       binSizeGrid = binSizeGrid,\n",
    "                       probs = probs,\n",
    "                       refitPerProb = False,\n",
    "                       n_jobs = None)\n",
    "\n",
    "CVStandard.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fe4ad1-9315-4e2a-96cf-1b448c1e2b14",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "test_eq(CVDistance.cvFolds, cvFolds)\n",
    "test_eq(CVDistance.probs, probs)\n",
    "assert CVDistance.weightsByDistance\n",
    "assert not CVDistance.refitPerProb\n",
    "\n",
    "#---\n",
    "\n",
    "# Check if CV Results are different compared to the standard case of generating weights\n",
    "# This is supposed to check whether we really used the attribute 'weightsByDistance'\n",
    "# in the predict function inside scorePerFold\n",
    "assert not np.allclose(CVDistance.cv_results, CVStandard.cv_results)\n",
    "\n",
    "#---\n",
    "\n",
    "# Stored binSize-Grid\n",
    "binSizesFiltered = [binSize for binSize in CVDistance.binSizeGrid if binSize <= len(cvFolds[0][0])]\n",
    "test_eq(CVDistance.binSizeGrid, binSizesFiltered)\n",
    "\n",
    "#---\n",
    "\n",
    "# Estimator the same?\n",
    "test_eq(CVDistance.estimator, LGBM)\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Raw\n",
    "assert isinstance(CVDistance.cv_results_raw, list)\n",
    "test_eq(len(CVDistance.cv_results_raw), kFolds)\n",
    "\n",
    "for resDf in CVDistance.cv_results_raw:\n",
    "    test_eq(resDf.shape, (len(binSizesFiltered), len(probs)))\n",
    "    test_eq(resDf.index, binSizesFiltered)\n",
    "    test_eq(resDf.columns, probs)\n",
    "    assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Aggregated\n",
    "meanCostMatrix = 0\n",
    "for i in range(0, kFolds, 1):\n",
    "    meanCostMatrix += CVDistance.cv_results_raw[i]\n",
    "    \n",
    "meanCostMatrix = meanCostMatrix / kFolds\n",
    "\n",
    "assert np.allclose(CVDistance.cv_results, meanCostMatrix)\n",
    "\n",
    "test_eq(CVDistance.cv_results.shape, (len(binSizesFiltered), len(probs)))\n",
    "test_eq(CVDistance.cv_results.index, binSizesFiltered)\n",
    "test_eq(CVDistance.cv_results.columns, probs)\n",
    "assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size\n",
    "averageCostsPerBin = CVDistance.cv_results.mean(axis = 1)\n",
    "best_binSize_test = CVDistance.cv_results.index[np.argmin(averageCostsPerBin)]\n",
    "test_eq(CVDistance.best_binSize, best_binSize_test)\n",
    "assert CVDistance.best_binSize in binSizeGrid\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size per prob\n",
    "test_eq(len(CVDistance.best_binSize_perProb), len(probs))\n",
    "assert [binSize in binSizeGrid for binSize in CVDistance.best_binSize_perProb]\n",
    "\n",
    "best_binSize_perProb_test = CVDistance.cv_results.idxmin(axis = 0)\n",
    "test_eq(CVDistance.best_binSize_perProb, best_binSize_perProb_test)\n",
    "\n",
    "#---\n",
    "\n",
    "# refitted LSx object\n",
    "assert isinstance(CVDistance.best_estimatorLSx, LevelSetKDEx)\n",
    "test_eq(CVDistance.best_estimatorLSx.estimator, LGBM)\n",
    "test_eq(CVDistance.best_estimatorLSx.binSize, best_binSize_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c16c86a-519c-49ad-8fe8-f44cc2c056cd",
   "metadata": {},
   "source": [
    "#### Distance Weights, refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92048279-9c4f-4c67-8a9f-3adda2e494ae",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "kFolds = 2\n",
    "probs = [0.001, 0.01, 0.1, 0.5, 0.9, 0.99, 0.999]\n",
    "binSizeGrid = [1, 100, 1000, 10000]\n",
    "LSF_type = 'LSF'\n",
    "\n",
    "dataTrain = data[data['label'] == 'train']\n",
    "\n",
    "cvFolds = groupedTimeSeriesSplit(data = dataTrain, \n",
    "                                 kFolds = kFolds, \n",
    "                                 testLength = 28, \n",
    "                                 groupFeature = 'id', \n",
    "                                 timeFeature = 'dayIndex')\n",
    "\n",
    "CVDistance = binSizeCV(estimator = LGBM, \n",
    "                       cvFolds = cvFolds, \n",
    "                       LSF_type = LSF_type, \n",
    "                       weightsByDistance = True,\n",
    "                       binSizeGrid = binSizeGrid,\n",
    "                       probs = probs,\n",
    "                       refitPerProb = True,\n",
    "                       n_jobs = None)\n",
    "\n",
    "CVDistance.fit(X = XTrain, y = yTrain)\n",
    "\n",
    "#---\n",
    "\n",
    "CVStandard = binSizeCV(estimator = LGBM, \n",
    "                       cvFolds = cvFolds, \n",
    "                       LSF_type = LSF_type, \n",
    "                       weightsByDistance = False,\n",
    "                       binSizeGrid = binSizeGrid,\n",
    "                       probs = probs,\n",
    "                       refitPerProb = True,\n",
    "                       n_jobs = None)\n",
    "\n",
    "CVStandard.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e97938-9c42-4fdc-a5c5-21cd07bd90ef",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "test_eq(CVDistance.cvFolds, cvFolds)\n",
    "test_eq(CVDistance.probs, probs)\n",
    "assert CVDistance.weightsByDistance\n",
    "assert CVDistance.refitPerProb\n",
    "\n",
    "#---\n",
    "\n",
    "# Check if CV Results are different compared to the standard case of generating weights\n",
    "# This is supposed to check whether we really used the attribute 'weightsByDistance'\n",
    "# in the predict function inside scorePerFold\n",
    "assert not np.allclose(CVDistance.cv_results, CVStandard.cv_results)\n",
    "\n",
    "#---\n",
    "\n",
    "# Stored binSize-Grid\n",
    "binSizesFiltered = [binSize for binSize in CVDistance.binSizeGrid if binSize <= len(cvFolds[0][0])]\n",
    "test_eq(CVDistance.binSizeGrid, binSizesFiltered)\n",
    "\n",
    "#---\n",
    "\n",
    "# Estimator the same?\n",
    "test_eq(CVDistance.estimator, LGBM)\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Raw\n",
    "assert isinstance(CVDistance.cv_results_raw, list)\n",
    "test_eq(len(CVDistance.cv_results_raw), kFolds)\n",
    "\n",
    "for resDf in CVDistance.cv_results_raw:\n",
    "    test_eq(resDf.shape, (len(binSizesFiltered), len(probs)))\n",
    "    test_eq(resDf.index, binSizesFiltered)\n",
    "    test_eq(resDf.columns, probs)\n",
    "    assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Aggregated\n",
    "meanCostMatrix = 0\n",
    "for i in range(0, kFolds, 1):\n",
    "    meanCostMatrix += CVDistance.cv_results_raw[i]\n",
    "    \n",
    "meanCostMatrix = meanCostMatrix / kFolds\n",
    "\n",
    "assert np.allclose(CVDistance.cv_results, meanCostMatrix)\n",
    "\n",
    "test_eq(CVDistance.cv_results.shape, (len(binSizesFiltered), len(probs)))\n",
    "test_eq(CVDistance.cv_results.index, binSizesFiltered)\n",
    "test_eq(CVDistance.cv_results.columns, probs)\n",
    "assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size\n",
    "averageCostsPerBin = CVDistance.cv_results.mean(axis = 1)\n",
    "best_binSize_test = CVDistance.cv_results.index[np.argmin(averageCostsPerBin)]\n",
    "test_eq(CVDistance.best_binSize, best_binSize_test)\n",
    "assert CVDistance.best_binSize in binSizeGrid\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size per prob\n",
    "test_eq(len(CVDistance.best_binSize_perProb), len(probs))\n",
    "assert [binSize in binSizeGrid for binSize in CVDistance.best_binSize_perProb]\n",
    "\n",
    "best_binSize_perProb_test = CVDistance.cv_results.idxmin(axis = 0)\n",
    "test_eq(CVDistance.best_binSize_perProb, best_binSize_perProb_test)\n",
    "\n",
    "#---\n",
    "\n",
    "# refitted LSx objects\n",
    "assert isinstance(CVDistance.best_estimatorLSx, dict)\n",
    "test_eq(list(CVDistance.best_estimatorLSx.keys()), probs)\n",
    "\n",
    "for prob, LSx in CVDistance.best_estimatorLSx.items():\n",
    "    assert isinstance(LSx, LevelSetKDEx)\n",
    "    test_eq(LSx.estimator, LGBM)\n",
    "    test_eq(LSx.binSize, best_binSize_perProb_test.loc[prob])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecac0f2b-6327-4462-b634-24aa2a62f8ca",
   "metadata": {},
   "source": [
    "### LSx kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea77988-a469-4c24-90dc-2221b75b056b",
   "metadata": {},
   "source": [
    "#### Normal Weights, refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f748d9e-3417-4f0d-8bf8-92657210acef",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "kFolds = 3\n",
    "probs = [0.005, 0.2, 0.4, 0.6, 0.78,0.99999]\n",
    "binSizeGrid = [1, 100, 1000, 10000, 2000000]\n",
    "LSF_type = 'LSF_kNN'\n",
    "\n",
    "dataTrain = data[data['label'] == 'train']\n",
    "\n",
    "cvFolds = groupedTimeSeriesSplit(data = dataTrain, \n",
    "                                 kFolds = kFolds, \n",
    "                                 testLength = 7, \n",
    "                                 groupFeature = 'id', \n",
    "                                 timeFeature = 'dayIndex')\n",
    "\n",
    "CV = binSizeCV(estimator = LGBM, \n",
    "               cvFolds = cvFolds, \n",
    "               LSF_type = LSF_type, \n",
    "               weightsByDistance = False,\n",
    "               binSizeGrid = binSizeGrid, \n",
    "               probs = probs,\n",
    "               refitPerProb = True,\n",
    "               n_jobs = 2)\n",
    "\n",
    "CV.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a382e-462e-4627-ab69-157cea29ff0a",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "test_eq(CV.cvFolds, cvFolds)\n",
    "test_eq(CV.probs, probs)\n",
    "assert not CV.weightsByDistance\n",
    "assert CV.refitPerProb\n",
    "\n",
    "#---\n",
    "\n",
    "# Stored binSize-Grid\n",
    "binSizesFiltered = [binSize for binSize in CV.binSizeGrid if binSize <= len(cvFolds[0][0])]\n",
    "test_eq(CV.binSizeGrid, binSizesFiltered)\n",
    "\n",
    "#---\n",
    "\n",
    "# Estimator the same?\n",
    "test_eq(CV.estimator, LGBM)\n",
    "# test_eq(CV.estimator.predict(XTest), LGBM.predict(XTest))\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Raw\n",
    "assert isinstance(CV.cv_results_raw, list)\n",
    "test_eq(len(CV.cv_results_raw), kFolds)\n",
    "\n",
    "for resDf in CV.cv_results_raw:\n",
    "    test_eq(resDf.shape, (len(binSizesFiltered), len(probs)))\n",
    "    test_eq(resDf.index, binSizesFiltered)\n",
    "    test_eq(resDf.columns, probs)\n",
    "    assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Aggregated\n",
    "meanCostMatrix = 0\n",
    "for i in range(0, kFolds, 1):\n",
    "    meanCostMatrix += CV.cv_results_raw[i]\n",
    "    \n",
    "meanCostMatrix = meanCostMatrix / kFolds\n",
    "\n",
    "assert np.allclose(CV.cv_results, meanCostMatrix)\n",
    "\n",
    "test_eq(CV.cv_results.shape, (len(binSizesFiltered), len(probs)))\n",
    "test_eq(CV.cv_results.index, binSizesFiltered)\n",
    "test_eq(CV.cv_results.columns, probs)\n",
    "assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size\n",
    "averageCostsPerBin = CV.cv_results.mean(axis = 1)\n",
    "best_binSize_test = CV.cv_results.index[np.argmin(averageCostsPerBin)]\n",
    "test_eq(CV.best_binSize, best_binSize_test)\n",
    "assert CV.best_binSize in binSizeGrid\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size per prob\n",
    "test_eq(len(CV.best_binSize_perProb), len(probs))\n",
    "assert [binSize in binSizeGrid for binSize in CV.best_binSize_perProb]\n",
    "\n",
    "best_binSize_perProb_test = CV.cv_results.idxmin(axis = 0)\n",
    "test_eq(CV.best_binSize_perProb, best_binSize_perProb_test)\n",
    "\n",
    "#---\n",
    "\n",
    "# refitted LSx objects\n",
    "assert isinstance(CV.best_estimatorLSx, dict)\n",
    "test_eq(list(CV.best_estimatorLSx.keys()), probs)\n",
    "\n",
    "for prob, LSx in CV.best_estimatorLSx.items():\n",
    "    assert isinstance(LSx, LevelSetKDEx_kNN)\n",
    "    test_eq(LSx.estimator, LGBM)\n",
    "    test_eq(LSx.binSize, best_binSize_perProb_test.loc[prob])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524f0da-d4da-49da-8466-d4bd78ebfa9d",
   "metadata": {},
   "source": [
    "#### Distance Weights, refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3fe671-5c09-44ac-9e0c-6e85b791182f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "kFolds = 3\n",
    "probs = [0.005, 0.2, 0.4, 0.6, 0.78,0.99999]\n",
    "binSizeGrid = [1, 100, 1000, 10000, 2000000]\n",
    "LSF_type = 'LSF_kNN'\n",
    "\n",
    "dataTrain = data[data['label'] == 'train']\n",
    "\n",
    "cvFolds = groupedTimeSeriesSplit(data = dataTrain, \n",
    "                                 kFolds = kFolds, \n",
    "                                 testLength = 7, \n",
    "                                 groupFeature = 'id', \n",
    "                                 timeFeature = 'dayIndex')\n",
    "\n",
    "CVDistance = binSizeCV(estimator = LGBM, \n",
    "                       cvFolds = cvFolds, \n",
    "                       LSF_type = LSF_type,\n",
    "                       weightsByDistance = True,\n",
    "                       binSizeGrid = binSizeGrid, \n",
    "                       probs = probs,\n",
    "                       refitPerProb = True,\n",
    "                       n_jobs = 2)\n",
    "\n",
    "CVDistance.fit(X = XTrain, y = yTrain)\n",
    "\n",
    "#---\n",
    "\n",
    "CVStandard = binSizeCV(estimator = LGBM, \n",
    "                       cvFolds = cvFolds, \n",
    "                       LSF_type = LSF_type, \n",
    "                       weightsByDistance = False,\n",
    "                       binSizeGrid = binSizeGrid,\n",
    "                       probs = probs,\n",
    "                       refitPerProb = True,\n",
    "                       n_jobs = None)\n",
    "\n",
    "CVStandard.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817c2d2-6945-459c-891e-01e1c1fa28df",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "test_eq(CVDistance.cvFolds, cvFolds)\n",
    "test_eq(CVDistance.probs, probs)\n",
    "assert CVDistance.weightsByDistance\n",
    "assert CVDistance.refitPerProb\n",
    "\n",
    "#---\n",
    "\n",
    "# Check if CV Results are different compared to the standard case of generating weights\n",
    "# This is supposed to check whether we really used the attribute 'weightsByDistance'\n",
    "# in the predict function inside scorePerFold\n",
    "assert not np.allclose(CVDistance.cv_results, CVStandard.cv_results)\n",
    "\n",
    "#---\n",
    "\n",
    "# Stored binSize-Grid\n",
    "binSizesFiltered = [binSize for binSize in CVDistance.binSizeGrid if binSize <= len(cvFolds[0][0])]\n",
    "test_eq(CVDistance.binSizeGrid, binSizesFiltered)\n",
    "\n",
    "#---\n",
    "\n",
    "# Estimator the same?\n",
    "test_eq(CVDistance.estimator, LGBM)\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Raw\n",
    "assert isinstance(CVDistance.cv_results_raw, list)\n",
    "test_eq(len(CVDistance.cv_results_raw), kFolds)\n",
    "\n",
    "for resDf in CVDistance.cv_results_raw:\n",
    "    test_eq(resDf.shape, (len(binSizesFiltered), len(probs)))\n",
    "    test_eq(resDf.index, binSizesFiltered)\n",
    "    test_eq(resDf.columns, probs)\n",
    "    assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# CV Results Aggregated\n",
    "meanCostMatrix = 0\n",
    "for i in range(0, kFolds, 1):\n",
    "    meanCostMatrix += CVDistance.cv_results_raw[i]\n",
    "    \n",
    "meanCostMatrix = meanCostMatrix / kFolds\n",
    "\n",
    "assert np.allclose(CVDistance.cv_results, meanCostMatrix)\n",
    "\n",
    "test_eq(CVDistance.cv_results.shape, (len(binSizesFiltered), len(probs)))\n",
    "test_eq(CVDistance.cv_results.index, binSizesFiltered)\n",
    "test_eq(CVDistance.cv_results.columns, probs)\n",
    "assert np.all(resDf >= 0)\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size\n",
    "averageCostsPerBin = CVDistance.cv_results.mean(axis = 1)\n",
    "best_binSize_test = CVDistance.cv_results.index[np.argmin(averageCostsPerBin)]\n",
    "test_eq(CVDistance.best_binSize, best_binSize_test)\n",
    "assert CVDistance.best_binSize in binSizeGrid\n",
    "\n",
    "#---\n",
    "\n",
    "# Best bin size per prob\n",
    "test_eq(len(CVDistance.best_binSize_perProb), len(probs))\n",
    "assert [binSize in binSizeGrid for binSize in CVDistance.best_binSize_perProb]\n",
    "\n",
    "best_binSize_perProb_test = CVDistance.cv_results.idxmin(axis = 0)\n",
    "test_eq(CVDistance.best_binSize_perProb, best_binSize_perProb_test)\n",
    "\n",
    "#---\n",
    "\n",
    "# refitted LSx objects\n",
    "assert isinstance(CVDistance.best_estimatorLSx, dict)\n",
    "test_eq(list(CVDistance.best_estimatorLSx.keys()), probs)\n",
    "\n",
    "for prob, LSx in CVDistance.best_estimatorLSx.items():\n",
    "    assert isinstance(LSx, LevelSetKDEx_kNN)\n",
    "    test_eq(LSx.estimator, LGBM)\n",
    "    test_eq(LSx.binSize, best_binSize_perProb_test.loc[prob])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4112db-d50d-46aa-9e66-b09c7cceb90b",
   "metadata": {},
   "source": [
    "## LS_KDEx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e63dd3f-e332-4a5f-857f-9c031edab2b0",
   "metadata": {},
   "source": [
    "### Standard Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b972c2d6-2f1e-4cd9-9ed8-6e6cd39029ee",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# All train-indices must be part of indicesPerBin\n",
    "# and duplicates mustn't exist\n",
    "indicesList = list()\n",
    "\n",
    "for values in LS_KDEx.indicesPerBin.values():\n",
    "    indicesList.extend(values)\n",
    "    \n",
    "test_eq(set(indicesList), set(np.arange(XTrain.shape[0])))\n",
    "test_eq(len(indicesList), XTrain.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c3c72b-4409-4ad8-a5d4-f66eddee2e8f",
   "metadata": {},
   "source": [
    "### Lower Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1746eb43-e46a-4695-98bf-e0bada400385",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Lower-bound structure has to be correct\n",
    "yPred = LS_KDEx.yPred\n",
    "indicesPerBin = LS_KDEx.indicesPerBin\n",
    "lowerBoundPerBin = LS_KDEx.lowerBoundPerBin\n",
    "\n",
    "for i in range(len(indicesPerBin)):\n",
    "    binIndex = list(indicesPerBin.keys())[i]\n",
    "    indices = indicesPerBin[binIndex]\n",
    "    \n",
    "    minValue = yPred[indices].min()\n",
    "    maxValue = yPred[indices].max()\n",
    "    \n",
    "    assert minValue >= lowerBoundPerBin.loc[binIndex]\n",
    "    \n",
    "    if binIndex < max(list(indicesPerBin.keys())):\n",
    "        assert maxValue < lowerBoundPerBin.loc[binIndex + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb508cd-dde2-49eb-a95e-61597497632a",
   "metadata": {},
   "source": [
    "### getWeights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532ef110-b8d2-443b-b98a-fef857a09820",
   "metadata": {},
   "source": [
    "#### Standard Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8193d3-ffdf-4fb3-b18e-9c6028ea8852",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Weights-Output Test\n",
    "\n",
    "LS_KDEx = LevelSetKDEx(estimator = LGBM, binSize = 100)\n",
    "LS_KDEx.fit(XTrain, yTrain)\n",
    "\n",
    "#---\n",
    "\n",
    "indicesPerBin = LS_KDEx.indicesPerBin\n",
    "lowerBoundPerBin = LS_KDEx.lowerBoundPerBin\n",
    "yPredTrain = LGBM.predict(XTrain)\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "binPerPred = np.searchsorted(a = lowerBoundPerBin, v = yPredTest, side = 'right') - 1\n",
    "indicesPerPred = [indicesPerBin[binIndex] for binIndex in binPerPred]\n",
    "\n",
    "#---\n",
    "\n",
    "weightsAll = LS_KDEx.getWeights(X = XTest, outputType = 'all')\n",
    "\n",
    "# Check if every bin contains at least 100 observations\n",
    "binSizesReal = [sum(weightsAll[i] > 0) for i in range(XTest.shape[0])]\n",
    "assert (np.array(binSizesReal) >= 100).all()\n",
    "\n",
    "test_eq(len(weightsAll), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsAll)):\n",
    "    weights = weightsAll[i]\n",
    "    \n",
    "    assert all(weights >= 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    test_eq(np.where(weights > 0)[0], np.sort(indicesPerPred[i]))\n",
    "\n",
    "#---\n",
    "\n",
    "weightsOnlyPos = LS_KDEx.getWeights(X = XTest, outputType = 'onlyPositiveWeights')\n",
    "\n",
    "# Check if every bin contains at least 100 observations\n",
    "binSizesReal = [len(weightsOnlyPos[i][1]) for i in range(XTest.shape[0])]\n",
    "assert (np.array(binSizesReal) >= 100).all()\n",
    "\n",
    "test_eq(len(weightsOnlyPos), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsOnlyPos)):\n",
    "    weights = weightsOnlyPos[i][0]\n",
    "    indices = weightsOnlyPos[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    test_eq(indices, indicesPerPred[i])\n",
    "    \n",
    "    if len(indices) > 100:\n",
    "        checkLastBin = yPredTrain.max() == yPredTrain[indices].max()\n",
    "        checkBinExtension = yPredTrain[indices[99]] == yPredTrain[indices[100]]\n",
    "        assert checkLastBin or checkBinExtension\n",
    "        \n",
    "#---\n",
    "\n",
    "weightsSummarized = LS_KDEx.getWeights(X = XTest, outputType = 'summarized')\n",
    "\n",
    "test_eq(len(weightsSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsSummarized)):\n",
    "    weights = weightsSummarized[i][0]\n",
    "    values = weightsSummarized[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(set(yTrain[indicesPerPred[i]]), set(values))\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsCumDistr = LS_KDEx.getWeights(X = XTest, outputType = 'cumulativeDistribution')\n",
    "\n",
    "# Check if every bin contains at least 100 observations\n",
    "binSizesReal = [len(weightsCumDistr[i][1]) for i in range(XTest.shape[0])]\n",
    "assert (np.array(binSizesReal) >= 100).all()\n",
    "\n",
    "test_eq(len(weightsCumDistr), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsCumDistr)):\n",
    "    cumProb = weightsCumDistr[i][0]\n",
    "    values = weightsCumDistr[i][1]\n",
    "    \n",
    "    assert all(cumProb > 0)\n",
    "    assert isclose(cumProb.max(), 1)\n",
    "    test_eq(cumProb, np.sort(cumProb))\n",
    "    assert np.allclose(np.diff(cumProb), np.diff(cumProb)[0])\n",
    "    \n",
    "    test_eq(values, np.sort(yTrain[indicesPerPred[i]]))\n",
    "\n",
    "#---\n",
    "\n",
    "weightsDistrSummarized = LS_KDEx.getWeights(X = XTest, outputType = 'cumulativeDistributionSummarized')\n",
    "\n",
    "test_eq(len(weightsDistrSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsDistrSummarized)):\n",
    "    cumProb = weightsDistrSummarized[i][0]\n",
    "    values = weightsDistrSummarized[i][1]\n",
    "    \n",
    "    assert all(cumProb > 0)\n",
    "    assert isclose(cumProb.max(), 1)\n",
    "    test_eq(cumProb, np.sort(cumProb))\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(set(values), set(np.sort(yTrain[indicesPerPred[i]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e29b66c-f331-4150-b997-d71410f51cd6",
   "metadata": {},
   "source": [
    "#### Distance Based Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8df32ba-07c7-4d4d-9eac-1c0b0a3599cf",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Weights-Output Test\n",
    "\n",
    "# Modifying XTrain to enforce test-predictions being identical to train predictions\n",
    "XTrainMod = np.concatenate([XTest[0:2, :], XTrain], axis = 0)\n",
    "yTrainMod = np.concatenate([yTest[0:2], yTrain], axis = 0)\n",
    "\n",
    "LS_KDEx = LevelSetKDEx(estimator = LGBM, binSize = 100)\n",
    "LS_KDEx.fit(XTrainMod, yTrainMod)\n",
    "\n",
    "#---\n",
    "\n",
    "indicesPerBin = LS_KDEx.indicesPerBin\n",
    "lowerBoundPerBin = LS_KDEx.lowerBoundPerBin\n",
    "yPredTrain = LGBM.predict(XTrainMod)\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "binPerPred = np.searchsorted(a = lowerBoundPerBin, v = yPredTest, side = 'right') - 1\n",
    "indicesPerPred = [indicesPerBin[binIndex] for binIndex in binPerPred]\n",
    "\n",
    "predDistances = [np.abs(yPredTrain[indicesPerPred[i]] - yPredTest[i]) for i in range(XTest.shape[0])]\n",
    "\n",
    "#---\n",
    "\n",
    "weightsList = LS_KDEx.getWeights(X = XTest, weightsByDistance = True, outputType = 'onlyPositiveWeights')\n",
    "\n",
    "# Check if all bins either contain at least 100 observations or if not all weights have to equal\n",
    "binSizesReal = [len(weightsList[i][1]) for i in range(XTest.shape[0])]\n",
    "\n",
    "for i in range(len(binSizesReal)):\n",
    "    if binSizesReal[i] < 100:\n",
    "        assert np.allclose(weightsList[i][0], 1 / len(weightsList[i][0]))\n",
    "        \n",
    "# Because of our above modification of XTrain and yTrain, for the first and second test observation \n",
    "# the special case applies where the test prediction is identical to at least 1 train prediction.\n",
    "assert np.allclose(weightsList[0][0], 1 / len(weightsList[0][0]))\n",
    "assert np.allclose(weightsList[1][0], 1 / len(weightsList[0][0]))\n",
    "\n",
    "assert 0 in weightsList[0][1]\n",
    "assert 1 in weightsList[1][1]\n",
    "\n",
    "#---\n",
    "\n",
    "weightsAll = LS_KDEx.getWeights(X = XTest, weightsByDistance = True, outputType = 'all')\n",
    "\n",
    "test_eq(len(weightsAll), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsAll)):\n",
    "    neighbors = indicesPerPred[i]\n",
    "    distances = predDistances[i]\n",
    "    weights = weightsAll[i]\n",
    "    \n",
    "    assert all(weights >= 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        assert np.allclose(weights[neighborsPredDistanceZero], 1 / sum(predDistanceCloseZero))\n",
    "        test_eq(np.sort(neighborsPredDistanceZero), np.sort(np.where(weights > 0)[0]))\n",
    "        \n",
    "    else:\n",
    "        inverseDistances = 1 / distances\n",
    "        np.allclose(np.sort(weights[neighbors]), np.sort(inverseDistances / sum(inverseDistances)))\n",
    "        test_eq(np.sort(neighbors), np.sort(np.where(weights > 0)[0]))\n",
    "\n",
    "#---\n",
    "\n",
    "weightsOnlyPos = LS_KDEx.getWeights(X = XTest, weightsByDistance = True, outputType = 'onlyPositiveWeights')\n",
    "\n",
    "test_eq(len(weightsOnlyPos), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsOnlyPos)):\n",
    "    neighbors = indicesPerPred[i]\n",
    "    distances = predDistances[i]\n",
    "    weights = weightsOnlyPos[i][0]\n",
    "    indices = weightsOnlyPos[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        assert np.allclose(weights, 1 / sum(predDistanceCloseZero))\n",
    "        test_eq(np.sort(neighborsPredDistanceZero), np.sort(indices))\n",
    "            \n",
    "    else:\n",
    "        inverseDistances = 1 / distances\n",
    "        assert np.allclose(weights, inverseDistances / sum(inverseDistances))\n",
    "        test_eq(np.sort(neighbors), np.sort(indices))\n",
    "    \n",
    "    if len(indices) > 100:\n",
    "        checkLastBin = yPredTrain.max() == yPredTrain[indices].max()\n",
    "        checkBinExtension = yPredTrain[indices[99]] == yPredTrain[indices[100]]\n",
    "        assert checkLastBin or checkBinExtension\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsSummarized = LS_KDEx.getWeights(X = XTest, weightsByDistance = True, outputType = 'summarized')\n",
    "\n",
    "test_eq(len(weightsSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsSummarized)):\n",
    "    neighbors = indicesPerPred[i]\n",
    "    distances = predDistances[i]\n",
    "    weights = weightsSummarized[i][0]\n",
    "    values = weightsSummarized[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n",
    "            \n",
    "    else:\n",
    "        valuesByHand = yTrainMod[neighbors]\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(set(valuesByHand), set(values))\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsCumDistr = LS_KDEx.getWeights(X = XTest, weightsByDistance = True, outputType = 'cumulativeDistribution')\n",
    "\n",
    "test_eq(len(weightsCumDistr), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsCumDistr)):\n",
    "    neighbors = indicesPerPred[i]\n",
    "    distances = predDistances[i]\n",
    "    cumProb = weightsCumDistr[i][0]\n",
    "    values = weightsCumDistr[i][1]\n",
    "    \n",
    "    assert all(cumProb > 0)\n",
    "    assert isclose(cumProb.max(), 1)\n",
    "    test_eq(cumProb, np.sort(cumProb))\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n",
    "        nCloseZero = sum(predDistanceCloseZero)\n",
    "        assert np.allclose(cumProb, np.cumsum(np.repeat(1 / nCloseZero, nCloseZero)))\n",
    "        \n",
    "    else:\n",
    "        # The following test works if we use 'valuesByHand = yTrainMod[weightsOnlyPos[i][1]' to grab the yTrain values\n",
    "        # because the getWeights-function does nothing else. If we grab them differently here (e.g. via neighborsMatrix),\n",
    "        # the sorting can become different for identical yTrain values which will change the cumulated probabilities\n",
    "        # for exactly those indices (and only these). This has no practical implications for the usage of the computed\n",
    "        # cumulated distribution function, but it has for the exact value testing we are doing here.\n",
    "        inverseDistances = 1 / distances\n",
    "        valuesByHand = yTrainMod[weightsOnlyPos[i][1]]\n",
    "        valuesByHandIndicesSort = np.argsort(valuesByHand)\n",
    "        assert np.allclose(cumProb, np.cumsum((inverseDistances / sum(inverseDistances))[valuesByHandIndicesSort]))\n",
    "    \n",
    "    test_eq(values, np.sort(values))\n",
    "    test_eq(np.sort(valuesByHand), values)\n",
    "\n",
    "#---\n",
    "\n",
    "weightsDistrSummarized = LS_KDEx.getWeights(X = XTest, weightsByDistance = True, outputType = 'cumulativeDistributionSummarized')\n",
    "\n",
    "test_eq(len(weightsDistrSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsDistrSummarized)):\n",
    "    neighbors = indicesPerPred[i]\n",
    "    distances = predDistances[i]\n",
    "    cumProb = weightsDistrSummarized[i][0]\n",
    "    values = weightsDistrSummarized[i][1]\n",
    "    \n",
    "    assert all(cumProb > 0)\n",
    "    assert isclose(cumProb.max(), 1)\n",
    "    test_eq(cumProb, np.sort(cumProb))\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n",
    "    \n",
    "    else:\n",
    "        inverseDistances = 1 / distances\n",
    "        valuesByHand = yTrainMod[neighbors]\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(values, np.sort(values))\n",
    "    test_eq(set(valuesByHand), set(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94fcf0a-e903-4d0a-a0e5-b733869df259",
   "metadata": {},
   "source": [
    "#### ScalingList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8058fc83-14d3-4967-8aa5-9d42b2a5058b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Testing scalingList \n",
    "\n",
    "LS_KDEx = LevelSetKDEx(estimator = LGBM, binSize = 100)\n",
    "LS_KDEx.fit(XTrain, yTrain)\n",
    "\n",
    "#---\n",
    "\n",
    "indicesPerBin = LS_KDEx.indicesPerBin\n",
    "lowerBoundPerBin = LS_KDEx.lowerBoundPerBin\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "binPerPred = np.searchsorted(a = lowerBoundPerBin, v = yPredTest, side = 'right') - 1\n",
    "indicesPerPred = [indicesPerBin[binIndex] for binIndex in binPerPred]\n",
    "\n",
    "#---\n",
    "\n",
    "weightsSummarized = LS_KDEx.getWeights(X = XTest, outputType = 'summarized', scalingList = scalingList)\n",
    "\n",
    "test_eq(len(weightsSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsSummarized)):\n",
    "    weights = weightsSummarized[i][0]\n",
    "    values = weightsSummarized[i][1]\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(set(yTrain[indicesPerPred[i]] * scalingList[i]), set(values))\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsCumDistr = LS_KDEx.getWeights(X = XTest, outputType = 'cumulativeDistribution', scalingList = scalingList)\n",
    "\n",
    "test_eq(len(weightsCumDistr), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsCumDistr)):\n",
    "    cumProb = weightsCumDistr[i][0]\n",
    "    values = weightsCumDistr[i][1]\n",
    "    \n",
    "    test_eq(values, np.sort(yTrain[indicesPerPred[i]]) * scalingList[i])\n",
    "\n",
    "#---\n",
    "\n",
    "weightsDistrSummarized = LS_KDEx.getWeights(X = XTest, outputType = 'cumulativeDistributionSummarized', scalingList = scalingList)\n",
    "\n",
    "test_eq(len(weightsDistrSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsDistrSummarized)):\n",
    "    cumProb = weightsDistrSummarized[i][0]\n",
    "    values = weightsDistrSummarized[i][1]\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(set(values), set(np.sort(yTrain[indicesPerPred[i]]) * scalingList[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e687f6-18a6-4522-8585-3242b14403fa",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cf08ad9-5bce-4fe7-af0f-586a7bb849e9",
   "metadata": {},
   "source": [
    "#### predictQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d086697-3a40-4127-83a4-3e360f4c311c",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Testing predictQ-method\n",
    "LS_KDEx = LevelSetKDEx(estimator = LGBM, binSize = 100)\n",
    "LS_KDEx.fit(XTrain, yTrain)\n",
    "\n",
    "#---\n",
    "\n",
    "indicesPerBin = LS_KDEx.indicesPerBin\n",
    "lowerBoundPerBin = LS_KDEx.lowerBoundPerBin\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "binPerPred = np.searchsorted(a = lowerBoundPerBin, v = yPredTest, side = 'right') - 1\n",
    "indicesPerPred = [indicesPerBin[binIndex] for binIndex in binPerPred]\n",
    "yTrainPerPred = [yTrain[indices] for indices in indicesPerPred]\n",
    "\n",
    "#---\n",
    "\n",
    "probs = [0.001, 0.5, 0.999]\n",
    "quantileDict = LS_KDEx.predictQ(X = XTest, probs = probs, outputAsDf = False, scalingList = None)\n",
    "quantileDf = LS_KDEx.predictQ(X = XTest, probs = probs, outputAsDf = True, scalingList = None)\n",
    "\n",
    "test_eq(pd.DataFrame(quantileDict), quantileDf)\n",
    "test_eq(list(quantileDict.keys()), probs)\n",
    "\n",
    "for i in range(quantileDf.shape[0]):\n",
    "    assert((np.diff(quantileDf.iloc[i,:]) >= 0).all())\n",
    "    test_eq(yTrainPerPred[i].min(), quantileDf.loc[i, 0.001])\n",
    "    test_eq(yTrainPerPred[i].max(), quantileDf.loc[i, 0.999])\n",
    "    test_eq(np.quantile(a = yTrainPerPred[i], q = 0.5, method = 'inverted_cdf'), quantileDf.loc[i, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1d7eb3-95c6-42aa-9be7-8857c7cd55b2",
   "metadata": {},
   "source": [
    "## LS_KDEx_kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ef55b2-00e4-45ff-b772-e1e05ad38db3",
   "metadata": {},
   "source": [
    "### Standard Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ef3022-b673-49bc-a3b5-522a6ccaf850",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 100)\n",
    "LS_KDEx_kNN.fit(XTrain, yTrain)\n",
    "\n",
    "# Check if nothing weird happened to y and yPred\n",
    "test_eq(LS_KDEx_kNN.y, yTrain)\n",
    "test_eq(LS_KDEx_kNN.yPred, LGBM.predict(XTrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9de8b1-8199-49f5-81e2-1f682b10bd77",
   "metadata": {},
   "source": [
    "### getWeights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a0317-8042-4bb0-8386-2654806f053f",
   "metadata": {},
   "source": [
    "#### Standard Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a599bb7-377e-41b7-80cb-c0331ee6a59b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Weights-Output Test\n",
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 100)\n",
    "LS_KDEx_kNN.fit(XTrain, yTrain)\n",
    "\n",
    "nn = LS_KDEx_kNN.nearestNeighborsOnPreds\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "yPredTest_reshaped = np.reshape(yPredTest, newshape = (len(yPredTest), 1))\n",
    "\n",
    "weightsList = LS_KDEx_kNN.getWeights(X = XTest, \n",
    "                                     weightsByDistance = False, \n",
    "                                     outputType = 'onlyPositiveWeights')\n",
    "\n",
    "binSizesReal = [len(weightsList[i][1]) for i in range(XTest.shape[0])]\n",
    "distancesDf, neighborsMatrix = nn.kneighbors(X = yPredTest_reshaped, n_neighbors = max(binSizesReal))\n",
    "\n",
    "# Check if all bins contain at least 100 observations\n",
    "assert np.all((np.array(binSizesReal) >= 100))\n",
    "\n",
    "#---\n",
    "\n",
    "weightsAll = LS_KDEx_kNN.getWeights(X = XTest, weightsByDistance = False, outputType = 'all')\n",
    "\n",
    "test_eq(len(weightsAll), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsAll)):\n",
    "    weights = weightsAll[i]\n",
    "    \n",
    "    assert all(weights >= 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    assert np.allclose(weights[weights > 0], 1 / binSizesReal[i])\n",
    "    \n",
    "    test_eq(set(neighborsMatrix[i, 0:binSizesReal[i]]), set(np.where(weights > 0)[0]))\n",
    "\n",
    "#---\n",
    "\n",
    "weightsOnlyPos = LS_KDEx_kNN.getWeights(X = XTest, weightsByDistance = False, outputType = 'onlyPositiveWeights')\n",
    "\n",
    "test_eq(len(weightsOnlyPos), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsOnlyPos)):\n",
    "    weights = weightsOnlyPos[i][0]\n",
    "    indices = weightsOnlyPos[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    assert np.allclose(weights, 1 / binSizesReal[i])\n",
    "    \n",
    "    test_eq(set(neighborsMatrix[i, 0:binSizesReal[i]]), set(indices))\n",
    "    \n",
    "    if len(indices) > 100:\n",
    "        assert np.allclose(np.diff(distancesDf[i, 99:binSizesReal[i]]), 0)\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsSummarized = LS_KDEx_kNN.getWeights(X = XTest, weightsByDistance = False, outputType = 'summarized')\n",
    "\n",
    "test_eq(len(weightsSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsSummarized)):\n",
    "    weights = weightsSummarized[i][0]\n",
    "    values = weightsSummarized[i][1]\n",
    "    valuesByHand = yTrain[neighborsMatrix[i, 0:binSizesReal[i]]]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    assert np.all(weights >= 1 / binSizesReal[i])\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(set(valuesByHand), set(values))\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsCumDistr = LS_KDEx_kNN.getWeights(X = XTest, weightsByDistance = False, outputType = 'cumulativeDistribution')\n",
    "\n",
    "test_eq(len(weightsCumDistr), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsCumDistr)):\n",
    "    cumProb = weightsCumDistr[i][0]\n",
    "    values = weightsCumDistr[i][1]\n",
    "    valuesByHand = yTrain[neighborsMatrix[i, 0:binSizesReal[i]]]\n",
    "    \n",
    "    assert all(cumProb > 0)\n",
    "    assert isclose(cumProb.max(), 1)\n",
    "    test_eq(cumProb, np.sort(cumProb))\n",
    "    assert np.allclose(np.diff(cumProb), np.diff(cumProb)[0])\n",
    "    \n",
    "    test_eq(values, np.sort(values))\n",
    "    test_eq(np.sort(valuesByHand), values)\n",
    "\n",
    "#---\n",
    "\n",
    "weightsDistrSummarized = LS_KDEx_kNN.getWeights(X = XTest, weightsByDistance = False, outputType = 'cumulativeDistributionSummarized')\n",
    "\n",
    "test_eq(len(weightsDistrSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsDistrSummarized)):\n",
    "    cumProb = weightsDistrSummarized[i][0]\n",
    "    values = weightsDistrSummarized[i][1]\n",
    "    valuesByHand = yTrain[neighborsMatrix[i, 0:binSizesReal[i]]]\n",
    "    \n",
    "    assert all(cumProb > 0)\n",
    "    assert isclose(cumProb.max(), 1)\n",
    "    test_eq(cumProb, np.sort(cumProb))\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(values, np.sort(values))\n",
    "    test_eq(set(valuesByHand), set(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b1924f-7ec9-4915-bd66-04b443020e1d",
   "metadata": {},
   "source": [
    "#### Distance Based Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f8c0ec-e5eb-40c5-ac16-6e7d87e963e3",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Weights-Output Test\n",
    "\n",
    "# Modifying XTrain to enforce test-predictions being identical to train predictions\n",
    "XTrainMod = np.concatenate([XTest[0:2, :], XTrain], axis = 0)\n",
    "yTrainMod = np.concatenate([yTest[0:2], yTrain], axis = 0)\n",
    "\n",
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 100)\n",
    "LS_KDEx_kNN.fit(XTrainMod, yTrainMod)\n",
    "\n",
    "#---\n",
    "\n",
    "nn = LS_KDEx_kNN.nearestNeighborsOnPreds\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "yPredTest_reshaped = np.reshape(yPredTest, newshape = (len(yPredTest), 1))\n",
    "\n",
    "weightsList = LS_KDEx_kNN.getWeights(X = XTest, \n",
    "                                     weightsByDistance = True, \n",
    "                                     outputType = 'onlyPositiveWeights')\n",
    "\n",
    "#---\n",
    "\n",
    "binSizesReal = [len(weightsList[i][1]) for i in range(XTest.shape[0])]\n",
    "distancesDf, neighborsMatrix = nn.kneighbors(X = yPredTest_reshaped, n_neighbors = max(binSizesReal))\n",
    "\n",
    "# Check if all bins either contain at least 100 observations or if not all weights have to equal\n",
    "for i in range(len(binSizesReal)):\n",
    "    if binSizesReal[i] < 100:\n",
    "        assert np.allclose(weightsList[i][0], 1 / len(weightsList[i][0]))\n",
    "        \n",
    "# Because of our above modification of XTrain and yTrain, for the first and second test observation \n",
    "# the special case applies where the test prediction is identical to at least 1 train prediction.\n",
    "assert np.allclose(weightsList[0][0], 1 / len(weightsList[0][0]))\n",
    "assert np.allclose(weightsList[1][0], 1 / len(weightsList[0][0]))\n",
    "\n",
    "assert 0 in weightsList[0][1]\n",
    "assert 1 in weightsList[1][1]\n",
    "\n",
    "#---\n",
    "\n",
    "weightsAll = LS_KDEx_kNN.getWeights(X = XTest, weightsByDistance = True, outputType = 'all')\n",
    "\n",
    "test_eq(len(weightsAll), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsAll)):\n",
    "    neighbors = neighborsMatrix[i, 0:binSizesReal[i]]\n",
    "    distances = distancesDf[i, 0:binSizesReal[i]]\n",
    "    weights = weightsAll[i]\n",
    "    \n",
    "    assert all(weights >= 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        assert np.allclose(weights[neighborsPredDistanceZero], 1 / sum(predDistanceCloseZero))\n",
    "        test_eq(np.sort(neighborsPredDistanceZero), np.sort(np.where(weights > 0)[0]))\n",
    "        \n",
    "    else:\n",
    "        inverseDistances = 1 / distances\n",
    "        np.allclose(np.sort(weights[neighbors]), np.sort(inverseDistances / sum(inverseDistances)))\n",
    "        test_eq(np.sort(neighbors), np.sort(np.where(weights > 0)[0]))\n",
    "\n",
    "#---\n",
    "\n",
    "weightsOnlyPos = LS_KDEx_kNN.getWeights(X = XTest, weightsByDistance = True, outputType = 'onlyPositiveWeights')\n",
    "\n",
    "test_eq(len(weightsOnlyPos), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsOnlyPos)):\n",
    "    neighbors = neighborsMatrix[i, 0:binSizesReal[i]]\n",
    "    distances = distancesDf[i, 0:binSizesReal[i]]\n",
    "    weights = weightsOnlyPos[i][0]\n",
    "    indices = weightsOnlyPos[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        assert np.allclose(weights, 1 / sum(predDistanceCloseZero))\n",
    "        test_eq(np.sort(neighborsPredDistanceZero), np.sort(indices))\n",
    "            \n",
    "    else:\n",
    "        inverseDistances = 1 / distances\n",
    "        assert np.allclose(weights, inverseDistances / sum(inverseDistances))\n",
    "        test_eq(np.sort(neighbors), np.sort(indices))\n",
    "    \n",
    "    if len(indices) > 100:\n",
    "        assert np.allclose(np.diff(distancesDf[i, 99:binSizesReal[i]]), 0)\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsSummarized = LS_KDEx_kNN.getWeights(X = XTest, weightsByDistance = True, outputType = 'summarized')\n",
    "\n",
    "test_eq(len(weightsSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsSummarized)):\n",
    "    neighbors = neighborsMatrix[i, 0:binSizesReal[i]]\n",
    "    distances = distancesDf[i, 0:binSizesReal[i]]\n",
    "    weights = weightsSummarized[i][0]\n",
    "    values = weightsSummarized[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n",
    "            \n",
    "    else:\n",
    "        valuesByHand = yTrainMod[neighborsMatrix[i, 0:binSizesReal[i]]]\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(set(valuesByHand), set(values))\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsCumDistr = LS_KDEx_kNN.getWeights(X = XTest, weightsByDistance = True, outputType = 'cumulativeDistribution')\n",
    "\n",
    "test_eq(len(weightsCumDistr), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsCumDistr)):\n",
    "    neighbors = neighborsMatrix[i, 0:binSizesReal[i]]\n",
    "    distances = distancesDf[i, 0:binSizesReal[i]]\n",
    "    cumProb = weightsCumDistr[i][0]\n",
    "    values = weightsCumDistr[i][1]\n",
    "    \n",
    "    assert all(cumProb > 0)\n",
    "    assert isclose(cumProb.max(), 1)\n",
    "    test_eq(cumProb, np.sort(cumProb))\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n",
    "        nCloseZero = sum(predDistanceCloseZero)\n",
    "        assert np.allclose(cumProb, np.cumsum(np.repeat(1 / nCloseZero, nCloseZero)))\n",
    "        \n",
    "    else:\n",
    "        # The following test works if we use 'valuesByHand = yTrainMod[weightsOnlyPos[i][1]' to grab the yTrain values\n",
    "        # because the getWeights-function does nothing else. If we grab them differently here (e.g. via neighborsMatrix),\n",
    "        # the sorting can become different for identical yTrain values which will change the cumulated probabilities\n",
    "        # for exactly those indices (and only these). This has no practical implications for the usage of the computed\n",
    "        # cumulated distribution function, but it has for the exact value testing we are doing here.\n",
    "        inverseDistances = 1 / distances\n",
    "        valuesByHand = yTrainMod[weightsOnlyPos[i][1]]\n",
    "        valuesByHandIndicesSort = np.argsort(valuesByHand)\n",
    "        assert np.allclose(cumProb, np.cumsum((inverseDistances / sum(inverseDistances))[valuesByHandIndicesSort]))\n",
    "    \n",
    "    test_eq(values, np.sort(values))\n",
    "    test_eq(np.sort(valuesByHand), values)\n",
    "\n",
    "#---\n",
    "\n",
    "weightsDistrSummarized = LS_KDEx_kNN.getWeights(X = XTest, weightsByDistance = True, outputType = 'cumulativeDistributionSummarized')\n",
    "\n",
    "test_eq(len(weightsDistrSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsDistrSummarized)):\n",
    "    neighbors = neighborsMatrix[i, 0:binSizesReal[i]]\n",
    "    distances = distancesDf[i, 0:binSizesReal[i]]\n",
    "    cumProb = weightsDistrSummarized[i][0]\n",
    "    values = weightsDistrSummarized[i][1]\n",
    "    \n",
    "    \n",
    "    assert all(cumProb > 0)\n",
    "    assert isclose(cumProb.max(), 1)\n",
    "    test_eq(cumProb, np.sort(cumProb))\n",
    "    \n",
    "    predDistanceCloseZero = np.isclose(distances, 0)\n",
    "    \n",
    "    if np.any(predDistanceCloseZero):\n",
    "        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n",
    "        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n",
    "    \n",
    "    else:\n",
    "        inverseDistances = 1 / distances\n",
    "        valuesByHand = yTrainMod[neighborsMatrix[i, 0:binSizesReal[i]]]\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(values, np.sort(values))\n",
    "    test_eq(set(valuesByHand), set(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c669976c-c64c-4776-8e7d-912eb4352eee",
   "metadata": {},
   "source": [
    "#### Artificially Big Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb16f73-c72f-4344-8825-7f528b92b881",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Enforcing bins with size bigger than binSize\n",
    "binSize = 10\n",
    "\n",
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 10)\n",
    "\n",
    "# Done to ensure that bins with binSize > 100 happen\n",
    "XTrainDuplicated = np.concatenate([XTrain] * (binSize + 1), axis = 0)\n",
    "yTrainDuplicated = np.concatenate([yTrain] * (binSize + 1), axis = 0)\n",
    "\n",
    "LS_KDEx_kNN.fit(XTrainDuplicated, yTrainDuplicated)\n",
    "\n",
    "#---\n",
    "\n",
    "nn = LS_KDEx_kNN.nearestNeighborsOnPreds\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "yPredTest_reshaped = np.reshape(yPredTest, newshape = (len(yPredTest), 1))\n",
    "\n",
    "distancesDf, neighborsMatrix = nn.kneighbors(X = yPredTest_reshaped, n_neighbors = binSize + 1)\n",
    "\n",
    "#---\n",
    "\n",
    "weightsOnlyPos = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'onlyPositiveWeights')\n",
    "\n",
    "test_eq(len(weightsOnlyPos), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsOnlyPos)):\n",
    "    weights = weightsOnlyPos[i][0]\n",
    "    indices = weightsOnlyPos[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    assert set(neighborsMatrix[i, 0:binSize]) <= set(indices)\n",
    "    \n",
    "    if len(indices) > 100:\n",
    "        test_eq(distancesDf[i, binSize-1], distancesDf[i, binSize])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e3303e-760d-46f5-8f4f-661a6da81fd9",
   "metadata": {},
   "source": [
    "#### Bins with only 1 Unique Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c9e4d9-07cc-4fb4-9212-6dae36c4e1b5",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Enforcing bins with only one unique value\n",
    "binSize = 10\n",
    "\n",
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 10)\n",
    "\n",
    "# Done to ensure that bins with binSize > 100 happen\n",
    "XTrainDuplicated = np.concatenate([XTrain] * binSize, axis = 0)\n",
    "yTrainDuplicated = np.concatenate([yTrain] * binSize, axis = 0)\n",
    "\n",
    "LS_KDEx_kNN.fit(XTrainDuplicated, yTrainDuplicated)\n",
    "\n",
    "#---\n",
    "\n",
    "weightsOnlyPos = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'summarized')\n",
    "\n",
    "test_eq(len(weightsOnlyPos), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsOnlyPos)):\n",
    "    weights = weightsOnlyPos[i][0]\n",
    "    values = weightsOnlyPos[i][1]\n",
    "    \n",
    "    assert all(weights > 0)\n",
    "    assert isclose(weights.sum(), 1)\n",
    "    \n",
    "    test_eq(len(values), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a450e8de-2bb7-4253-b411-083b26ea0631",
   "metadata": {},
   "source": [
    "#### ScalingList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ccda98-430f-4f72-a38e-f9ba090ab1b7",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Testing scalingList \n",
    "binSize = 20\n",
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = binSize)\n",
    "\n",
    "#---\n",
    "\n",
    "LS_KDEx_kNN.fit(XTrain, yTrain)\n",
    "nn = LS_KDEx_kNN.nearestNeighborsOnPreds\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "yPredTest_reshaped = np.reshape(yPredTest, newshape = (len(yPredTest), 1))\n",
    "\n",
    "distancesDf, neighborsMatrix = nn.kneighbors(X = yPredTest_reshaped, n_neighbors = binSize)\n",
    "\n",
    "#---\n",
    "\n",
    "weightsSummarized = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'summarized', scalingList = scalingList)\n",
    "\n",
    "test_eq(len(weightsSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsSummarized)):\n",
    "    weights = weightsSummarized[i][0]\n",
    "    values = weightsSummarized[i][1]\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    assert set(yTrain[neighborsMatrix[i, :]] * scalingList[i]) <= set(values)\n",
    "    \n",
    "#---\n",
    "\n",
    "weightsCumDistr = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'cumulativeDistribution', scalingList = scalingList)\n",
    "\n",
    "test_eq(len(weightsCumDistr), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsCumDistr)):\n",
    "    cumProb = weightsCumDistr[i][0]\n",
    "    values = weightsCumDistr[i][1]\n",
    "    \n",
    "    test_eq(values, np.sort(values))\n",
    "    assert set(yTrain[neighborsMatrix[i, :]] * scalingList[i]) <= set(values)\n",
    "\n",
    "#---\n",
    "\n",
    "weightsDistrSummarized = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'cumulativeDistributionSummarized', scalingList = scalingList)\n",
    "\n",
    "test_eq(len(weightsDistrSummarized), XTest.shape[0])\n",
    "\n",
    "for i in range(len(weightsDistrSummarized)):\n",
    "    cumProb = weightsDistrSummarized[i][0]\n",
    "    values = weightsDistrSummarized[i][1]\n",
    "    \n",
    "    test_eq(len(values), len(np.unique(values)))\n",
    "    test_eq(values, np.sort(values))\n",
    "    assert set(yTrain[neighborsMatrix[i, :]] * scalingList[i]) <= set(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55172450-e90f-43ef-bf41-29bc6fff14ac",
   "metadata": {},
   "source": [
    "### predictQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403f0b52-c2ec-47eb-ba70-99b75e20be7e",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Testing predictQ-method\n",
    "binSize = 15\n",
    "\n",
    "LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = binSize)\n",
    "\n",
    "LS_KDEx_kNN.fit(XTrain, yTrain)\n",
    "nn = LS_KDEx_kNN.nearestNeighborsOnPreds\n",
    "yPredTest = LGBM.predict(XTest)\n",
    "yPredTest_reshaped = np.reshape(yPredTest, newshape = (len(yPredTest), 1))\n",
    "\n",
    "weightsList = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'onlyPositiveWeights')\n",
    "binSizesReal = [len(weightsList[i][1]) for i in range(XTest.shape[0])]\n",
    "distancesDf, neighborsMatrix = nn.kneighbors(X = yPredTest_reshaped, n_neighbors = max(binSizesReal))\n",
    "\n",
    "#---\n",
    "\n",
    "probs = [0.001, 0.5, 0.999]\n",
    "quantileDict = LS_KDEx_kNN.predictQ(X = XTest, probs = probs, outputAsDf = False, scalingList = None)\n",
    "quantileDf = LS_KDEx_kNN.predictQ(X = XTest, probs = probs, outputAsDf = True, scalingList = None)\n",
    "\n",
    "test_eq(pd.DataFrame(quantileDict), quantileDf)\n",
    "test_eq(list(quantileDict.keys()), probs)\n",
    "\n",
    "for i in range(quantileDf.shape[0]):\n",
    "    \n",
    "    assert((np.diff(quantileDf.iloc[i,:]) >= 0).all())\n",
    "    \n",
    "    binSizeReal = binSizesReal[i]\n",
    "    valuesByHand = yTrain[neighborsMatrix[i, 0:binSizeReal]]\n",
    "    \n",
    "    test_eq(valuesByHand.min(), quantileDf.loc[i, 0.001])\n",
    "    test_eq(valuesByHand.max(), quantileDf.loc[i, 0.999])\n",
    "    test_eq(np.quantile(a = valuesByHand, q = 0.5, method = 'inverted_cdf'), quantileDf.loc[i, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e7b9c9-0575-42aa-8fa8-08134cba1f18",
   "metadata": {},
   "source": [
    "## Generate Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568736df-bd7c-456a-97c1-47d5a80474a4",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Testing various artificial inputs of 'generateBins'\n",
    "\n",
    "yPred = np.arange(100)\n",
    "indicesPerBin, lowerBoundPerBin = generateBins(binSize = 10, yPred = yPred)\n",
    "\n",
    "test_eq(list(indicesPerBin.keys()), [i for i in range(10)])\n",
    "\n",
    "indicesPerBinTest = {0: np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
    "                     1: np.array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]),\n",
    "                     2: np.array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
    "                     3: np.array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39]),\n",
    "                     4: np.array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n",
    "                     5: np.array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59]),\n",
    "                     6: np.array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69]),\n",
    "                     7: np.array([70, 71, 72, 73, 74, 75, 76, 77, 78, 79]),\n",
    "                     8: np.array([80, 81, 82, 83, 84, 85, 86, 87, 88, 89]),\n",
    "                     9: np.array([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])}\n",
    "\n",
    "indicesTracker = list()\n",
    "for i in range(len(indicesPerBin)):\n",
    "    test_eq(set(indicesPerBin[i]), set(indicesPerBinTest[i]))\n",
    "    test_eq(len(indicesPerBin[i]), len(np.unique(indicesPerBin[i])))\n",
    "    \n",
    "    indicesTracker.extend(indicesPerBin[i].tolist())\n",
    "\n",
    "test_eq(len(indicesTracker), len(np.unique(indicesTracker)))\n",
    "test_eq(np.sort(indicesTracker), np.arange(len(yPred)))\n",
    "\n",
    "lowerBoundPerBinTest = [np.NINF, 9.5, 19.5, 29.5, 39.5, 49.5, 59.5, 69.5, 79.5, 89.5]\n",
    "test_eq(list(lowerBoundPerBin), lowerBoundPerBinTest)\n",
    "test_eq(list(lowerBoundPerBin.index), [i for i in range(10)])\n",
    "\n",
    "#---\n",
    "\n",
    "yPred = np.append(np.arange(100), np.arange(100))\n",
    "indicesPerBin, lowerBoundPerBin = generateBins(binSize = 10, yPred = yPred)\n",
    "\n",
    "test_eq(list(indicesPerBin.keys()), [i for i in range(20)])\n",
    "\n",
    "indicesPerBinTest = {0: np.array([   0, 100,   1, 101,   2, 102,   3, 103,   4, 104]),\n",
    "                     1: np.array([   5, 105,   6, 106,   7, 107,   8, 108,   9, 109]),\n",
    "                     2: np.array([  10, 110,  11, 111,  12, 112,  13, 113,  14, 114]),\n",
    "                     3: np.array([  15, 115,  16, 116,  17, 117,  18, 118,  19, 119]),\n",
    "                     4: np.array([  20, 120,  21, 121,  22, 122,  23, 123,  24, 124]),\n",
    "                     5: np.array([  25, 125,  26, 126,  27, 127,  28, 128,  29, 129]),\n",
    "                     6: np.array([  30, 130,  31, 131,  32, 132,  33, 133,  34, 134]),\n",
    "                     7: np.array([  35, 135,  36, 136,  37, 137,  38, 138,  39, 139]),\n",
    "                     8: np.array([  40, 140,  41, 141,  42, 142,  43, 143,  44, 144]),\n",
    "                     9: np.array([  45, 145,  46, 146,  47, 147,  48, 148,  49, 149]),\n",
    "                     10: np.array([ 50, 150,  51, 151,  52, 152,  53, 153,  54, 154]),\n",
    "                     11: np.array([ 55, 155,  56, 156,  57, 157,  58, 158,  59, 159]),\n",
    "                     12: np.array([ 60, 160,  61, 161,  62, 162,  63, 163,  64, 164]),\n",
    "                     13: np.array([ 65, 165,  66, 166,  67, 167,  68, 168,  69, 169]),\n",
    "                     14: np.array([ 70, 170,  71, 171,  72, 172,  73, 173,  74, 174]),\n",
    "                     15: np.array([ 75, 175,  76, 176,  77, 177,  78, 178,  79, 179]),\n",
    "                     16: np.array([ 80, 180,  81, 181,  82, 182,  83, 183,  84, 184]),\n",
    "                     17: np.array([ 85, 185,  86, 186,  87, 187,  88, 188,  89, 189]),\n",
    "                     18: np.array([ 90, 190,  91, 191,  92, 192,  93, 193,  94, 194]),\n",
    "                     19: np.array([ 95, 195,  96, 196,  97, 197,  98, 198,  99, 199])}\n",
    "\n",
    "indicesTracker = list()\n",
    "for i in range(len(indicesPerBin)):\n",
    "    test_eq(set(indicesPerBin[i]), set(indicesPerBinTest[i]))\n",
    "    test_eq(len(indicesPerBin[i]), len(np.unique(indicesPerBin[i])))\n",
    "    \n",
    "    indicesTracker.extend(indicesPerBin[i].tolist())\n",
    "\n",
    "test_eq(len(indicesTracker), len(np.unique(indicesTracker)))\n",
    "test_eq(np.sort(indicesTracker), np.arange(len(yPred)))\n",
    "    \n",
    "lowerBoundPerBinTest = [np.NINF] + list(np.arange(4.5, 99.5, 5))\n",
    "test_eq(list(lowerBoundPerBin), lowerBoundPerBinTest)\n",
    "test_eq(list(lowerBoundPerBin.index), [i for i in range(20)])\n",
    "\n",
    "#---\n",
    "\n",
    "# Check if creation of last bin works correctly\n",
    "yPred = np.append(np.arange(10), np.arange(10))\n",
    "indicesPerBin, lowerBoundPerBin = generateBins(binSize = 5, yPred = yPred)\n",
    "\n",
    "test_eq(list(indicesPerBin.keys()), [i for i in range(3)])\n",
    "\n",
    "indicesPerBinTest = {0: np.array([ 0, 10,  1, 11,  2, 12]),\n",
    "                     1: np.array([ 3, 13,  4, 14,  5, 15]),\n",
    "                     2: np.array([ 6, 16,  7, 17,  8, 18,  9, 19])}\n",
    "\n",
    "indicesTracker = list()\n",
    "for i in range(len(indicesPerBin)):\n",
    "    test_eq(set(indicesPerBin[i]), set(indicesPerBinTest[i]))\n",
    "    test_eq(len(indicesPerBin[i]), len(np.unique(indicesPerBin[i])))\n",
    "    \n",
    "    indicesTracker.extend(indicesPerBin[i].tolist())\n",
    "\n",
    "test_eq(len(indicesTracker), len(np.unique(indicesTracker)))\n",
    "test_eq(np.sort(indicesTracker), np.arange(len(yPred)))\n",
    "    \n",
    "lowerBoundPerBinTest = [np.NINF, 2.5, 5.5]\n",
    "test_eq(list(lowerBoundPerBin), lowerBoundPerBinTest)\n",
    "test_eq(list(lowerBoundPerBin.index), [i for i in range(3)])\n",
    "\n",
    "#---\n",
    "\n",
    "# yPred.unique() == 1\n",
    "yPred = np.repeat(1, 100)\n",
    "indicesPerBin, lowerBoundPerBin = generateBins(binSize = 5, yPred = yPred)\n",
    "\n",
    "test_eq(list(indicesPerBin.keys()), [0])\n",
    "\n",
    "indicesPerBinTest = {0: np.arange(0, 100, 1)}\n",
    "\n",
    "indicesTracker = list()\n",
    "for i in range(len(indicesPerBin)):\n",
    "    test_eq(set(indicesPerBin[i]), set(indicesPerBinTest[i]))\n",
    "    test_eq(len(indicesPerBin[i]), len(np.unique(indicesPerBin[i])))\n",
    "    \n",
    "    indicesTracker.extend(indicesPerBin[i].tolist())\n",
    "\n",
    "test_eq(len(indicesTracker), len(np.unique(indicesTracker)))\n",
    "test_eq(np.sort(indicesTracker), np.arange(len(yPred)))\n",
    "    \n",
    "lowerBoundPerBinTest = [np.NINF]\n",
    "test_eq(list(lowerBoundPerBin), lowerBoundPerBinTest)\n",
    "test_eq(list(lowerBoundPerBin.index), [i for i in range(1)])\n",
    "\n",
    "#---\n",
    "\n",
    "# binSize > len(yPred)\n",
    "yPred = np.arange(10)\n",
    "indicesPerBin, lowerBoundPerBin = generateBins(binSize = 100, yPred = yPred)\n",
    "\n",
    "test_eq(list(indicesPerBin.keys()), [0])\n",
    "\n",
    "indicesPerBinTest = {0: np.arange(0, 10, 1)}\n",
    "\n",
    "indicesTracker = list()\n",
    "for i in range(len(indicesPerBin)):\n",
    "    test_eq(set(indicesPerBin[i]), set(indicesPerBinTest[i]))\n",
    "    test_eq(len(indicesPerBin[i]), len(np.unique(indicesPerBin[i])))\n",
    "    \n",
    "    indicesTracker.extend(indicesPerBin[i].tolist())\n",
    "\n",
    "test_eq(len(indicesTracker), len(np.unique(indicesTracker)))\n",
    "test_eq(np.sort(indicesTracker), np.arange(len(yPred)))\n",
    "    \n",
    "lowerBoundPerBinTest = [np.NINF]\n",
    "test_eq(list(lowerBoundPerBin), lowerBoundPerBinTest)\n",
    "test_eq(list(lowerBoundPerBin.index), [i for i in range(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99819d-ec03-4147-a1c7-30db22ef2579",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# # LevelSetKDEx.getWeights() and LevelSetKDEx_kNN.getWeights()\n",
    "# for i in range(len(neighborsList)):\n",
    "#     if len(neighborsList[i]) < self.binSize:\n",
    "#         ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ba712-307c-4c2b-9496-98288c8fa992",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# # generateBins\n",
    "# indices = np.array([])\n",
    "# for k in range(len(indicesPerBin.keys())):\n",
    "#     indices = np.append(indices, indicesPerBin[k])\n",
    "\n",
    "# if len(indices) != len(yPred):\n",
    "#     ipdb.set_trace()\n",
    "\n",
    "# predCheck = np.array([pred in binPerPred.keys() for pred in yPred])\n",
    "# keyCheck = np.array([key in yPred for key in binPerPred.keys()])\n",
    "\n",
    "# if (all(predCheck) & all(keyCheck)) is False:\n",
    "#     ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0c6e34-3490-453d-8302-910815a5260c",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# # LevelSetKDEx.getWeights()\n",
    "# check = [i for i in range(len(weightsDataList)) if len(weightsDataList[i][1]) > 100]\n",
    "# check2 = [i for i in range(len(weightsDataList)) if len(weightsDataList[i][1]) > 100 and binPerPred[i] != self.lowerBoundPerBin.index.max()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HC-Scheduling",
   "language": "python",
   "name": "hc-scheduling"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
