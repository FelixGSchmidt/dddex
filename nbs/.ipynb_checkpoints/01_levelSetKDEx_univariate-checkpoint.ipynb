{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61516f21-8606-49d3-8907-c0190315ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd6b76-2644-458b-8436-da808dd134c7",
   "metadata": {},
   "source": [
    "# Level-Set Based Kernel Density Estimation\n",
    "> Defining the classes `LevelSetKDEx` and `LevelSetKDEx_kNN` which turn any point predictor into a conditional kernel density estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7668fd2-5361-43a1-ba2b-42506a2419ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp levelSetKDEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8cef21-4158-4307-b898-6bc03398a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "# from nbdev.qmd import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d95d3a6-a5e0-46de-b191-d1de0281f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from fastcore.docments import *\n",
    "from fastcore.test import *\n",
    "from fastcore.utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from collections import defaultdict, Counter, deque\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from dddex.baseClasses import BaseWeightsBasedEstimator\n",
    "from dddex.utils import restructureWeightsDataList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b8315b-c072-4e14-b477-5856b5d922fe",
   "metadata": {},
   "source": [
    "In the following we define the classes `LevelSetKDEx` and `LevelSetKDEx_kNN` where KDE is short for 'Kernel Density Estimator' and the 'x' is supposed to signal that both classes can be defined based on any arbitrary point predictor. The name 'LevelSet' stems from the fact that every approach presented in this notebook interprets the values of the point forecasts as a similarity measure between samples. The point predictor is specified by the argument `estimator` and must have a `.predict()`-method and should have been trained before hand. \n",
    "\n",
    "Both classes `LevelSetKDEx` and `LevelSetKDEx_kNN` fulfill the same task: By first running `.fit(XTrain, yTrain)` and then calling `.generateWeights(XTest)`, they both output an estimation of the conditional density of every sample specified by 'XTest'. The basic idea for both approaches is also identical: Suppose we have a single test sample at hand. At first, we compare the value of the point prediction of this sample and the values of the point predictions of the training samples computed via `estimator.predict(XTrain)` and `estimator.predict(XTest)`, respectively. Based on this comparison, we select 'binSize'-many training samples that we deem the most similar to the test sample at hand. The concrete way we select the training samples constitutes the only difference between `LevelSetKDEx` and `LevelSetKDEx_kNN`. Finally, the empirical distribution of the y-values of these training samples then acts as our estimation of the conditional distribution.\n",
    "\n",
    "Further details on how both approaches work approaches can be found below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a870226b-528e-490a-b0b7-273f277cf1da",
   "metadata": {},
   "source": [
    "## Base Level-Set Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a712302d-46fb-4c47-8c4f-bad683afc9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BaseLSx:\n",
    "    \"\"\"\n",
    "    Base class for the Level-Set based approaches. This class is not supposed to be used directly.\n",
    "    Use derived classes instead.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 estimator, # Model with a `fit` and `predict` method (implementing the scikit-learn estimator interface).\n",
    "                 binSize: int=None, # Number of training samples considered for creating weights.\n",
    "                 # Determines behaviour of method `getWeights`. If False, all weights receive the same  \n",
    "                 # value. If True, the distance of the point forecasts is taking into account.\n",
    "                 weightsByDistance: bool=False,  \n",
    "                 ):\n",
    "        \n",
    "        if not (hasattr(estimator, 'predict') and callable(estimator.predict)):\n",
    "            raise ValueError(\"'estimator' has to have a 'predict'-method!\")\n",
    "            \n",
    "        if not (isinstance(binSize, (int, np.integer)) or binSize is None):\n",
    "            raise ValueError(\"'binSize' has to be an integer!\")\n",
    "            \n",
    "        self.estimator = copy.deepcopy(estimator)\n",
    "        self.binSize = binSize\n",
    "        self.weightsByDistance = weightsByDistance      \n",
    "        \n",
    "    #---\n",
    "    \n",
    "    def pointPredict(self: BaseLSx, \n",
    "                     # Feature matrix for which point predictions are computed based\n",
    "                     # on the point forecasting model specified via `estimator`.\n",
    "                     X: np.ndarray \n",
    "                     ):\n",
    "        \n",
    "        return self.estimator.predict(X)\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    def refitPointEstimator(self: BaseLSx, \n",
    "                            X: np.ndarray, # Input feature matrix\n",
    "                            y: np.ndarray, # Target values\n",
    "                            **kwargs):\n",
    "        \n",
    "        try:\n",
    "            self.estimator.set_params(**kwargs)\n",
    "        except:\n",
    "            raise NotImplementedError(\"The 'estimator' object has no 'set_params' method, so the\"\n",
    "                                      \"provided parameters via **kwargs can't be set!\")\n",
    "        else:\n",
    "            setattr(self, 'estimator', self.estimator.fit(X = X, y = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d97ec6-90cc-4c00-bb18-39c5691d3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(BaseLSx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9dab15f-f55a-413f-a5dd-75d9112ab385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(BaseLSx.pointPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d87fafe-5a5d-419d-bd69-16c6a12eabe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(BaseLSx.refitPointEstimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794a75d0-8a2c-4482-b372-6e67bf394d86",
   "metadata": {},
   "source": [
    "## Level-Set Approach based on Bin Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8cebd8e-52d0-4a7f-af8f-75af78972824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class LevelSetKDEx(BaseWeightsBasedEstimator, BaseLSx):\n",
    "    \"\"\"\n",
    "    `LevelSetKDEx` turns any point forecasting model into an estimator of the underlying conditional density.\n",
    "    The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
    "    as a similarity measure between samples. The point forecasts of the training samples are sorted and \n",
    "    recursively assigned to a bin until the size of the current bin reaches `binSize` many samples. Then\n",
    "    a new bin is created and so on. For a new test sample we check into which bin its point prediction\n",
    "    would have fallen and interpret the training samples of that bin as the empirical distribution function\n",
    "    of this test sample.    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 estimator, # Model with a .fit and .predict-method (implementing the scikit-learn estimator interface).\n",
    "                 binSize: int=None, # Size of the bins created while running fit.\n",
    "                 # Determines behaviour of method `getWeights`. If False, all weights receive the same  \n",
    "                 # value. If True, the distance of the point forecasts is taking into account.\n",
    "                 weightsByDistance: bool=False, \n",
    "                 ):\n",
    "        \n",
    "        super(BaseEstimator, self).__init__(estimator = estimator,\n",
    "                                            binSize = binSize,\n",
    "                                            weightsByDistance = weightsByDistance)\n",
    "\n",
    "        self.yTrain = None\n",
    "        self.yPredTrain = None\n",
    "        self.indicesPerBin = None\n",
    "        self.lowerBoundPerBin = None\n",
    "        self.fitted = False\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    def fit(self: LevelSetKDEx, \n",
    "            X: np.ndarray, # Feature matrix used by `estimator` to predict `y`.\n",
    "            y: np.ndarray, # 1-dimensional target variable corresponding to the feature matrix `X`.\n",
    "            ):\n",
    "        \"\"\"\n",
    "        Fit `LevelSetKDEx` model by grouping the point predictions of the samples specified via `X`\n",
    "        according to their value. Samples are recursively sorted into bins until each bin contains\n",
    "        `binSize` many samples. For details, checkout the function `generateBins` which does the\n",
    "        heavy lifting.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Checks\n",
    "        if self.binSize is None:\n",
    "            raise ValueError(\"'binSize' must be specified to fit the LSx estimator!\")\n",
    "            \n",
    "        if self.binSize > y.shape[0]:\n",
    "            raise ValueError(\"'binSize' mustn't be bigger than the size of 'y'!\")\n",
    "        \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(\"'X' and 'y' must contain the same number of samples!\")\n",
    "        \n",
    "        # IMPORTANT: In case 'y' is given as a pandas.Series, we can potentially run into indexing \n",
    "        # problems later on.\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.ravel()\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        try:\n",
    "            yPred = self.estimator.predict(X)\n",
    "            \n",
    "        except NotFittedError:\n",
    "            try:\n",
    "                self.estimator.fit(X = X, y = y)                \n",
    "            except:\n",
    "                raise ValueError(\"Couldn't fit 'estimator' with user specified 'X' and 'y'!\")\n",
    "            else:\n",
    "                yPred = self.estimator.predict(X)\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        indicesPerBin, lowerBoundPerBin = generateBins(binSize = self.binSize,\n",
    "                                                       yPred = yPred)\n",
    "\n",
    "        self.yTrain = y\n",
    "        self.yPredTrain = yPred\n",
    "        self.indicesPerBin = indicesPerBin\n",
    "        self.lowerBoundPerBin = lowerBoundPerBin\n",
    "        self.fitted = True\n",
    "        \n",
    "    #---\n",
    "    \n",
    "    def getWeights(self, \n",
    "                   X: np.ndarray, # Feature matrix for which conditional density estimates are computed.\n",
    "                   # Specifies structure of the returned density estimates. One of: \n",
    "                   # 'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized'\n",
    "                   outputType: str='onlyPositiveWeights', \n",
    "                   # Optional. List with length X.shape[0]. Values are multiplied to the estimated \n",
    "                   # density of each sample for scaling purposes.\n",
    "                   scalingList: list=None, \n",
    "                   ) -> list: # List whose elements are the conditional density estimates for the samples specified by `X`.\n",
    "        \n",
    "        # __annotations__ = BaseWeightsBasedEstimator.getWeights.__annotations__\n",
    "        __doc__ = BaseWeightsBasedEstimator.getWeights.__doc__\n",
    "        \n",
    "        if not self.fitted:\n",
    "            raise NotFittedError(\"This LevelSetKDEx instance is not fitted yet. Call 'fit' with \"\n",
    "                                 \"appropriate arguments before trying to compute weights.\")\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        yPred = self.estimator.predict(X)\n",
    "        \n",
    "        binPerPred = np.searchsorted(a = self.lowerBoundPerBin, v = yPred, side = 'right') - 1\n",
    "        neighborsList = [self.indicesPerBin[binIndex] for binIndex in binPerPred]\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        if self.weightsByDistance:\n",
    "\n",
    "            predDistances = [np.abs(self.yPredTrain[neighborsList[i]] - yPred[i]) for i in range(len(neighborsList))]\n",
    "\n",
    "            weightsDataList = list()\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                distances = predDistances[i]\n",
    "                distancesCloseZero = np.isclose(distances, 0)\n",
    "                \n",
    "                if np.any(distancesCloseZero):\n",
    "                    indicesCloseZero = neighborsList[i][np.where(distancesCloseZero)[0]]\n",
    "                    weightsDataList.append((np.repeat(1 / len(indicesCloseZero), len(indicesCloseZero)),\n",
    "                                            indicesCloseZero))\n",
    "                    \n",
    "                else:                                 \n",
    "                    inverseDistances = 1 / distances\n",
    "\n",
    "                    weightsDataList.append((inverseDistances / inverseDistances.sum(), \n",
    "                                            np.array(neighborsList[i])))\n",
    "            \n",
    "            weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "                                                         outputType = outputType, \n",
    "                                                         y = self.yTrain,\n",
    "                                                         scalingList = scalingList,\n",
    "                                                         equalWeights = False)\n",
    "        \n",
    "        else:\n",
    "            weightsDataList = [(np.repeat(1 / len(neighbors), len(neighbors)), np.array(neighbors)) for neighbors in neighborsList]\n",
    "\n",
    "            weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "                                                         outputType = outputType, \n",
    "                                                         y = self.yTrain,\n",
    "                                                         scalingList = scalingList,\n",
    "                                                         equalWeights = True)\n",
    "        \n",
    "        return weightsDataList\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7fdb5bf-f39d-470f-b7cc-8679e733b2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L113){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx.fit\n",
       "\n",
       ">      LevelSetKDEx.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "Fit `LevelSetKDEx` model by grouping the point predictions of the samples specified via `X`\n",
       "according to their value. Samples are recursively sorted into bins until each bin contains\n",
       "`binSize` many samples. For details, checkout the function `generateBins` which does the\n",
       "heavy lifting.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | np.ndarray | Feature matrix used by `estimator` to predict `y`. |\n",
       "| y | np.ndarray | 1-dimensional target variable corresponding to the feature matrix `X`. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L113){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx.fit\n",
       "\n",
       ">      LevelSetKDEx.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "Fit `LevelSetKDEx` model by grouping the point predictions of the samples specified via `X`\n",
       "according to their value. Samples are recursively sorted into bins until each bin contains\n",
       "`binSize` many samples. For details, checkout the function `generateBins` which does the\n",
       "heavy lifting.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | np.ndarray | Feature matrix used by `estimator` to predict `y`. |\n",
       "| y | np.ndarray | 1-dimensional target variable corresponding to the feature matrix `X`. |"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LevelSetKDEx.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cca538d-96ff-48df-9e29-8573a6442a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L165){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx.getWeights\n",
       "\n",
       ">      LevelSetKDEx.getWeights (X:numpy.ndarray,\n",
       ">                               outputType:str='onlyPositiveWeights',\n",
       ">                               scalingList:list=None)\n",
       "\n",
       "Computes estimated conditional density for each sample specified by `X`. The concrete structure of each element \n",
       "of the returned list depends on the specified value of `outputType`:\n",
       "\n",
       "- **all**: An array with the same length as the number of training samples. Each entry represents the probability \n",
       "  of each training sample.\n",
       "- **onlyPositiveWeights**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the indices of the corresponding training sample. Only probalities greater than zero are returned. \n",
       "  Note: This is the most memory and computationally efficient output type.\n",
       "- **summarized**: A tuple. The first element of the tuple represents the probabilities and the second one the \n",
       "  corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
       "- **cumDistribution**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the corresponding value of `yTrain`.\n",
       "- **cumDistributionSummarized**: A tuple. The first element of the tuple represents the probabilities and \n",
       "  the second one the corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | np.ndarray |  | Feature matrix for which conditional density estimates are computed. |\n",
       "| outputType | str | onlyPositiveWeights | Specifies structure of the returned density estimates. One of: <br>'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized' |\n",
       "| scalingList | list | None | Optional. List with length X.shape[0]. Values are multiplied to the estimated <br>density of each sample for scaling purposes. |\n",
       "| **Returns** | **list** |  | **List whose elements are the conditional density estimates for the samples specified by `X`.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L165){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx.getWeights\n",
       "\n",
       ">      LevelSetKDEx.getWeights (X:numpy.ndarray,\n",
       ">                               outputType:str='onlyPositiveWeights',\n",
       ">                               scalingList:list=None)\n",
       "\n",
       "Computes estimated conditional density for each sample specified by `X`. The concrete structure of each element \n",
       "of the returned list depends on the specified value of `outputType`:\n",
       "\n",
       "- **all**: An array with the same length as the number of training samples. Each entry represents the probability \n",
       "  of each training sample.\n",
       "- **onlyPositiveWeights**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the indices of the corresponding training sample. Only probalities greater than zero are returned. \n",
       "  Note: This is the most memory and computationally efficient output type.\n",
       "- **summarized**: A tuple. The first element of the tuple represents the probabilities and the second one the \n",
       "  corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
       "- **cumDistribution**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the corresponding value of `yTrain`.\n",
       "- **cumDistributionSummarized**: A tuple. The first element of the tuple represents the probabilities and \n",
       "  the second one the corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | np.ndarray |  | Feature matrix for which conditional density estimates are computed. |\n",
       "| outputType | str | onlyPositiveWeights | Specifies structure of the returned density estimates. One of: <br>'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized' |\n",
       "| scalingList | list | None | Optional. List with length X.shape[0]. Values are multiplied to the estimated <br>density of each sample for scaling purposes. |\n",
       "| **Returns** | **list** |  | **List whose elements are the conditional density estimates for the samples specified by `X`.** |"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LevelSetKDEx.getWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661e147-5acc-4593-b3a5-e93f2d82447f",
   "metadata": {},
   "source": [
    "#### Generate Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d0d9778-557b-4618-80a8-c440a81b2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def generateBins(binSize: int, # Size of the bins of values of `yPred` being grouped together.\n",
    "                 yPred: np.ndarray, # 1-dimensional array of predicted values.\n",
    "                 ):\n",
    "    \"Used to generate the bin-structure used by `LevelSetKDEx` to compute density estimations.\"\n",
    "    \n",
    "    predIndicesSort = np.argsort(yPred)\n",
    "    yPredSorted = yPred[predIndicesSort]\n",
    "\n",
    "    currentBinSize = 0\n",
    "    binIndex = 0\n",
    "    trainIndicesLeft = len(yPred)\n",
    "    indicesPerBin = defaultdict(list)\n",
    "    lowerBoundPerBin = dict()\n",
    "    \n",
    "    for i in range(len(yPred)):\n",
    "        \n",
    "        if i == 0:\n",
    "            lowerBoundPerBin[binIndex] = np.NINF\n",
    "            \n",
    "        currentBinSize += 1\n",
    "        trainIndicesLeft -= 1\n",
    "\n",
    "        indicesPerBin[binIndex].append(predIndicesSort[i])\n",
    "        \n",
    "        if trainIndicesLeft < binSize:\n",
    "            indicesPerBin[binIndex].extend(predIndicesSort[np.arange(i+1, len(yPred), 1)])\n",
    "            break\n",
    "\n",
    "        if currentBinSize >= binSize and yPredSorted[i] < yPredSorted[i+1]:\n",
    "            lowerBoundPerBin[binIndex + 1] = (yPredSorted[i] + yPredSorted[i+1]) / 2\n",
    "            binIndex += 1\n",
    "            currentBinSize = 0\n",
    "           \n",
    "    indicesPerBin = {binIndex: np.array(indices) for binIndex, indices in indicesPerBin.items()}\n",
    "    \n",
    "    lowerBoundPerBin = pd.Series(lowerBoundPerBin)\n",
    "    lowerBoundPerBin.index.name = 'binIndex'\n",
    "    \n",
    "    return indicesPerBin, lowerBoundPerBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "450b9d07-e1af-49e1-8709-5575002f1bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L231){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### generateBins\n",
       "\n",
       ">      generateBins (binSize:int, yPred:numpy.ndarray)\n",
       "\n",
       "Used to generate the bin-structure used by `LevelSetKDEx` to compute density estimations.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| binSize | int | Size of the bins of values of `yPred` being grouped together. |\n",
       "| yPred | np.ndarray | 1-dimensional array of predicted values. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L231){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### generateBins\n",
       "\n",
       ">      generateBins (binSize:int, yPred:numpy.ndarray)\n",
       "\n",
       "Used to generate the bin-structure used by `LevelSetKDEx` to compute density estimations.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| binSize | int | Size of the bins of values of `yPred` being grouped together. |\n",
       "| yPred | np.ndarray | 1-dimensional array of predicted values. |"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(generateBins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd550e-ae6e-44fe-a91b-f0ffee0096bc",
   "metadata": {},
   "source": [
    "## Level-Set Approach based on kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e34b41f2-b012-428e-a18c-6fa6c20690ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class LevelSetKDEx_kNN(BaseWeightsBasedEstimator, BaseLSx):\n",
    "    \"\"\"\n",
    "     `LevelSetKDEx_kNN` turns any point predictor that has a .predict-method \n",
    "    into an estimator of the condititional density of the underlying distribution.\n",
    "    The basic idea of each level-set based approach is to interprete the point forecast\n",
    "    generated by the underlying point predictor as a similarity measure of samples.\n",
    "    In the case of the `LevelSetKDEx_kNN` defined here, for every new samples\n",
    "    'binSize'-many training samples are computed whose point forecast is closest\n",
    "    to the point forecast of the new sample.\n",
    "    The resulting empirical distribution of these 'nearest' training samples are \n",
    "    viewed as our estimation of the conditional distribution of each the new sample \n",
    "    at hand.\n",
    "    \n",
    "    NOTE: In contrast to the standard `LevelSetKDEx`, it is possible to apply\n",
    "    `LevelSetKDEx_kNN` to arbitrary dimensional point predictors.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 estimator, # Model with a .fit and .predict-method (implementing the scikit-learn estimator interface).\n",
    "                 binSize: int=None, # Size of the bins created while running fit.\n",
    "                 # Determines behaviour of method `getWeights`. If False, all weights receive the same  \n",
    "                 # value. If True, the distance of the point forecasts is taking into account.\n",
    "                 weightsByDistance: bool=False, \n",
    "                 ):\n",
    "        \n",
    "        super(BaseEstimator, self).__init__(estimator = estimator,\n",
    "                                            binSize = binSize,\n",
    "                                            weightsByDistance = weightsByDistance)\n",
    "        \n",
    "        self.yTrain = None\n",
    "        self.yPredTrain = None\n",
    "        self.nearestNeighborsOnPreds = None\n",
    "        self.fitted = False\n",
    "        \n",
    "    #---\n",
    "    \n",
    "    def fit(self: LevelSetKDEx, \n",
    "            X: np.ndarray, # Feature matrix used by `estimator` to predict `y`.\n",
    "            y: np.ndarray, # 1-dimensional target variable corresponding to the feature matrix `X`.\n",
    "            ):\n",
    "        \"\"\"\n",
    "        Fit `LevelSetKDEx_kNN` model by applying the nearest neighbors algorithm to the point\n",
    "        predictions of the samples specified by `X` based on `estimator`. \n",
    "        \"\"\"\n",
    "        \n",
    "        # Checks\n",
    "        if self.binSize is None:\n",
    "            raise ValueError(\"'binSize' must be specified to fit the LSx estimator!\")\n",
    "            \n",
    "        if self.binSize > y.shape[0]:\n",
    "            raise ValueError(\"'binSize' mustn't be bigger than the size of 'y'!\")\n",
    "            \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(\"'X' and 'y' must contain the same number of samples!\")\n",
    "            \n",
    "        # IMPORTANT: In case 'y' is given as a pandas.Series, we can potentially run into indexing \n",
    "        # problems later on.\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.ravel()\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        try:\n",
    "            yPred = self.estimator.predict(X)\n",
    "        except NotFittedError:\n",
    "            # warnings.warn(\"The object 'estimator' must have been fitted already!\"\n",
    "            #               \"'estimator' will be fitted with 'X' and 'y' to enable point predicting!\",\n",
    "            #               stacklevel = 2)\n",
    "            try:\n",
    "                self.estimator.fit(X = X, y = y)                \n",
    "            except:\n",
    "                raise ValueError(\"Couldn't fit 'estimator' with user specified 'X' and 'y'!\")\n",
    "            else:\n",
    "                yPred = self.estimator.predict(X)\n",
    "\n",
    "        #---\n",
    "        \n",
    "        yPred_reshaped = np.reshape(yPred, newshape = (len(yPred), 1))\n",
    "        \n",
    "        nn = NearestNeighbors(algorithm = 'kd_tree')\n",
    "        nn.fit(X = yPred_reshaped)\n",
    "\n",
    "        #---\n",
    "\n",
    "        self.yTrain = y\n",
    "        self.yPredTrain = yPred\n",
    "        self.nearestNeighborsOnPreds = nn\n",
    "        self.fitted = True\n",
    "        \n",
    "    #---\n",
    "    \n",
    "    def getWeights(self, \n",
    "                   X: np.ndarray, # Feature matrix for which conditional density estimates are computed.\n",
    "                   # Specifies structure of the returned density estimates. One of: \n",
    "                   # 'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized'\n",
    "                   outputType: str='onlyPositiveWeights', \n",
    "                   # Optional. List with length X.shape[0]. Values are multiplied to the estimated \n",
    "                   # density of each sample for scaling purposes.\n",
    "                   scalingList: list=None, \n",
    "                   ) -> list: # List whose elements are the conditional density estimates for the samples specified by `X`.\n",
    "        \n",
    "        __doc__ = BaseWeightsBasedEstimator.getWeights.__doc__\n",
    "        \n",
    "        if not self.fitted:\n",
    "            raise NotFittedError(\"This LevelSetKDEx_kNN instance is not fitted yet. Call 'fit' with \"\n",
    "                                 \"appropriate arguments before trying to compute weights.\")\n",
    "            \n",
    "        #---\n",
    "\n",
    "        nn = self.nearestNeighborsOnPreds\n",
    "\n",
    "        #---\n",
    "\n",
    "        yPred = self.estimator.predict(X)   \n",
    "        yPred_reshaped = np.reshape(yPred, newshape = (len(yPred), 1))\n",
    "\n",
    "        distancesMatrix, neighborsMatrix = nn.kneighbors(X = yPred_reshaped, \n",
    "                                                         n_neighbors = self.binSize + 1)\n",
    "\n",
    "        #---\n",
    "\n",
    "        neighborsList = list(neighborsMatrix[:, 0:self.binSize])\n",
    "        distanceCheck = np.where(distancesMatrix[:, self.binSize - 1] == distancesMatrix[:, self.binSize])\n",
    "        indicesToMod = distanceCheck[0]\n",
    "\n",
    "        for index in indicesToMod:\n",
    "            distanceExtremePoint = np.absolute(yPred[index] - self.yPredTrain[neighborsMatrix[index, self.binSize-1]])\n",
    "\n",
    "            neighborsByRadius = nn.radius_neighbors(X = yPred_reshaped[index:index + 1], \n",
    "                                                    radius = distanceExtremePoint, return_distance = False)[0]\n",
    "            neighborsList[index] = neighborsByRadius\n",
    "\n",
    "        #---\n",
    "        \n",
    "        if self.weightsByDistance:\n",
    "            binSizesReal = [len(neighbors) for neighbors in neighborsList]\n",
    "            binSizeMax = max(binSizesReal)\n",
    "            \n",
    "            distancesMatrix, neighborsMatrix = nn.kneighbors(X = yPred_reshaped, \n",
    "                                                             n_neighbors = binSizeMax)\n",
    "            \n",
    "            weightsDataList = list()\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                distances = distancesMatrix[i, 0:binSizesReal[i]]\n",
    "                distancesCloseZero = np.isclose(distances, 0)\n",
    "                \n",
    "                if np.any(distancesCloseZero):\n",
    "                    indicesCloseZero = neighborsMatrix[i, np.where(distancesCloseZero)[0]]\n",
    "                    weightsDataList.append((np.repeat(1 / len(indicesCloseZero), len(indicesCloseZero)),\n",
    "                                            indicesCloseZero))\n",
    "                    \n",
    "                else:                                 \n",
    "                    inverseDistances = 1 / distances\n",
    "\n",
    "                    weightsDataList.append((inverseDistances / inverseDistances.sum(), \n",
    "                                            np.array(neighborsList[i])))\n",
    "            \n",
    "            weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "                                                         outputType = outputType, \n",
    "                                                         y = self.yTrain,\n",
    "                                                         scalingList = scalingList,\n",
    "                                                         equalWeights = False)\n",
    "            \n",
    "        else:\n",
    "            weightsDataList = [(np.repeat(1 / len(neighbors), len(neighbors)), np.array(neighbors)) for neighbors in neighborsList]\n",
    "\n",
    "            weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "                                                         outputType = outputType, \n",
    "                                                         y = self.yTrain,\n",
    "                                                         scalingList = scalingList,\n",
    "                                                         equalWeights = True)\n",
    "\n",
    "        return weightsDataList\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb9daa50-ef7b-4858-b343-b212f07a02b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L308){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_kNN.fit\n",
       "\n",
       ">      LevelSetKDEx_kNN.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "Fit `LevelSetKDEx_kNN` model by applying the nearest neighbors algorithm to the point\n",
       "predictions of the samples specified by `X` based on `estimator`.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | np.ndarray | Feature matrix used by `estimator` to predict `y`. |\n",
       "| y | np.ndarray | 1-dimensional target variable corresponding to the feature matrix `X`. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L308){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_kNN.fit\n",
       "\n",
       ">      LevelSetKDEx_kNN.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "Fit `LevelSetKDEx_kNN` model by applying the nearest neighbors algorithm to the point\n",
       "predictions of the samples specified by `X` based on `estimator`.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | np.ndarray | Feature matrix used by `estimator` to predict `y`. |\n",
       "| y | np.ndarray | 1-dimensional target variable corresponding to the feature matrix `X`. |"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LevelSetKDEx_kNN.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c97f4603-b305-464c-a67b-45ff7be439ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L363){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_kNN.getWeights\n",
       "\n",
       ">      LevelSetKDEx_kNN.getWeights (X:numpy.ndarray,\n",
       ">                                   outputType:str='onlyPositiveWeights',\n",
       ">                                   scalingList:list=None)\n",
       "\n",
       "Computes estimated conditional density for each sample specified by `X`. The concrete structure of each element \n",
       "of the returned list depends on the specified value of `outputType`:\n",
       "\n",
       "- **all**: An array with the same length as the number of training samples. Each entry represents the probability \n",
       "  of each training sample.\n",
       "- **onlyPositiveWeights**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the indices of the corresponding training sample. Only probalities greater than zero are returned. \n",
       "  Note: This is the most memory and computationally efficient output type.\n",
       "- **summarized**: A tuple. The first element of the tuple represents the probabilities and the second one the \n",
       "  corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
       "- **cumDistribution**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the corresponding value of `yTrain`.\n",
       "- **cumDistributionSummarized**: A tuple. The first element of the tuple represents the probabilities and \n",
       "  the second one the corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | np.ndarray |  | Feature matrix for which conditional density estimates are computed. |\n",
       "| outputType | str | onlyPositiveWeights | Specifies structure of the returned density estimates. One of: <br>'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized' |\n",
       "| scalingList | list | None | Optional. List with length X.shape[0]. Values are multiplied to the estimated <br>density of each sample for scaling purposes. |\n",
       "| **Returns** | **list** |  | **List whose elements are the conditional density estimates for the samples specified by `X`.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L363){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_kNN.getWeights\n",
       "\n",
       ">      LevelSetKDEx_kNN.getWeights (X:numpy.ndarray,\n",
       ">                                   outputType:str='onlyPositiveWeights',\n",
       ">                                   scalingList:list=None)\n",
       "\n",
       "Computes estimated conditional density for each sample specified by `X`. The concrete structure of each element \n",
       "of the returned list depends on the specified value of `outputType`:\n",
       "\n",
       "- **all**: An array with the same length as the number of training samples. Each entry represents the probability \n",
       "  of each training sample.\n",
       "- **onlyPositiveWeights**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the indices of the corresponding training sample. Only probalities greater than zero are returned. \n",
       "  Note: This is the most memory and computationally efficient output type.\n",
       "- **summarized**: A tuple. The first element of the tuple represents the probabilities and the second one the \n",
       "  corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
       "- **cumDistribution**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the corresponding value of `yTrain`.\n",
       "- **cumDistributionSummarized**: A tuple. The first element of the tuple represents the probabilities and \n",
       "  the second one the corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | np.ndarray |  | Feature matrix for which conditional density estimates are computed. |\n",
       "| outputType | str | onlyPositiveWeights | Specifies structure of the returned density estimates. One of: <br>'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized' |\n",
       "| scalingList | list | None | Optional. List with length X.shape[0]. Values are multiplied to the estimated <br>density of each sample for scaling purposes. |\n",
       "| **Returns** | **list** |  | **List whose elements are the conditional density estimates for the samples specified by `X`.** |"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LevelSetKDEx_kNN.getWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10822979-f3a5-4612-bfed-c6cca4b341a6",
   "metadata": {},
   "source": [
    "## Level-Set Approach based on NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b6c8fe1-6e5d-47fd-a0bb-13376e4149e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class LevelSetKDEx_NN(BaseWeightsBasedEstimator, BaseLSx):\n",
    "    \"\"\"\n",
    "     `LevelSetKDEx_kNN` turns any point predictor that has a .predict-method \n",
    "    into an estimator of the condititional density of the underlying distribution.\n",
    "    The basic idea of each level-set based approach is to interprete the point forecast\n",
    "    generated by the underlying point predictor as a similarity measure of samples.\n",
    "    In the case of the `LevelSetKDEx_kNN` defined here, for every new samples\n",
    "    'binSize'-many training samples are computed whose point forecast is closest\n",
    "    to the point forecast of the new sample.\n",
    "    The resulting empirical distribution of these 'nearest' training samples are \n",
    "    viewed as our estimation of the conditional distribution of each the new sample \n",
    "    at hand.\n",
    "    \n",
    "    NOTE: In contrast to the standard `LevelSetKDEx`, it is possible to apply\n",
    "    `LevelSetKDEx_kNN` to arbitrary dimensional point predictors.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 estimator, # Model with a .fit and .predict-method (implementing the scikit-learn estimator interface).\n",
    "                 binSize: int=None, # Size of the bins created while running fit.\n",
    "                 # Determines behaviour of method `getWeights`. If False, all weights receive the same  \n",
    "                 # value. If True, the distance of the point forecasts is taking into account.\n",
    "                 weightsByDistance: bool=False, \n",
    "                 ):\n",
    "        \n",
    "        super(BaseEstimator, self).__init__(estimator = estimator,\n",
    "                                            binSize = binSize,\n",
    "                                            weightsByDistance = weightsByDistance)\n",
    "        \n",
    "        self.yTrain = None\n",
    "        self.yPredTrain = None\n",
    "        self.nearestNeighborsOnPreds = None\n",
    "        self.fitted = False\n",
    "        \n",
    "    #---\n",
    "    \n",
    "    def fit(self: LevelSetKDEx, \n",
    "            X: np.ndarray, # Feature matrix used by `estimator` to predict `y`.\n",
    "            y: np.ndarray, # 1-dimensional target variable corresponding to the feature matrix `X`.\n",
    "            ):\n",
    "        \"\"\"\n",
    "        Fit `LevelSetKDEx_kNN` model by applying the nearest neighbors algorithm to the point\n",
    "        predictions of the samples specified by `X` based on `estimator`. \n",
    "        \"\"\"\n",
    "        \n",
    "        # Checks\n",
    "        if self.binSize is None:\n",
    "            raise ValueError(\"'binSize' must be specified to fit the LSx estimator!\")\n",
    "            \n",
    "        if self.binSize > y.shape[0]:\n",
    "            raise ValueError(\"'binSize' mustn't be bigger than the size of 'y'!\")\n",
    "            \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(\"'X' and 'y' must contain the same number of samples!\")\n",
    "            \n",
    "        # IMPORTANT: In case 'y' is given as a pandas.Series, we can potentially run into indexing \n",
    "        # problems later on.\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.ravel()\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        try:\n",
    "            yPred = self.estimator.predict(X)\n",
    "            \n",
    "        except NotFittedError:\n",
    "            try:\n",
    "                self.estimator.fit(X = X, y = y)                \n",
    "            except:\n",
    "                raise ValueError(\"Couldn't fit 'estimator' with user specified 'X' and 'y'!\")\n",
    "            else:\n",
    "                yPred = self.estimator.predict(X)\n",
    "\n",
    "        #---\n",
    "        \n",
    "        neighborsDict, neighborsRemoved, neighborsAdded = getNeighbors(binSize = self.binSize,\n",
    "                                                                       yPred = yPred)\n",
    "\n",
    "        self.yTrain = y\n",
    "        self.yPredTrain = yPred\n",
    "        self.neighborsDictTrain = neighborsDict\n",
    "        self._neighborsRemoved = neighborsRemoved\n",
    "        self._neighborsAdded = neighborsAdded\n",
    "        self._fitted = True\n",
    "        \n",
    "    #---\n",
    "    \n",
    "    def getWeights(self, \n",
    "                   X: np.ndarray, # Feature matrix for which conditional density estimates are computed.\n",
    "                   # Specifies structure of the returned density estimates. One of: \n",
    "                   # 'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized'\n",
    "                   outputType: str='onlyPositiveWeights', \n",
    "                   # Optional. List with length X.shape[0]. Values are multiplied to the estimated \n",
    "                   # density of each sample for scaling purposes.\n",
    "                   scalingList: list=None, \n",
    "                   ) -> list: # List whose elements are the conditional density estimates for the samples specified by `X`.\n",
    "        \n",
    "        __doc__ = BaseWeightsBasedEstimator.getWeights.__doc__\n",
    "        \n",
    "        if not self._fitted:\n",
    "            raise NotFittedError(\"This LevelSetKDEx_kNN instance is not fitted yet. Call 'fit' with \"\n",
    "                                 \"appropriate arguments before trying to compute weights.\")\n",
    "            \n",
    "        #---\n",
    "        \n",
    "        yPred = self.estimator.predict(X)\n",
    "        \n",
    "        neighborsDictTest = getNeighborsTest(binSize = self.binSize,\n",
    "                                             yPred = yPred,\n",
    "                                             yPredTrain = self.yPredTrain,\n",
    "                                             neighborsDictTrain = self.neighborsDictTrain)\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        weightsDataList = getKernelValues(yPred = yPred,\n",
    "                                          yPredTrain = self.yPredTrain,\n",
    "                                          neighborsDictTest = neighborsDictTest,\n",
    "                                          neighborsDictTrain = self.neighborsDictTrain,\n",
    "                                          neighborsRemoved = self._neighborsRemoved,\n",
    "                                          neighborsAdded = self._neighborsAdded,\n",
    "                                          binSize = self.binSize,\n",
    "                                          returnWeights = True)\n",
    "        \n",
    "        weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "                                                     outputType = outputType, \n",
    "                                                     y = self.yTrain,\n",
    "                                                     scalingList = scalingList,\n",
    "                                                     equalWeights = True)\n",
    "\n",
    "        return weightsDataList\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a17558-e558-4e37-82b4-d2c5ac0c8f06",
   "metadata": {},
   "source": [
    "### Get Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a73ad7e-7e41-4934-8465-736c9f2fc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def getNeighbors(binSize: int, # Size of the bins of values of `yPred` being grouped together.\n",
    "                 yPred: np.ndarray, # 1-dimensional array of predicted values.\n",
    "                 ):\n",
    "    \"Used to generate the neighboorhoods used by `LevelSetKDEx` to compute density estimations.\"\n",
    "    \n",
    "    duplicationDict = defaultdict(list)\n",
    "    counterDict = defaultdict(int)\n",
    "    \n",
    "    for index, value in enumerate(yPred):\n",
    "        duplicationDict[value].append(index)\n",
    "        counterDict[value] += 1\n",
    "    \n",
    "    yPredUnique = np.sort(list(duplicationDict.keys()))\n",
    "    \n",
    "    neighborsPerPred = dict()\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    neighbors = deque()\n",
    "    \n",
    "    for k in range(len(yPredUnique)):\n",
    "        \n",
    "        if len(neighbors) < binSize:\n",
    "            neighbors.extend(duplicationDict[yPredUnique[k]])\n",
    "            \n",
    "        else:\n",
    "            neighborsMaxIter = k\n",
    "            break\n",
    "        \n",
    "        if k == (len(yPredUnique) - 1):\n",
    "            neighborsMaxIter = len(yPred)\n",
    "            \n",
    "    neighborsPerPred[yPredUnique[0]] = list(neighbors)\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    neighborsRemoved = [0]\n",
    "    neighborsAdded = [0]\n",
    "    \n",
    "    for i in range(1, len(yPredUnique)):\n",
    "        \n",
    "        removeCounter = 0\n",
    "        addCounter = 0\n",
    "        \n",
    "        predCurrent = yPredUnique[i]\n",
    "        \n",
    "        #---\n",
    "            \n",
    "        # Check and Clean current neighborhood before starting the loop\n",
    "            \n",
    "        if len(neighbors) > binSize:\n",
    "            \n",
    "            checkNeeded = True\n",
    "            while checkNeeded:\n",
    "                \n",
    "                distanceToMin = predCurrent - yPred[neighbors[0]]\n",
    "                distanceToMax = yPred[neighbors[len(neighbors) - 1]] - predCurrent\n",
    "\n",
    "                if distanceToMin > 0 and distanceToMin > distanceToMax:\n",
    "                    countIdenticalMin = counterDict[yPred[neighbors[0]]]\n",
    "                \n",
    "                    if len(neighbors) - countIdenticalMin >= binSize:\n",
    "                        removeCounter += countIdenticalMin\n",
    "\n",
    "                        for p in range(countIdenticalMin):\n",
    "                            neighbors.popleft()\n",
    "                            \n",
    "                    else:\n",
    "                        checkNeeded = False\n",
    "                else:\n",
    "                    checkNeeded = False\n",
    "\n",
    "        #---\n",
    "        \n",
    "        distanceToMin = predCurrent - yPred[neighbors[0]]\n",
    "        distanceToMax = yPred[neighbors[len(neighbors) - 1]] - predCurrent\n",
    "\n",
    "        for k in range(neighborsMaxIter, len(yPredUnique), 1):\n",
    "            predNew = yPredUnique[k]\n",
    "            distance = predNew - predCurrent \n",
    "\n",
    "            if len(neighbors) < binSize:\n",
    "                neighbors.extend(duplicationDict[predNew])\n",
    "                distanceToMax = yPred[neighbors[len(neighbors) - 1]] - predCurrent\n",
    "                addCounter += counterDict[predNew]\n",
    "                \n",
    "            elif distance < distanceToMin:\n",
    "                neighbors.extend(duplicationDict[predNew])\n",
    "                addCounter += counterDict[predNew]\n",
    "                \n",
    "                countIdenticalMin = counterDict[yPred[neighbors[0]]]\n",
    "                for p in range(countIdenticalMin): \n",
    "                    neighbors.popleft()\n",
    "                    \n",
    "                removeCounter += countIdenticalMin\n",
    "                distanceToMin = predCurrent - yPred[neighbors[0]]\n",
    "                distanceToMax = yPred[neighbors[len(neighbors) - 1]] - predCurrent\n",
    "\n",
    "            elif distance == distanceToMin:\n",
    "                neighbors.extend(duplicationDict[predNew])\n",
    "                distanceToMax = yPred[neighbors[len(neighbors) - 1]] - predCurrent\n",
    "                addCounter += counterDict[predNew]\n",
    "                \n",
    "            elif distance == distanceToMax:\n",
    "                neighbors.extend(duplicationDict[predNew])\n",
    "                addCounter += counterDict[predNew]\n",
    "                \n",
    "            else:\n",
    "                neighborsMaxIter = k\n",
    "                break\n",
    "\n",
    "            # If we end up down here, it means that all train preds have sucessuflly been\n",
    "            # added to the current neighborhood. For that reason, k has to be set to len(yPred)\n",
    "            # in order to stop the code from starting the loop.\n",
    "            if k == (len(yPredUnique) - 1):\n",
    "                neighborsMaxIter = len(yPred)\n",
    "        \n",
    "        neighborsPerPred[predCurrent] = list(neighbors)\n",
    "        neighborsRemoved.append(removeCounter)\n",
    "        neighborsAdded.append(addCounter)\n",
    "        \n",
    "    #---\n",
    " \n",
    "    return neighborsPerPred, np.array(neighborsRemoved), np.array(neighborsAdded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bdbc68-a9ce-4384-a9f3-00b7a6adcf33",
   "metadata": {},
   "source": [
    "### Get Neighbor Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d980d802-9d12-49aa-adfc-a4377c8dc0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def getNeighborsTest(binSize: int, # Size of the bins of values of `yPred` being grouped together.\n",
    "                     yPred: np.ndarray, # 1-dimensional array of predicted values.\n",
    "                     yPredTrain: np.ndarray, # 1-dimensional array of predicted train values.\n",
    "                     # Dict containing the neighbors of all train samples. Keys are the train predictions.\n",
    "                     neighborsDictTrain: dict, \n",
    "                     ):\n",
    "    \"Used to generate the neighboorhoods used by `LevelSetKDEx` to compute density estimations.\"\n",
    "    \n",
    "    duplicationDict = defaultdict(list)\n",
    "    counterDict = defaultdict(int)\n",
    "    \n",
    "    for index, value in enumerate(yPredTrain):\n",
    "        duplicationDict[value].append(index)\n",
    "        counterDict[value] += 1\n",
    "    \n",
    "    yPredTrainUnique = np.sort(list(duplicationDict.keys()))\n",
    "    yPredUnique = np.unique(yPred)\n",
    "    \n",
    "    yPredTrainUniqueRanking = {value: index for index, value in enumerate(yPredTrainUnique)}\n",
    "    \n",
    "    trainIndicesClosest = np.searchsorted(a = yPredTrainUnique, v = yPredUnique, side = 'right') - 1\n",
    "    \n",
    "    # Needed if any yPred value is lower than all yPredTrain values\n",
    "    trainIndicesClosest = np.clip(a = trainIndicesClosest, a_min = 0, a_max = None) \n",
    "    yPredTrainClosest = yPredTrainUnique[trainIndicesClosest]\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    neighborsPerPred = dict()\n",
    "\n",
    "    for i, predCurrent in enumerate(yPredUnique):\n",
    "        \n",
    "        neighbors = deque(neighborsDictTrain[yPredTrainClosest[i]])\n",
    "        neighborsMaxIndex = yPredTrainUniqueRanking[yPredTrain[neighbors[len(neighbors) - 1]]]\n",
    "        \n",
    "        distanceToMin = predCurrent - yPredTrain[neighbors[0]]\n",
    "        \n",
    "        # Check and Clean current neighborhood before starting the loop\n",
    "        if len(neighbors) > binSize:\n",
    "            \n",
    "            checkNeeded = True\n",
    "            while checkNeeded:\n",
    "                \n",
    "                distanceToMin = predCurrent - yPredTrain[neighbors[0]]\n",
    "                distanceToMax = yPredTrain[neighbors[len(neighbors) - 1]] - predCurrent\n",
    "\n",
    "                if distanceToMin > 0 and distanceToMin > distanceToMax:\n",
    "                    countIdenticalValuesLeftSide = counterDict[yPredTrain[neighbors[0]]]\n",
    "\n",
    "                    if len(neighbors) - countIdenticalValuesLeftSide >= binSize:\n",
    "                        for p in range(countIdenticalValuesLeftSide):\n",
    "                            neighbors.popleft()\n",
    "                    else:\n",
    "                        checkNeeded = False\n",
    "                else:\n",
    "                    checkNeeded = False\n",
    "\n",
    "        #---\n",
    "\n",
    "        distanceToMin = predCurrent - yPredTrain[neighbors[0]]\n",
    "        distanceToMax = yPredTrain[neighbors[len(neighbors) - 1]] - predCurrent\n",
    "\n",
    "        for k in range(neighborsMaxIndex + 1, len(yPredTrainUnique), 1):\n",
    "            predNew = yPredTrainUnique[k]\n",
    "            distance = predNew - predCurrent \n",
    "                \n",
    "            if len(neighbors) < binSize:\n",
    "                neighbors.extend(duplicationDict[predNew])\n",
    "                distanceToMax = yPredTrain[neighbors[len(neighbors) - 1]] - predCurrent\n",
    "\n",
    "            elif distance < distanceToMin:\n",
    "                neighbors.extend(duplicationDict[predNew])\n",
    "                \n",
    "                for p in range(counterDict[yPredTrain[neighbors[0]]]): \n",
    "                    neighbors.popleft()\n",
    "\n",
    "                distanceToMin = predCurrent - yPredTrain[neighbors[0]]\n",
    "                distanceToMax = yPredTrain[neighbors[len(neighbors) - 1]] - predCurrent\n",
    "\n",
    "            elif distance == distanceToMin:\n",
    "                neighbors.extend(duplicationDict[predNew])\n",
    "                distanceToMax = yPredTrain[neighbors[len(neighbors) - 1]] - predCurrent\n",
    "\n",
    "            elif distance == distanceToMax:\n",
    "                neighbors.extend(duplicationDict[predNew])\n",
    "\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        neighborsPerPred[predCurrent] = list(neighbors)\n",
    "        \n",
    "    #---\n",
    " \n",
    "    return neighborsPerPred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7168278-74bf-4af3-ba23-525d490d2bfb",
   "metadata": {},
   "source": [
    "### Get Kernel Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "269e08de-2803-4c80-a715-f98be3557de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def getKernelValues(yPred,\n",
    "                    yPredTrain,\n",
    "                    neighborsDictTest,\n",
    "                    neighborsDictTrain,\n",
    "                    neighborsRemoved,\n",
    "                    neighborsAdded,\n",
    "                    binSize,\n",
    "                    returnWeights = True):\n",
    "    \n",
    "    duplicationDict = defaultdict(list)\n",
    "    counterDict = defaultdict(int)\n",
    "    \n",
    "    for index, value in enumerate(yPredTrain):\n",
    "        duplicationDict[value].append(index)\n",
    "        counterDict[value] += 1\n",
    "    \n",
    "    yPredTrainUnique = np.sort(list(neighborsDictTrain.keys()))\n",
    "    trainIndicesClosest = np.searchsorted(a = yPredTrainUnique, v = yPred, side = 'right') - 1\n",
    "    \n",
    "    # Needed if any yPred value is lower than all yPredTrain values\n",
    "    trainIndicesClosest = np.clip(a = trainIndicesClosest, a_min = 0, a_max = None)\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    kernelValuesList = list()\n",
    "    \n",
    "    for i in range(len(yPred)):\n",
    "        \n",
    "        trainIndexClosest = trainIndicesClosest[i]\n",
    "        neighbors = neighborsDictTest[yPred[i]]\n",
    "        sizeBin = len(neighbors)\n",
    "        \n",
    "        #---\n",
    "        \n",
    "        if trainIndexClosest + 1 <= len(yPredTrainUnique) - 1:\n",
    "            neighborsTrainClosest = neighborsDictTrain[yPredTrainUnique[trainIndexClosest+1]]\n",
    "            sharedNeighborsClosest = len(set(neighbors) & set(neighborsTrainClosest))\n",
    "            \n",
    "            if trainIndexClosest + 1 == len(yPredTrainUnique) - 1:\n",
    "                kernelValuesRight = np.expand_dims(2 * sharedNeighborsClosest / (sizeBin + len(neighborsTrainClosest)), axis = 0)\n",
    "                \n",
    "            else:\n",
    "                removeCum = np.concatenate([np.arange(1), neighborsRemoved[trainIndexClosest+2:len(yPredTrainUnique)]], axis = 0).cumsum()\n",
    "                addCum = np.concatenate([np.arange(1), neighborsAdded[trainIndexClosest+2:len(yPredTrainUnique)]], axis = 0).cumsum()\n",
    "\n",
    "                sharedNeighborsRight = np.clip(a = sharedNeighborsClosest - removeCum, a_min = 0, a_max = None)\n",
    "                binSizesRight = len(neighborsTrainClosest) - removeCum + addCum\n",
    "\n",
    "                kernelValuesRight = 2 * sharedNeighborsRight / (sizeBin + binSizesRight)\n",
    "        \n",
    "        else:\n",
    "            kernelValuesRight = np.arange(0)\n",
    "            \n",
    "        #---\n",
    "        \n",
    "        # trainIndexClosest == -1 means that the test pred is lower than any train pred\n",
    "        if trainIndexClosest >= 0:\n",
    "            neighborsTrainClosest = neighborsDictTrain[yPredTrainUnique[trainIndexClosest]]\n",
    "            sharedNeighborsClosest = len(set(neighbors) & set(neighborsTrainClosest))\n",
    "            \n",
    "            if trainIndexClosest == 0:\n",
    "                kernelValuesLeft = np.expand_dims(2 * sharedNeighborsClosest / (sizeBin + len(neighborsTrainClosest)), axis = 0)\n",
    "            \n",
    "            else:\n",
    "                neighborsRemovedFlip = np.flip(neighborsRemoved[1:trainIndexClosest+1])\n",
    "                addCum = np.concatenate([np.arange(1), neighborsRemovedFlip], axis = 0).cumsum()\n",
    "\n",
    "                neighborsAddedFlip = np.flip(neighborsAdded[1:trainIndexClosest+1])\n",
    "                removeCum = np.concatenate([np.arange(1), neighborsAddedFlip], axis = 0).cumsum()\n",
    "\n",
    "                sharedNeighborsLeft = np.clip(a = sharedNeighborsClosest - removeCum, a_min = 0, a_max = None)\n",
    "                binSizesLeft = len(neighborsTrainClosest) - removeCum + addCum\n",
    "\n",
    "                kernelValuesLeft = np.flip(2 * sharedNeighborsLeft / (sizeBin + binSizesLeft))\n",
    "                    \n",
    "        else:\n",
    "            kernelValuesLeft = np.arange(0)\n",
    "\n",
    "        #---\n",
    "        \n",
    "        kernelValuesUnique = np.concatenate([kernelValuesLeft, kernelValuesRight], axis = 0)\n",
    "        kernelValuesList.append(kernelValuesUnique)\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    kernelMatrixUnique = np.array(kernelValuesList)\n",
    "    kernelMatrix = np.zeros(shape = (len(yPred), len(yPredTrain)))\n",
    "    \n",
    "    for index, predTrain in enumerate(yPredTrainUnique):\n",
    "        kernelMatrix[:, duplicationDict[predTrain]] = kernelMatrixUnique[:, [index]]\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    if returnWeights:\n",
    "        weightsDataList = list()\n",
    "\n",
    "        for i in range(len(yPred)):\n",
    "            indices = np.where(kernelMatrix[i,:] > 0)[0]\n",
    "            weights = kernelMatrix[i, indices]\n",
    "            weights = weights / weights.sum()\n",
    "            weightsDataList.append((weights, indices))\n",
    "        \n",
    "        return weightsDataList\n",
    "    \n",
    "    else:\n",
    "        return kernelMatrix      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e79762a-1427-49d7-b8b2-42ecde48e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81936321-7fe7-4b27-91e3-a4a1444bd29e",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5f055de-89ce-4943-8242-8f434ee8a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# import ipdb\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from dddex.loadData import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34541b1d-b3a9-4310-ae57-0918cbd18c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# data, XTrain, yTrain, XTest, yTest = loadDataYaz(testDays = 14, \n",
    "#                                                  returnXY = True,\n",
    "#                                                  daysToCut = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbcd2880-1b9e-4d07-ab84-4ba8a2bef226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# LGBM = LGBMRegressor(boosting_type = 'gbdt',\n",
    "#                      n_jobs = 1)\n",
    "\n",
    "# LGBM.fit(X = XTrain, y = yTrain)\n",
    "# yPredTrain = LGBM.predict(XTrain)\n",
    "# yPredTest = LGBM.predict(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36723cd7-309b-462d-8d26-829b1854f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# LSKDEx = LevelSetKDEx(estimator = LGBM, binSize = 100, weightsByDistance = False)\n",
    "# LSKDEx.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ebeec7-8a14-46f7-8c85-c19fa6bde752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yPred = np.concatenate([np.arange(5000)] * 2, axis = 0)\n",
    "# yPredTrain = np.concatenate([np.arange(50000)] * 2, axis = 0)\n",
    "# binSize = 200\n",
    "\n",
    "# neighborsDictTrain, neighborsRemoved, neighborsAdded = generateNeighborhoodsUnique(binSize = binSize,\n",
    "#                                                                                yPred = yPredTrain)\n",
    "\n",
    "# neighborsDictTest = generateNeighborhoodsTestUnique(binSize = binSize,\n",
    "#                                                 yPred = yPred,\n",
    "#                                                 yPredTrain = yPredTrain,\n",
    "#                                                 neighborsDictTrain = neighborsDictTrain)\n",
    "\n",
    "# start = time.time()\n",
    "# kernelValuesList = getKernelValues(binSize = binSize,\n",
    "#                                    yPred = yPred,\n",
    "#                                    yPredTrain = yPredTrain,\n",
    "#                                    neighborsDictTest = neighborsDictTest,\n",
    "#                                    neighborsDictTrain = neighborsDictTrain,\n",
    "#                                    neighborsRemoved = neighborsRemoved,\n",
    "#                                    neighborsAdded = neighborsAdded)\n",
    "# print(time.time() - start)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dddex",
   "language": "python",
   "name": "dddex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
