{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Defining the classes `LevelSetKDEx` and `LevelSetKDEx_kNN` which turn\n",
    "  any point predictor into a conditional kernel density estimator.\n",
    "output-file: levelsetkdex.html\n",
    "title: Level-Set Based Kernel Density Estimation\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61516f21-8606-49d3-8907-c0190315ac26",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21b8315b-c072-4e14-b477-5856b5d922fe",
   "metadata": {},
   "source": [
    "In the following we define the classes [`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex.html#levelsetkdex) and [`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex.html#levelsetkdex_knn) where KDE is short for 'Kernel Density Estimator' and the 'x' is supposed to signal that both classes can be defined based on any arbitrary point predictor. The name 'LevelSet' stems from the fact that every approach presented in this notebook interprets the values of the point forecasts as a similarity measure between samples. The point predictor is specified by the argument `estimator` and must have a `.predict()`-method and should have been trained before hand. \n",
    "\n",
    "Both classes [`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex.html#levelsetkdex) and [`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex.html#levelsetkdex_knn) fulfill the same task: By first running `.fit(XTrain, yTrain)` and then calling `.generateWeights(XTest)`, they both output an estimation of the conditional density of every sample specified by 'XTest'. The basic idea for both approaches is also identical: Suppose we have a single test sample at hand. At first, we compare the value of the point prediction of this sample and the values of the point predictions of the training samples computed via `estimator.predict(XTrain)` and `estimator.predict(XTest)`, respectively. Based on this comparison, we select 'binSize'-many training samples that we deem the most similar to the test sample at hand. The concrete way we select the training samples constitutes the only difference between [`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex.html#levelsetkdex) and [`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex.html#levelsetkdex_knn). Finally, the empirical distribution of the y-values of these training samples then acts as our estimation of the conditional distribution.\n",
    "\n",
    "Further details on how both approaches work approaches can be found below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794a75d0-8a2c-4482-b372-6e67bf394d86",
   "metadata": {},
   "source": [
    "## Level-Set Approach based on Bin Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L22){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx\n",
       "\n",
       ">      LevelSetKDEx (estimator, binSize:int=None)\n",
       "\n",
       "[`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex.html#levelsetkdex)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | (Fitted) object with a .predict-method. |\n",
       "| binSize | int | None | Size of the bins created to group the training samples. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L22){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx\n",
       "\n",
       ">      LevelSetKDEx (estimator, binSize:int=None)\n",
       "\n",
       "`LevelSetKDEx`\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | (Fitted) object with a .predict-method. |\n",
       "| binSize | int | None | Size of the bins created to group the training samples. |"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(LevelSetKDEx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8a8982-2492-463b-93c1-6a4eb0db2e00",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# show_doc(LevelSetKDEx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdb5bf-f39d-470f-b7cc-8679e733b2c6",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# show_doc(LevelSetKDEx.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca538d-96ff-48df-9e29-8573a6442a05",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# show_doc(LevelSetKDEx.getWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661e147-5acc-4593-b3a5-e93f2d82447f",
   "metadata": {},
   "source": [
    "#### Generate Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L138){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### generateBins\n",
       "\n",
       ">      generateBins (binSize:int, yPred:numpy.ndarray)\n",
       "\n",
       "Used to generate the bin-structure induced by the Level-Set-Forecaster algorithm\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| binSize | int | Size of the bins of values being grouped together. |\n",
       "| yPred | np.ndarray | 1-dimensional array of predicted values. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L138){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### generateBins\n",
       "\n",
       ">      generateBins (binSize:int, yPred:numpy.ndarray)\n",
       "\n",
       "Used to generate the bin-structure induced by the Level-Set-Forecaster algorithm\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| binSize | int | Size of the bins of values being grouped together. |\n",
       "| yPred | np.ndarray | 1-dimensional array of predicted values. |"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(generateBins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd550e-ae6e-44fe-a91b-f0ffee0096bc",
   "metadata": {},
   "source": [
    "## Level-Set Approach based on kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L179){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_kNN\n",
       "\n",
       ">      LevelSetKDEx_kNN (estimator, binSize:int|None=None)\n",
       "\n",
       "[`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex.html#levelsetkdex_knn) turns any point predictor that has a .predict-method \n",
       "into an estimator of the condititional density of the underlying distribution.\n",
       "The basic idea of each level-set based approach is to interprete the point forecast\n",
       "generated by the underlying point predictor as a similarity measure of samples.\n",
       "In the case of the [`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex.html#levelsetkdex_knn) defined here, for every new samples\n",
       "'binSize'-many training samples are computed whose point forecast is closest\n",
       "to the point forecast of the new sample.\n",
       "The resulting empirical distribution of these 'nearest' training samples are \n",
       "viewed as our estimation of the conditional distribution of each the new sample \n",
       "at hand.\n",
       "\n",
       "NOTE 1: The [`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex.html#levelsetkdex_knn) class can only be applied to estimators that \n",
       "have been fitted already.\n",
       "\n",
       "NOTE 2: In contrast to the standard [`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex.html#levelsetkdex), it is possible to apply\n",
       "[`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex.html#levelsetkdex_knn) to arbitrary dimensional point predictors.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Object with a .predict-method (fitted). |\n",
       "| binSize | int \\| None | None | Size of the neighbors considered to compute conditional density. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L179){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_kNN\n",
       "\n",
       ">      LevelSetKDEx_kNN (estimator, binSize:int|None=None)\n",
       "\n",
       "`LevelSetKDEx_kNN` turns any point predictor that has a .predict-method \n",
       "into an estimator of the condititional density of the underlying distribution.\n",
       "The basic idea of each level-set based approach is to interprete the point forecast\n",
       "generated by the underlying point predictor as a similarity measure of samples.\n",
       "In the case of the `LevelSetKDEx_kNN` defined here, for every new samples\n",
       "'binSize'-many training samples are computed whose point forecast is closest\n",
       "to the point forecast of the new sample.\n",
       "The resulting empirical distribution of these 'nearest' training samples are \n",
       "viewed as our estimation of the conditional distribution of each the new sample \n",
       "at hand.\n",
       "\n",
       "NOTE 1: The `LevelSetKDEx_kNN` class can only be applied to estimators that \n",
       "have been fitted already.\n",
       "\n",
       "NOTE 2: In contrast to the standard `LevelSetKDEx`, it is possible to apply\n",
       "`LevelSetKDEx_kNN` to arbitrary dimensional point predictors.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Object with a .predict-method (fitted). |\n",
       "| binSize | int \\| None | None | Size of the neighbors considered to compute conditional density. |"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(LevelSetKDEx_kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08104da-f4fb-4b87-b86c-66867fb6cdcd",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# show_doc(LevelSetKDEx_kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9daa50-ef7b-4858-b343-b212f07a02b9",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# show_doc(LevelSetKDEx_kNN.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97f4603-b305-464c-a67b-45ff7be439ae",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# show_doc(LevelSetKDEx_kNN.getWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7dafad-822e-4399-9dac-c2c07e14a870",
   "metadata": {},
   "source": [
    "## Bin-Size CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L330){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### binSizeCV\n",
       "\n",
       ">      binSizeCV (estimator, cvFolds, LSF_type:\"'LSF'|'LSF_kNN'\",\n",
       ">                 weightsByDistance:bool=False, binSizeGrid:list|np.ndarray=[4,\n",
       ">                 7, 10, 15, 20, 30, 40, 50, 60, 70, 80, 100, 125, 150, 200,\n",
       ">                 250, 300, 350, 400, 450, 500, 600, 700, 800, 900, 1000, 1250,\n",
       ">                 1500, 1750, 2000, 2500, 3000, 4000, 5000, 6000, 7000, 8000,\n",
       ">                 9000, 10000], probs:list|np.ndarray=[0.01, 0.02, 0.03, 0.04,\n",
       ">                 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14,\n",
       ">                 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24,\n",
       ">                 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34,\n",
       ">                 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44,\n",
       ">                 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54,\n",
       ">                 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64,\n",
       ">                 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74,\n",
       ">                 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84,\n",
       ">                 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94,\n",
       ">                 0.95, 0.96, 0.97, 0.98, 0.99], refitPerProb:bool=False,\n",
       ">                 n_jobs:int|None=None)\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Object with a .predict-method (fitted). |\n",
       "| cvFolds |  |  | Specifies cross-validation-splits. Identical to 'cv' used for cross-validation in sklearn. |\n",
       "| LSF_type | 'LSF' \\| 'LSF_kNN' |  | Specifies which LSF-Object we work with during cross-validation. |\n",
       "| weightsByDistance | bool | False |  |\n",
       "| binSizeGrid | list \\| np.ndarray | [4, 7, 10, 15, 20, 30, 40, 50, 60, 70, 80, 100, 125, 150, 200, 250, 300, 350, 400, 450, 500, 600, 700, 800, 900, 1000, 1250, 1500, 1750, 2000, 2500, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000] |  |\n",
       "| probs | list \\| np.ndarray | [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99] | list or array of floats between 0 and 1. p-quantiles being predicted to evaluate performance of LSF. |\n",
       "| refitPerProb | bool | False | If True, for each p-quantile a fitted LSF with best binSize to predict it is returned. Otherwise only one LSF is returned that is best over all probs. |\n",
       "| n_jobs | int \\| None | None | number of folds being computed in parallel. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L330){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### binSizeCV\n",
       "\n",
       ">      binSizeCV (estimator, cvFolds, LSF_type:\"'LSF'|'LSF_kNN'\",\n",
       ">                 weightsByDistance:bool=False, binSizeGrid:list|np.ndarray=[4,\n",
       ">                 7, 10, 15, 20, 30, 40, 50, 60, 70, 80, 100, 125, 150, 200,\n",
       ">                 250, 300, 350, 400, 450, 500, 600, 700, 800, 900, 1000, 1250,\n",
       ">                 1500, 1750, 2000, 2500, 3000, 4000, 5000, 6000, 7000, 8000,\n",
       ">                 9000, 10000], probs:list|np.ndarray=[0.01, 0.02, 0.03, 0.04,\n",
       ">                 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14,\n",
       ">                 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24,\n",
       ">                 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34,\n",
       ">                 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44,\n",
       ">                 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54,\n",
       ">                 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64,\n",
       ">                 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74,\n",
       ">                 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84,\n",
       ">                 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94,\n",
       ">                 0.95, 0.96, 0.97, 0.98, 0.99], refitPerProb:bool=False,\n",
       ">                 n_jobs:int|None=None)\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Object with a .predict-method (fitted). |\n",
       "| cvFolds |  |  | Specifies cross-validation-splits. Identical to 'cv' used for cross-validation in sklearn. |\n",
       "| LSF_type | 'LSF' \\| 'LSF_kNN' |  | Specifies which LSF-Object we work with during cross-validation. |\n",
       "| weightsByDistance | bool | False |  |\n",
       "| binSizeGrid | list \\| np.ndarray | [4, 7, 10, 15, 20, 30, 40, 50, 60, 70, 80, 100, 125, 150, 200, 250, 300, 350, 400, 450, 500, 600, 700, 800, 900, 1000, 1250, 1500, 1750, 2000, 2500, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000] |  |\n",
       "| probs | list \\| np.ndarray | [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99] | list or array of floats between 0 and 1. p-quantiles being predicted to evaluate performance of LSF. |\n",
       "| refitPerProb | bool | False | If True, for each p-quantile a fitted LSF with best binSize to predict it is returned. Otherwise only one LSF is returned that is best over all probs. |\n",
       "| n_jobs | int \\| None | None | number of folds being computed in parallel. |"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(binSizeCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f38ec08-8835-4c32-9979-5a71d90fd150",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# show_doc(binSizeCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L381){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### binSizeCV.fit\n",
       "\n",
       ">      binSizeCV.fit (X, y)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L381){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### binSizeCV.fit\n",
       "\n",
       ">      binSizeCV.fit (X, y)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(binSizeCV.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6475323-2d18-489d-88f2-1675a3f7198f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# show_doc(binSizeCV.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf7bd61-adb2-42cc-93f9-9734d6d39f57",
   "metadata": {},
   "source": [
    "#### Scores for Single Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L459){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### scoresForFold\n",
       "\n",
       ">      scoresForFold (cvFold, binSizeGrid, probs, estimator, LSF_type,\n",
       ">                     weightsByDistance, y, X)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L459){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### scoresForFold\n",
       "\n",
       ">      scoresForFold (cvFold, binSizeGrid, probs, estimator, LSF_type,\n",
       ">                     weightsByDistance, y, X)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(scoresForFold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5121f5c4-fab2-4788-8691-ffbef17d703f",
   "metadata": {},
   "source": [
    "##### Get Cost Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L522){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getCostRatio\n",
       "\n",
       ">      getCostRatio (decisions, decisionsSAA, yTest, prob)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx.py#L522){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getCostRatio\n",
       "\n",
       ">      getCostRatio (decisions, decisionsSAA, yTest, prob)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(getCostRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568bd960-a397-48b3-a274-952a0b6eadef",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "## Bin-Size CV 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6667bcd-238b-449a-a16a-fea05161f62f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| export\n",
    "\n",
    "# class binSizeCV2:\n",
    "\n",
    "#     def __init__(self,\n",
    "#                  estimator, # Object with a .predict-method (fitted).\n",
    "#                  paramGrid = None,\n",
    "#                  binSizeGrid: list | np.ndarray = [4, 7, 10, 15, 20, 30, 40, 50, 60, 70, 80, \n",
    "#                                                    100, 125, 150, 200, 250, 300, 350, 400, 450, 500, 600, 700, 800, 900,\n",
    "#                                                    1000, 1250, 1500, 1750, 2000, 2500, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000], # binSize (int) values being evaluated.         \n",
    "#                  cvFolds, # Specifies cross-validation-splits. Identical to 'cv' used for cross-validation in sklearn.\n",
    "#                  LSF_type: 'LSF' | 'LSF_kNN', # Specifies which LSF-Object we work with during cross-validation.       \n",
    "#                  probs: list | np.ndarray = [i / 100 for i in range(1, 100, 1)], # list or array of floats between 0 and 1. p-quantiles being predicted to evaluate performance of LSF.\n",
    "#                  refitPerProb: bool = False, # If True, for each p-quantile a fitted LSF with best binSize to predict it is returned. Otherwise only one LSF is returned that is best over all probs.\n",
    "#                  n_jobs: int | None = None, # number of folds being computed in parallel.\n",
    "#                  ):\n",
    "        \n",
    "#         # CHECKS\n",
    "        \n",
    "#         if isinstance(estimator, (LevelSetKDEx, LevelSetKDEx_kNN)):\n",
    "#             raise ValueError(\"'estimator' has to be a point predictor and not a LevelSetKDEx-Object!\")   \n",
    "#         elif not (hasattr(estimator, 'predict') and callable(estimator.predict)):\n",
    "#             raise ValueError(\"'estimator' has to have a 'predict'-method!\")\n",
    "#         else:\n",
    "#             self.estimator = estimator\n",
    "            \n",
    "#         if LSF_type is None or not LSF_type in [\"LSF\", \"LSF_kNN\"]:\n",
    "#             raise ValueError(\"LSF_type must be specified and must either be 'LSF' or 'LSF_kNN'!\")\n",
    "#         else:\n",
    "#             self.LSF_type = LSF_type\n",
    "            \n",
    "#         if np.any(np.array(probs) > 1) or np.any(np.array(probs) < 0): \n",
    "#             raise ValueError(\"probs must only contain numbers between 0 and 1!\")\n",
    "#         else:\n",
    "#             self.probs = probs\n",
    "        \n",
    "#         #---\n",
    "        \n",
    "#         self.binSizeGrid = binSizeGrid        \n",
    "#         self.cvFolds = cvFolds\n",
    "#         self.refitPerProb = refitPerProb\n",
    "#         self.n_jobs = n_jobs\n",
    "        \n",
    "#         self.best_binSize = None\n",
    "#         self.best_binSize_perProb = None\n",
    "#         self.best_estimatorLSx = None\n",
    "#         self.cv_results = None\n",
    "#         self.cv_results_raw = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5f43f-287d-458b-8ceb-95054092aa0a",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| export\n",
    "\n",
    "# @patch\n",
    "# def fit(self: binSizeCV2, \n",
    "#         X, \n",
    "#         y):\n",
    "    \n",
    "#     scoresPerFold = Parallel(n_jobs = self.n_jobs)(delayed(scoresForFold)(cvFold = cvFold,\n",
    "#                                                                           binSizeGrid = self.binSizeGrid,\n",
    "#                                                                           probs = self.probs,\n",
    "#                                                                           estimator = self.estimator,\n",
    "#                                                                           LSF_type = self.LSF_type,\n",
    "#                                                                           y = y,\n",
    "#                                                                           X = X) for cvFold in cvFolds)    \n",
    "\n",
    "#     self.cv_results_raw = scoresPerFold\n",
    "\n",
    "#     #---\n",
    "\n",
    "#     nvCostsMatrix = scoresPerFold[0]\n",
    "\n",
    "#     for i in range(1, len(scoresPerFold)):\n",
    "#         nvCostsMatrix = nvCostsMatrix + scoresPerFold[i]\n",
    "\n",
    "#     nvCostsMatrix = nvCostsMatrix / len(cvFolds)\n",
    "\n",
    "#     self.cv_results = nvCostsMatrix\n",
    "\n",
    "#     #---\n",
    "\n",
    "#     meanCostsDf = nvCostsMatrix.mean(axis = 1)\n",
    "#     binSizeBestOverall = meanCostsDf.index[np.argmax(meanCostsDf)]\n",
    "#     self.best_binSize = binSizeBestOverall\n",
    "\n",
    "#     binSizeBestPerProb = nvCostsMatrix.idxmax(axis = 0)\n",
    "#     self.best_binSize_perProb = binSizeBestPerProb\n",
    "\n",
    "#     #---\n",
    "\n",
    "#     if self.refitPerProb:\n",
    "\n",
    "#         LSFDict = dict()\n",
    "#         for binSize in binSizeBestPerProb.unique():\n",
    "\n",
    "#             if self.LSF_type == 'LSF':\n",
    "#                 LSF = LevelSetKDEx(estimator = self.estimator, \n",
    "#                                          binSize = binSize)\n",
    "#             else:\n",
    "#                 LSF = LevelSetKDEx_kNN(estimator = self.estimator, \n",
    "#                                              binSize = binSize)\n",
    "\n",
    "#             LSF.fit(X = X, y = y)\n",
    "#             LSFDict[binSize] = LSF\n",
    "\n",
    "#         self.best_estimatorLSx = {prob: LSFDict[binSizeBestPerProb.loc[prob]] \n",
    "#                                   for prob in binSizeBestPerProb.index}\n",
    "\n",
    "#     else:\n",
    "#         if self.LSF_type == 'LSF':\n",
    "#             LSF = LevelSetKDEx(estimator = self.estimator, \n",
    "#                                      binSize = binSizeBestOverall)\n",
    "#         else:\n",
    "#             LSF = LevelSetKDEx_kNN(estimator = self.estimator, \n",
    "#                                          binSize = binSizeBestOverall)\n",
    "\n",
    "#         LSF.fit(X = X, y = y)\n",
    "\n",
    "#         self.best_estimatorLSx = LSF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81936321-7fe7-4b27-91e3-a4a1444bd29e",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f055de-89ce-4943-8242-8f434ee8a3f1",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from dddex.loadData import *\n",
    "\n",
    "# data, XTrain, yTrain, XTest, yTest = loadDataYaz(testDays = 14, \n",
    "#                                                  returnXY = True,\n",
    "#                                                  daysToCut = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd2880-1b9e-4d07-ab84-4ba8a2bef226",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(n_jobs=1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "\n",
    "# LGBM = LGBMRegressor(boosting_type = 'gbdt',\n",
    "#                      n_jobs = 1)\n",
    "\n",
    "# LGBM.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1533bbef-fe12-4600-85a7-07cd9dc05fc8",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# LS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 100)\n",
    "# LS_KDEx_kNN.fit(XTrain, yTrain)\n",
    "\n",
    "# LS_KDEx = LevelSetKDEx(estimator = LGBM, binSize = 100)\n",
    "# LS_KDEx.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd21ad0a-a606-456a-9a04-e68f157c38ff",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# test = LS_KDEx_kNN.predictQ(X = XTest, weightsByDistance = True, outputAsDf = True)\n",
    "# test2 = LS_KDEx_kNN.predictQ(X = XTest, weightsByDistance = False, outputAsDf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b68c1fd-9eb8-4e88-b6a9-888e47f42536",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# test3 = LS_KDEx.predictQ(X = XTest, weightsByDistance = True, outputAsDf = True)\n",
    "# test4 = LS_KDEx.predictQ(X = XTest, weightsByDistance = False, outputAsDf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f41dfeb-6655-4cf0-8961-74bb4d14ede4",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# from dddex.utils import groupedTimeSeriesSplit\n",
    "\n",
    "# dataTrain = data[data.label == 'train']\n",
    "\n",
    "# cvFolds = groupedTimeSeriesSplit(data = dataTrain, \n",
    "#                                  kFolds = 3, \n",
    "#                                  testLength = 28, \n",
    "#                                  groupFeature = 'id', \n",
    "#                                  timeFeature = 'dayIndex')\n",
    "\n",
    "# CV = binSizeCV(estimator = LGBM,\n",
    "#                cvFolds = cvFolds,\n",
    "#                LSF_type = 'LSF',\n",
    "#                weightsByDistance = True,\n",
    "#                binSizeGrid = [10, 100, 1000],\n",
    "#                probs = [0.001, 0.5, 0.999])\n",
    "\n",
    "# CV.fit(X = XTrain, y = yTrain)\n",
    "\n",
    "# CV2 = binSizeCV(estimator = LGBM,\n",
    "#                 cvFolds = cvFolds,\n",
    "#                 LSF_type = 'LSF',\n",
    "#                 weightsByDistance = False,\n",
    "#                 binSizeGrid = [10, 100, 1000],\n",
    "#                 probs = [0.001, 0.5, 0.999])\n",
    "\n",
    "# CV2.fit(X = XTrain, y = yTrain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HC-Scheduling",
   "language": "python",
   "name": "hc-scheduling"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
