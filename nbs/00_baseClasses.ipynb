{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Class\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp baseClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "# from nbdev.qmd import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from fastcore.docments import *\n",
    "from fastcore.test import *\n",
    "from fastcore.utils import *\n",
    "from fastcore.script import *\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Class - Weights-Based Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BaseWeightsBasedEstimator(BaseEstimator):\n",
    "    \"\"\" \n",
    "    Base class that implements the 'prediction'-method for approaches based \n",
    "    on a reweighting of the empirical distribution. This class is not supposed\n",
    "    to be used directly.\n",
    "    \"\"\"\n",
    "    \n",
    "    # @call_parse\n",
    "    def predict(self : BaseWeightsBasedEstimator, \n",
    "                X: np.ndarray, # Feature matrix for which conditional quantiles are computed.\n",
    "                probs: list, # Probabilities for which quantiles are computed.\n",
    "                outputAsDf: bool=True, # Determines output. Either a dataframe with probs as columns or a dict with probs as keys.\n",
    "                # Optional. List with length X.shape[0]. Values are multiplied to the predictions\n",
    "                # of each sample to rescale values.\n",
    "                scalingList: list=None, \n",
    "                ): \n",
    "        \"\"\" Predict p-quantiles based on a reweighting of the empirical distribution function.\"\"\"\n",
    "        \n",
    "        # Checks\n",
    "        if isinstance(probs, float) or probs == 0 or probs == 1:\n",
    "            probs = [probs]\n",
    "            \n",
    "        if any([prob > 1 or prob < 0 for prob in probs]):\n",
    "            raise ValueError(\"The values specified via 'probs' must lie between 0 and 1!\")\n",
    "        \n",
    "        #---\n",
    "                             \n",
    "        distributionDataList = self.getWeights(X = X,\n",
    "                                               outputType = 'cumulativeDistribution',\n",
    "                                               scalingList = scalingList)\n",
    "\n",
    "        quantilesDict = {prob: [] for prob in probs}\n",
    "\n",
    "        for probsDistributionFunction, yDistributionFunction in distributionDataList:\n",
    "\n",
    "            for prob in probs:\n",
    "                \n",
    "                # A tolerance term of 10^-8 is substracted from prob to account for rounding errors due to numerical precision. \n",
    "                quantileIndex = np.where(probsDistributionFunction >= prob - 10**-8)[0][0]\n",
    "                    \n",
    "                quantile = yDistributionFunction[quantileIndex]\n",
    "                quantilesDict[prob].append(quantile)\n",
    "\n",
    "        quantilesDf = pd.DataFrame(quantilesDict)\n",
    "\n",
    "        # Just done to make the dictionary contain arrays rather than lists of the quantiles.\n",
    "        quantilesDict = {prob: np.array(quantiles) for prob, quantiles in quantilesDict.items()}\n",
    "\n",
    "        #---\n",
    "\n",
    "        if outputAsDf:\n",
    "            return quantilesDf\n",
    "\n",
    "        else:\n",
    "            return quantilesDict\n",
    "        \n",
    "    #---\n",
    "    \n",
    "    def getWeights(self, \n",
    "                   X: np.ndarray, # Feature matrix for which conditional density estimates are computed.\n",
    "                   # Specifies structure of the returned density estimates. One of: \n",
    "                   # 'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized'\n",
    "                   outputType: str='onlyPositiveWeights', \n",
    "                   # Optional. List with length X.shape[0]. Values are multiplied to the estimated \n",
    "                   # density of each sample for scaling purposes.\n",
    "                   scalingList: list=None,\n",
    "                   ) -> list: # List whose elements are the conditional density estimates for the samples specified by `X`.\n",
    "        \"\"\"\n",
    "        Computes estimated conditional density for each sample specified by `X`. The concrete structure of each element \n",
    "        of the returned list depends on the specified value of `outputType`:\n",
    "        \n",
    "        - **all**: An array with the same length as the number of training samples. Each entry represents the probability \n",
    "          of each training sample.\n",
    "        - **onlyPositiveWeights**: A tuple. The first element of the tuple represents the probabilities and the second \n",
    "          one the indices of the corresponding training sample. Only probalities greater than zero are returned. \n",
    "          Note: This is the most memory and computationally efficient output type.\n",
    "        - **summarized**: A tuple. The first element of the tuple represents the probabilities and the second one the \n",
    "          corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
    "        - **cumDistribution**: A tuple. The first element of the tuple represents the probabilities and the second \n",
    "          one the corresponding value of `yTrain`.\n",
    "        - **cumDistributionSummarized**: A tuple. The first element of the tuple represents the probabilities and \n",
    "          the second one the corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(BaseWeightsBasedEstimator.getWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(BaseWeightsBasedEstimator.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# def predict(self: BaseWeightsBasedEstimator, \n",
    "#                 X,\n",
    "#                 probs, \n",
    "#                 outputAsDf = True, \n",
    "#                 scalingList = None, \n",
    "#                 ):\n",
    "        \n",
    "#         \"\"\"\n",
    "#         Build a gradient boosting model from the training set (X, y).\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : array-like\n",
    "#             Input feature matrix with n_samples many rows.\n",
    "#         probs : iterable, default = [0.1, 0.5, 0.9]\n",
    "#             Probabilities for which quantiles are computed.\n",
    "#         outputAsDf: bool\n",
    "#             If false, predictions are returned as dict with values of probs as keys.\n",
    "#         scalingList: iterable\n",
    "#             Optional. List with length X.shape[0]. Values are multiplied to the preds for each samples to rescale values.\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         list of length n_samples\n",
    "#         \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HC-Scheduling",
   "language": "python",
   "name": "hc-scheduling"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
